{"pullReviews":[{"pull":{"id":6230,"html_url":"https://github.com/jina-ai/serve/pull/6230","title":"fix: direct docs usage in client","body":"Goals:\n\n\n\nresolves #ISSUE-NUMBER\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n check and update documentation. See guide and ask the team.","is_merged":false,"diff":"diff --git a/jina/clients/request/helper.py b/jina/clients/request/helper.py\nindex 9976c470216fe..7b6c9f68125c5 100644\n--- a/jina/clients/request/helper.py\n+++ b/jina/clients/request/helper.py\n@@ -90,4 +90,5 @@ def _add_docs(req: DataRequest, batch, data_type: DataInputType) -> None:\n         d, data_type = _new_doc_from_data(content, data_type)\n         da.append(d)\n     req.document_array_cls = da.__class__\n-    req.data.docs = da\n+    req.direct_docs = da\n+    #req.data.docs = da\n"},"summary":"## MR Summary\n\nДанный MR вносит изменения, связанные с обработкой документов в запросах. Основное изменение заключается в замене `req.data.docs` на `req.direct_docs`, что, вероятно, направлено на оптимизацию доступа к документам. Оценка сложности изменений – низкая, так как изменения локальны и просты для понимания. Анализ стиля кода показал соответствие стандартам, читаемость не ухудшилась. В области паттернов проектирования и анти-паттернов существенных изменений не обнаружено, хотя потенциально `direct_docs` может улучшить производительность.\n","antiPatterns":{"detailed_analysis":"Внесенные изменения заменяют `req.data.docs` на `req.direct_docs`. Это может быть улучшением, если `direct_docs` предоставляет более эффективный способ доступа к документам. Однако, без дополнительного контекста, сложно оценить, является ли это решением анти-паттерна. В текущем виде, это не ухудшает и не улучшает ситуацию с анти-паттернами.","recommendations":[],"confidence":"High","score":8,"summary":"Изменения вносят небольшие изменения в способ доступа к документам, не вводя новых анти-паттернов."},"complexity":{"justification":"Изменения вносят небольшие корректировки в код, связанные с использованием документации. Объем изменений невелик, затрагивает один файл. Изменения не влияют на критические компоненты или основные потоки данных. Когнитивная нагрузка низкая, логика проста и понятна. Риск регрессии минимален. Пример соответствует категории \"Low\", так как изменения локализованы и просты для понимания.","classification":"Low"},"designPatterns":{"detailed_analysis":"Внесенные изменения заменяют `req.data.docs` на `req.direct_docs`. Это может быть улучшением, если `direct_docs` предоставляет более эффективный способ доступа к документам. Однако, без дополнительного контекста, сложно оценить, является ли это решением анти-паттерна или просто изменением реализации. В текущем контексте, анти-паттерны не обнаружены.","recommendations":[],"confidence":"High","score":9,"summary":"Изменения вносят небольшие изменения в способ доступа к документам, потенциально улучшая производительность. Анти-паттерны не обнаружены."},"codeStyle":{"detailed_analysis":"В данном diff изменена строка, касающаяся добавления документов в запрос. Вместо `req.data.docs = da` теперь используется `req.direct_docs = da`, а старая строка закомментирована. Это изменение, вероятно, направлено на оптимизацию или изменение способа передачи документов. Форматирование сохранено, отступы и пробелы соответствуют стилю. Именование переменных и функций осталось прежним, что обеспечивает консистентность. Читаемость кода не ухудшилась, так как изменение небольшое и понятное. Соответствие гайдлайнам не нарушено. В целом, изменения минимальны и не вызывают проблем со стилем.","recommendations":[],"confidence":"High","score":9,"summary":"Изменения в коде минимальны и касаются способа добавления документов в запрос. Код соответствует стандартам и легко читается."}},{"pull":{"id":6223,"html_url":"https://github.com/jina-ai/serve/pull/6223","title":"ci: test uvicorn non standard install","body":"Goals:\n\n\n\nresolves #ISSUE-NUMBER\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n check and update documentation. See guide and ask the team.","is_merged":true,"diff":"diff --git a/extra-requirements.txt b/extra-requirements.txt\nindex 9df83c9a8310b..f5e4432c67bb5 100644\n--- a/extra-requirements.txt\n+++ b/extra-requirements.txt\n@@ -46,7 +46,7 @@ opentelemetry-instrumentation-aiohttp-client>=0.33b0:    perf,standard,devel\n opentelemetry-instrumentation-fastapi>=0.33b0: perf,standard,devel\n opentelemetry-exporter-otlp-proto-grpc>=1.13.0: perf,standrad,devel\n fastapi>=0.76.0:            standard,devel\n-uvicorn[standard]<=0.23.1:  standard,devel\n+uvicorn<=0.23.1:            standard,devel\n docker:                     standard,devel\n pathspec:                   standard,devel\n filelock:                   standard,devel\n"},"summary":"## MR Summary\n\nДанный merge request направлен на обновление зависимости `uvicorn` в файле `extra-requirements.txt`. Основное изменение заключается в удалении суффикса `[standard]` при указании версии `uvicorn`. Оценка сложности изменений – низкая, так как правки незначительны и не затрагивают критические компоненты. Анализ Code Style показал соответствие стандартам кодирования. Отсутствуют анти-паттерны и нарушения Design Patterns, что подтверждает высокое качество внесенных изменений.\n","antiPatterns":{"detailed_analysis":"Внесенные изменения касаются только обновления версии `uvicorn` в файле `extra-requirements.txt`. Изменения не вводят и не устраняют анти-паттерны. Изменение версии само по себе не является анти-паттерном.","recommendations":[],"confidence":"High","score":10,"summary":"Изменения в файле `extra-requirements.txt` не содержат анти-паттернов."},"complexity":{"justification":"Изменение вносит незначительные правки в файл `extra-requirements.txt`.  Изменена строка с зависимостью `uvicorn`, удален суффикс `[standard]`. Это, вероятно, необходимо для тестирования нестандартной установки uvicorn. Объем изменений мал, затрагивает только конфигурацию зависимостей, не влияет на критические компоненты или логику работы. Когнитивная нагрузка низкая, понимание изменений не требует глубоких знаний системы. Риски минимальны.","classification":"Low"},"designPatterns":{"detailed_analysis":"Внесенные изменения касаются только обновления версии `uvicorn` в файле `extra-requirements.txt`. Изменения не вводят и не устраняют анти-паттерны. Изменение версии само по себе не является анти-паттерном.","recommendations":[],"confidence":"High","score":10,"summary":"Изменения в файле `extra-requirements.txt` не содержат анти-паттернов."},"codeStyle":{"detailed_analysis":"Изменения в файле `extra-requirements.txt` касаются версии `uvicorn`.  В частности, удалена опция `[standard]` при указании версии.  Форматирование соответствует общему стилю файла.  Именование и консистентность в порядке. Читаемость не страдает. Соответствие гайдлайнам соблюдено. Изменения простые и понятные.","recommendations":[],"confidence":"High","score":9,"summary":"Изменения в файле `extra-requirements.txt` соответствуют стандартам кодирования. Удалена опция `[standard]` для `uvicorn`."}},{"pull":{"id":6222,"html_url":"https://github.com/jina-ai/serve/pull/6222","title":"ci: pdate force-release.yml","body":"Goals:\n\n\n\nresolves #ISSUE-NUMBER\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n check and update documentation. See guide and ask the team.","is_merged":true,"diff":"diff --git a/.github/workflows/force-release.yml b/.github/workflows/force-release.yml\nindex bf44188975c1d..b9aeb324c3b1d 100644\n--- a/.github/workflows/force-release.yml\n+++ b/.github/workflows/force-release.yml\n@@ -154,7 +154,7 @@ jobs:\n #          submodules: true\n       - uses: actions/setup-python@v4\n         with:\n-          python-version: 3.7\n+          python-version: \"3.10\"\n         # https://github.com/actions/checkout#fetch-all-tags\n       - uses: actions/download-artifact@v3\n         with:\n"},"summary":"## MR Summary\n\nДанный merge request направлен на обновление версии Python в файле конфигурации CI/CD (force-release.yml) с 3.7 до 3.10. Изменения минимальны и не влияют на общую структуру кода. Экспертная оценка подтверждает низкую сложность изменений. Анализ стиля кода показал соответствие стандартам, а также отсутствие анти-паттернов и применение улучшенных практик дизайна.\n","antiPatterns":{"detailed_analysis":"Внесенные изменения затрагивают файл конфигурации CI/CD. Изменение версии Python с 3.7 на 3.10 является улучшением, так как 3.7 устарела. Других анти-паттернов не обнаружено.","recommendations":[],"confidence":"High","score":10,"summary":"Изменение версии Python в файле конфигурации CI/CD. Анти-паттерны не обнаружены."},"complexity":{"justification":"Изменения простые и локализованные. Обновление версии Python в файле конфигурации CI/CD. Небольшое количество измененных строк, не затрагивает критические компоненты, простая логика, низкая когнитивная нагрузка, минимальный риск регрессии.","classification":"Low"},"designPatterns":{"detailed_analysis":"Внесенные изменения затрагивают файл конфигурации CI/CD. Изменения включают обновление версии Python с 3.7 до 3.10. Это улучшение, так как более новые версии Python обычно включают исправления безопасности и улучшения производительности. Анти-паттерны не обнаружены.","recommendations":[],"confidence":"High","score":10,"summary":"Обновление версии Python в файле конфигурации CI/CD. Анти-паттерны не обнаружены."},"codeStyle":{"detailed_analysis":"В данном diff изменена версия Python в файле force-release.yml с 3.7 на 3.10. Форматирование и именование соответствуют стандартам. Изменения минимальны и не влияют на читаемость или консистентность. Соответствие гайдлайнам соблюдено.","recommendations":[],"confidence":"High","score":9,"summary":"Изменения в файле force-release.yml касаются только версии Python, что не требует значительных изменений в стиле кода. Код соответствует стандартам."}},{"pull":{"id":6221,"html_url":"https://github.com/jina-ai/serve/pull/6221","title":"cI: change build","body":"Goals:\n\n\n\nresolves #ISSUE-NUMBER\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n check and update documentation. See guide and ask the team.","is_merged":true,"diff":"diff --git a/.github/workflows/force-release.yml b/.github/workflows/force-release.yml\nindex 358dc39e88918..bf44188975c1d 100644\n--- a/.github/workflows/force-release.yml\n+++ b/.github/workflows/force-release.yml\n@@ -34,9 +34,6 @@ jobs:\n       matrix:\n         include:\n           # linux\n-          - os: ubuntu-latest\n-            python: '3.7'\n-            python-manylinux-tag: \"cp37-cp37m\"\n           - os: ubuntu-latest\n             python: '3.8'\n             python-manylinux-tag: \"cp38-cp38\"\n"},"summary":"## MR Summary\n\nДанный merge request направлен на обновление конфигурации CI/CD для сборки. Основное изменение – удаление поддержки Python 3.7 из конфигурационного файла `.github/workflows/force-release.yml`. Оценка сложности изменений – \"Low\", так как изменения незначительны и не затрагивают критические компоненты. Анализ Code Style показал соответствие существующему стилю, оценка – 8 баллов, рекомендации отсутствуют. В изменениях не обнаружены анти-паттерны, оценка по этому критерию – 10 баллов.\n","antiPatterns":{"detailed_analysis":"В данном diff-файле изменений, связанных с анти-паттернами, не обнаружено. Удалены строки, связанные с python 3.7, что не является анти-паттерном. Код хорошо структурирован и соответствует лучшим практикам.","recommendations":[],"confidence":"High","score":10,"summary":"Внесенные изменения не содержат анти-паттернов."},"complexity":{"justification":"Изменения в файле конфигурации CI/CD (.github/workflows/force-release.yml). Изменения незначительны, затрагивают только конфигурацию сборки, а именно, удаление одной из версий Python для сборки. Это не влияет на критические компоненты, не требует глубокого понимания системы и не вносит существенных рисков. Объем изменений мал, что соответствует уровню сложности \"Low\".","classification":"Low"},"designPatterns":{"detailed_analysis":"Внесенные изменения в файл `.github/workflows/force-release.yml` касаются только конфигурации окружения для сборки.  Изменения включают в себя обновление версий Python, используемых для сборки.  Эти изменения не затрагивают логику работы, структуру кода или его взаимодействие с другими компонентами системы.  Поэтому, в данных изменениях отсутствуют анти-паттерны.","recommendations":[],"confidence":"High","score":10,"summary":"Изменения в конфигурации сборки не содержат анти-паттернов."},"codeStyle":{"detailed_analysis":"Изменения в файле .github/workflows/force-release.yml касаются конфигурации окружения для сборки.  В частности, удалена конфигурация для Python 3.7.  Форматирование сохранено, отступы и пробелы соответствуют существующему стилю.  Именование переменных и констант не изменено, поэтому оценка по этому критерию невозможна.  Изменения минимальны и не влияют на читаемость кода.  Соответствие гайдлайнам не оценивается, так как изменения касаются конфигурационного файла, а не кода на Python.  В целом, изменения минимальны и не вызывают проблем со стилем.","recommendations":[],"confidence":"Medium","score":8,"summary":"Изменения в конфигурации сборки минимальны и соответствуют существующему стилю. Рекомендации по улучшению отсутствуют."}},{"pull":{"id":6220,"html_url":"https://github.com/jina-ai/serve/pull/6220","title":"feat: change return error code","body":"Goals:\n\n\n\nresolves #ISSUE-NUMBER\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n check and update documentation. See guide and ask the team.","is_merged":true,"diff":"diff --git a/.github/workflows/cd.yml b/.github/workflows/cd.yml\nindex 805582199bfb3..f5fb181c7eb0b 100644\n--- a/.github/workflows/cd.yml\n+++ b/.github/workflows/cd.yml\n@@ -106,7 +106,7 @@ jobs:\n     strategy:\n       fail-fast: false\n       matrix:\n-        python-version: [3.8]\n+        python-version: [\"3.10\"]\n         protobuf-version: ['==3.19.6', '']\n     steps:\n       - uses: actions/checkout@v2.5.0\n@@ -127,7 +127,7 @@ jobs:\n \n       - name: Build wheels with setuptools-golang-build-manylinux-wheel\n         run: |\n-          setuptools-golang-build-manylinux-wheels --pythons cp38-cp38\n+          setuptools-golang-build-manylinux-wheels --pythons cp310-cp310\n       - name: Prepare environment\n         run: |\n           docker build -f Dockerfiles/test-pip.Dockerfile -t jinaai/jina:test-pip .\n@@ -138,7 +138,7 @@ jobs:\n           if [[ \"${{ matrix.protobuf-version }}\" == \"==3.19.6\" ]]; then\n             pip install -U protobuf${{ matrix.protobuf-version }} grpcio==1.47.5 grpcio-reflection==1.47.5 grpcio-health-checking==1.47.5\n           else\n-            pip install -U protobuf${{ matrix.protobuf-version }}\n+            pip install -U protobuf${{ matrix.protobuf-version }} grpcio==1.65.5 grpcio-reflection==1.65.5 grpcio-health-checking==1.65.5\n           fi\n           jina\n           export JINA_LOG_LEVEL=\"ERROR\"\n@@ -180,7 +180,7 @@ jobs:\n     strategy:\n       fail-fast: false\n       matrix:\n-        python-version: [3.8]\n+        python-version: [\"3.10\"]\n         protobuf-version: ['==3.19.6', '']\n     steps:\n       - uses: actions/checkout@v2.5.0\n@@ -202,7 +202,7 @@ jobs:\n \n       - name: Build wheels with setuptools-golang-build-manylinux-wheel\n         run: |\n-          setuptools-golang-build-manylinux-wheels --pythons cp38-cp38\n+          setuptools-golang-build-manylinux-wheels --pythons cp310-cp310\n       - name: Prepare environment\n         run: |\n           docker build -f Dockerfiles/test-pip.Dockerfile -t jinaai/jina:test-pip .\n@@ -213,7 +213,7 @@ jobs:\n           if [[ \"${{ matrix.protobuf-version }}\" == \"==3.19.6\" ]]; then\n             pip install -U protobuf${{ matrix.protobuf-version }} grpcio==1.47.5 grpcio-reflection==1.47.5 grpcio-health-checking==1.47.5\n           else\n-            pip install -U protobuf${{ matrix.protobuf-version }}\n+            pip install -U protobuf${{ matrix.protobuf-version }} grpcio==1.65.5 grpcio-reflection==1.65.5 grpcio-health-checking==1.65.5\n           fi\n           jina\n           export JINA_LOG_LEVEL=\"ERROR\"\n@@ -281,9 +281,6 @@ jobs:\n       matrix:\n         include:\n           # linux\n-          - os: ubuntu-latest\n-            python: '3.7'\n-            python-manylinux-tag: \"cp37-cp37m\"\n           - os: ubuntu-latest\n             python: '3.8'\n             python-manylinux-tag: \"cp38-cp38\"\n@@ -451,7 +448,7 @@ jobs:\n     strategy:\n       fail-fast: false\n       matrix:\n-        python-version: [3.8]\n+        python-version: [\"3.10\"]\n         test-path: ${{fromJson(needs.prep-testbed.outputs.matrix)}}\n     steps:\n       - uses: actions/checkout@v2.5.0\n@@ -473,7 +470,7 @@ jobs:\n \n       - name: Build wheels with setuptools-golang-build-manylinux-wheel\n         run: |\n-          setuptools-golang-build-manylinux-wheels --pythons cp38-cp38\n+          setuptools-golang-build-manylinux-wheels --pythons cp310-cp310\n       - name: Prepare environment\n         run: |\n           docker build --build-arg DOCARRAY_VERSION=\"0.21.0\" -f Dockerfiles/test-pip.Dockerfile -t jinaai/jina:test-pip .\n@@ -482,6 +479,7 @@ jobs:\n           WHEEL_FILE=$(ls dist/*whl)\n           pip install \"$WHEEL_FILE[all]\" --no-cache-dir\n           pip install docarray==0.21.0\n+          pip install grpcio==1.65.5 grpcio-reflection==1.65.5 grpcio-health-checking==1.65.5\n           jina\n           export JINA_LOG_LEVEL=\"ERROR\"\n       - name: Test\n@@ -503,7 +501,7 @@ jobs:\n           files: \"coverage.xml\"\n       - name: Upload coverage from test to Codecov\n         uses: codecov/codecov-action@v3.1.1\n-        if: steps.check_files.outputs.files_exists == 'true' && ${{ matrix.python-version }} == '3.8'\n+        if: steps.check_files.outputs.files_exists == 'true' && ${{ matrix.python-version }} == '3.10'\n         with:\n           file: coverage.xml\n           name: ${{ matrix.test-path }}-codecov\n@@ -587,10 +585,10 @@ jobs:\n       #        with:\n       #          access_token: ${{ github.token }}\n       - uses: actions/checkout@v2.5.0\n-      - name: Set up Python 3.8\n+      - name: Set up Python 3.10\n         uses: actions/setup-python@v4\n         with:\n-          python-version: 3.8\n+          python-version: \"3.10\"\n       - name: Test hubapp with hubpods\n         run: |\n           ./tests/jinahub/test_integration.sh\n@@ -604,10 +602,10 @@ jobs:\n     runs-on: ubuntu-latest\n     steps:\n       - uses: actions/checkout@v2.5.0\n-      - name: Set up Python 3.8\n+      - name: Set up Python 3.10\n         uses: actions/setup-python@v4\n         with:\n-          python-version: 3.8\n+          python-version: \"3.10\"\n       - name: Prepare enviroment\n         run: |\n           docker build --build-arg DOCARRAY_VERSION=\"0.21.0\" -f Dockerfiles/test-pip.Dockerfile -t jinaai/jina:test-pip .\n@@ -634,7 +632,7 @@ jobs:\n           files: \"coverage.xml\"\n       - name: Upload coverage from test to Codecov\n         uses: codecov/codecov-action@v3.1.1\n-        if: steps.check_files.outputs.files_exists == 'true' && ${{ matrix.python-version }} == '3.8'\n+        if: steps.check_files.outputs.files_exists == 'true' && ${{ matrix.python-version }} == '3.10'\n         with:\n           file: coverage.xml\n           name: ${{ matrix.test-path }}-codecov\n@@ -646,10 +644,10 @@ jobs:\n     runs-on: ubuntu-latest\n     steps:\n       - uses: actions/checkout@v2.5.0\n-      - name: Set up Python 3.8\n+      - name: Set up Python 3.10\n         uses: actions/setup-python@v4\n         with:\n-          python-version: 3.8\n+          python-version: \"3.10\"\n       - name: Prepare enviroment\n         run: |\n           docker build --build-arg DOCARRAY_VERSION=\"0.21.0\" -f Dockerfiles/test-pip.Dockerfile -t jinaai/jina:test-pip .\n@@ -676,7 +674,7 @@ jobs:\n           files: \"coverage.xml\"\n       - name: Upload coverage from test to Codecov\n         uses: codecov/codecov-action@v3.1.1\n-        if: steps.check_files.outputs.files_exists == 'true' && ${{ matrix.python-version }} == '3.8'\n+        if: steps.check_files.outputs.files_exists == 'true' && ${{ matrix.python-version }} == '3.10'\n         with:\n           file: coverage.xml\n           name: ${{ matrix.test-path }}-codecov\n@@ -688,10 +686,10 @@ jobs:\n     runs-on: ubuntu-latest\n     steps:\n       - uses: actions/checkout@v2.5.0\n-      - name: Set up Python 3.8\n+      - name: Set up Python 3.10\n         uses: actions/setup-python@v4\n         with:\n-          python-version: 3.8\n+          python-version: \"3.10\"\n       - name: Prepare enviroment\n         run: |\n           docker build --build-arg DOCARRAY_VERSION=\"0.21.0\" -f Dockerfiles/test-pip.Dockerfile -t jinaai/jina:test-pip .\n@@ -718,7 +716,7 @@ jobs:\n           files: \"coverage.xml\"\n       - name: Upload coverage from test to Codecov\n         uses: codecov/codecov-action@v3.1.1\n-        if: steps.check_files.outputs.files_exists == 'true' && ${{ matrix.python-version }} == '3.8'\n+        if: steps.check_files.outputs.files_exists == 'true' && ${{ matrix.python-version }} == '3.10'\n         with:\n           file: coverage.xml\n           name: ${{ matrix.test-path }}-codecov\n@@ -730,10 +728,10 @@ jobs:\n     runs-on: ubuntu-latest\n     steps:\n       - uses: actions/checkout@v2.5.0\n-      - name: Set up Python 3.8\n+      - name: Set up Python 3.10\n         uses: actions/setup-python@v4\n         with:\n-          python-version: 3.8\n+          python-version: \"3.10\"\n       - name: Prepare enviroment\n         run: |\n           docker build --build-arg DOCARRAY_VERSION=\"0.21.0\" -f Dockerfiles/test-pip.Dockerfile -t jinaai/jina:test-pip .\n@@ -761,7 +759,7 @@ jobs:\n           files: \"coverage.xml\"\n       - name: Upload coverage from test to Codecov\n         uses: codecov/codecov-action@v3.1.1\n-        if: steps.check_files.outputs.files_exists == 'true' && ${{ matrix.python-version }} == '3.8'\n+        if: steps.check_files.outputs.files_exists == 'true' && ${{ matrix.python-version }} == '3.10'\n         with:\n           file: coverage.xml\n           name: ${{ matrix.test-path }}-codecov\n@@ -773,10 +771,10 @@ jobs:\n     runs-on: ubuntu-latest\n     steps:\n       - uses: actions/checkout@v2.5.0\n-      - name: Set up Python 3.8\n+      - name: Set up Python 3.10\n         uses: actions/setup-python@v4\n         with:\n-          python-version: 3.8\n+          python-version: \"3.10\"\n       - name: Prepare enviroment\n         run: |\n           docker build --build-arg DOCARRAY_VERSION=\"0.21.0\" -f Dockerfiles/test-pip.Dockerfile -t jinaai/jina:test-pip .\n@@ -801,7 +799,7 @@ jobs:\n           files: \"coverage.xml\"\n       - name: Upload coverage from test to Codecov\n         uses: codecov/codecov-action@v3.1.1\n-        if: steps.check_files.outputs.files_exists == 'true' && ${{ matrix.python-version }} == '3.8'\n+        if: steps.check_files.outputs.files_exists == 'true' && ${{ matrix.python-version }} == '3.10'\n         with:\n           file: coverage.xml\n           name: ${{ matrix.test-path }}-codecov\n@@ -813,10 +811,10 @@ jobs:\n     runs-on: ubuntu-latest\n     steps:\n       - uses: actions/checkout@v2.5.0\n-      - name: Set up Python 3.8\n+      - name: Set up Python 3.10\n         uses: actions/setup-python@v4\n         with:\n-          python-version: 3.8\n+          python-version: \"3.10\"\n       - name: Prepare enviroment\n         run: |\n           docker build --build-arg DOCARRAY_VERSION=\"0.21.0\" -f Dockerfiles/test-pip.Dockerfile -t jinaai/jina:test-pip .\n@@ -839,7 +837,7 @@ jobs:\n           files: \"coverage.xml\"\n       - name: Upload coverage from test to Codecov\n         uses: codecov/codecov-action@v3.1.1\n-        if: steps.check_files.outputs.files_exists == 'true' && ${{ matrix.python-version }} == '3.8'\n+        if: steps.check_files.outputs.files_exists == 'true' && ${{ matrix.python-version }} == '3.10'\n         with:\n           file: coverage.xml\n           name: ${{ matrix.test-path }}-codecov\ndiff --git a/.github/workflows/ci.yml b/.github/workflows/ci.yml\nindex be1a07813463d..0896e30b29b52 100644\n--- a/.github/workflows/ci.yml\n+++ b/.github/workflows/ci.yml\n@@ -23,10 +23,10 @@ jobs:\n     runs-on: ubuntu-latest\n     steps:\n       - uses: actions/checkout@v2.5.0\n-      - name: Set up Python 3.8\n+      - name: Set up Python 3.10\n         uses: actions/setup-python@v4\n         with:\n-          python-version: 3.8\n+          python-version: \"3.10\"\n       - name: Lint with flake8\n         run: |\n           pip install flake8\n@@ -41,10 +41,10 @@ jobs:\n       - uses: actions/checkout@v2.5.0\n         with:\n           fetch-depth: 0\n-      - name: Set up Python 3.8\n-        uses: actions/setup-python@v1\n+      - name: Set up Python 3.10\n+        uses: actions/setup-python@v2\n         with:\n-          python-version: 3.8\n+          python-version: \"3.10\"\n       - id: file_changes\n         uses: Ana06/get-changed-files@v1.2\n       - name: docstring check with darglint and pydocstyle\n@@ -58,10 +58,10 @@ jobs:\n       - uses: actions/checkout@v2.5.0\n         with:\n           fetch-depth: 0\n-      - name: Set up Python 3.8\n+      - name: Set up Python 3.10\n         uses: actions/setup-python@v4\n         with:\n-          python-version: 3.8\n+          python-version: \"3.10\"\n       - id: file_changes\n         uses: Ana06/get-changed-files@v1.2\n       - name: check black\n@@ -77,11 +77,11 @@ jobs:\n         with:\n           token: ${{ secrets.GITHUB_TOKEN }}\n           ref: ${{ github.event.pull_request.head.sha }}\n-      - name: Set up Python 3.8\n+      - name: Set up Python 3.10\n         uses: actions/setup-python@v4\n         if: ${{ !github.event.pull_request.head.repo.fork }}\n         with:\n-          python-version: 3.8\n+          python-version: \"3.10\"\n       - name: Styling\n         id: styling\n         if: ${{ !github.event.pull_request.head.repo.fork }}\n@@ -158,10 +158,10 @@ jobs:\n #        with:\n #          access_token: ${{ github.token }}\n       - uses: actions/checkout@v2.5.0\n-      - name: Set up Python 3.8\n+      - name: Set up Python 3.10\n         uses: actions/setup-python@v4\n         with:\n-          python-version: 3.8\n+          python-version: \"3.10\"\n       - name: Test hubapp with hubpods\n         run: |\n           ./tests/jinahub/test_integration.sh\n@@ -175,10 +175,10 @@ jobs:\n     runs-on: ubuntu-latest\n     steps:\n       - uses: actions/checkout@v2.5.0\n-      - name: Set up Python 3.8\n+      - name: Set up Python 3.10\n         uses: actions/setup-python@v4\n         with:\n-          python-version: 3.8\n+          python-version: \"3.10\"\n       - name: Prepare enviroment\n         run: |\n           docker build --build-arg DOCARRAY_VERSION=\"0.21.0\" -f Dockerfiles/test-pip.Dockerfile -t jinaai/jina:test-pip .\n@@ -205,7 +205,7 @@ jobs:\n           files: \"coverage.xml\"\n       - name: Upload coverage from test to Codecov\n         uses: codecov/codecov-action@v3.1.1\n-        if: steps.check_files.outputs.files_exists == 'true' && ${{ matrix.python-version }} == '3.8'\n+        if: steps.check_files.outputs.files_exists == 'true' && ${{ matrix.python-version }} == '3.10'\n         with:\n           file: coverage.xml\n           name: ${{ matrix.test-path }}-codecov\n@@ -217,10 +217,10 @@ jobs:\n     runs-on: ubuntu-latest\n     steps:\n       - uses: actions/checkout@v2.5.0\n-      - name: Set up Python 3.8\n+      - name: Set up Python 3.10\n         uses: actions/setup-python@v4\n         with:\n-          python-version: 3.8\n+          python-version: \"3.10\"\n       - name: Prepare enviroment\n         run: |\n           docker build --build-arg DOCARRAY_VERSION=\"0.21.0\" -f Dockerfiles/test-pip.Dockerfile -t jinaai/jina:test-pip .\n@@ -247,7 +247,7 @@ jobs:\n           files: \"coverage.xml\"\n       - name: Upload coverage from test to Codecov\n         uses: codecov/codecov-action@v3.1.1\n-        if: steps.check_files.outputs.files_exists == 'true' && ${{ matrix.python-version }} == '3.8'\n+        if: steps.check_files.outputs.files_exists == 'true' && ${{ matrix.python-version }} == '3.10'\n         with:\n           file: coverage.xml\n           name: ${{ matrix.test-path }}-codecov\n@@ -259,10 +259,10 @@ jobs:\n     runs-on: ubuntu-latest\n     steps:\n       - uses: actions/checkout@v2.5.0\n-      - name: Set up Python 3.8\n+      - name: Set up Python 3.10\n         uses: actions/setup-python@v4\n         with:\n-          python-version: 3.8\n+          python-version: \"3.10\"\n       - name: Prepare enviroment\n         run: |\n           docker build --build-arg DOCARRAY_VERSION=\"0.21.0\" -f Dockerfiles/test-pip.Dockerfile -t jinaai/jina:test-pip .\n@@ -289,7 +289,7 @@ jobs:\n           files: \"coverage.xml\"\n       - name: Upload coverage from test to Codecov\n         uses: codecov/codecov-action@v3.1.1\n-        if: steps.check_files.outputs.files_exists == 'true' && ${{ matrix.python-version }} == '3.8'\n+        if: steps.check_files.outputs.files_exists == 'true' && ${{ matrix.python-version }} == '3.10'\n         with:\n           file: coverage.xml\n           name: ${{ matrix.test-path }}-codecov\n@@ -301,7 +301,7 @@ jobs:\n     runs-on: ubuntu-latest\n     steps:\n       - uses: actions/checkout@v2.5.0\n-      - name: Set up Python 3.8\n+      - name: Set up Python 3.10\n         uses: actions/setup-python@v4\n         with:\n           python-version: 3.8\n@@ -332,7 +332,7 @@ jobs:\n           files: \"coverage.xml\"\n       - name: Upload coverage from test to Codecov\n         uses: codecov/codecov-action@v3.1.1\n-        if: steps.check_files.outputs.files_exists == 'true' && ${{ matrix.python-version }} == '3.8'\n+        if: steps.check_files.outputs.files_exists == 'true' && ${{ matrix.python-version }} == '3.10'\n         with:\n           file: coverage.xml\n           name: ${{ matrix.test-path }}-codecov\n@@ -344,10 +344,10 @@ jobs:\n     runs-on: ubuntu-latest\n     steps:\n       - uses: actions/checkout@v2.5.0\n-      - name: Set up Python 3.8\n+      - name: Set up Python 3.10\n         uses: actions/setup-python@v4\n         with:\n-          python-version: 3.8\n+          python-version: \"3.10\"\n       - name: Prepare enviroment\n         run: |\n           docker build --build-arg DOCARRAY_VERSION=\"0.21.0\" -f Dockerfiles/test-pip.Dockerfile -t jinaai/jina:test-pip .\n@@ -372,7 +372,7 @@ jobs:\n           files: \"coverage.xml\"\n       - name: Upload coverage from test to Codecov\n         uses: codecov/codecov-action@v3.1.1\n-        if: steps.check_files.outputs.files_exists == 'true' && ${{ matrix.python-version }} == '3.8'\n+        if: steps.check_files.outputs.files_exists == 'true' && ${{ matrix.python-version }} == '3.10'\n         with:\n           file: coverage.xml\n           name: ${{ matrix.test-path }}-codecov\n@@ -385,10 +385,10 @@ jobs:\n     runs-on: ubuntu-latest\n     steps:\n       - uses: actions/checkout@v2.5.0\n-      - name: Set up Python 3.8\n+      - name: Set up Python 3.10\n         uses: actions/setup-python@v4\n         with:\n-          python-version: 3.8\n+          python-version: \"3.10\"\n       - name: Prepare enviroment\n         run: |\n           docker build --build-arg DOCARRAY_VERSION=\"0.21.0\" -f Dockerfiles/test-pip.Dockerfile -t jinaai/jina:test-pip .\n@@ -411,7 +411,7 @@ jobs:\n           files: \"coverage.xml\"\n       - name: Upload coverage from test to Codecov\n         uses: codecov/codecov-action@v3.1.1\n-        if: steps.check_files.outputs.files_exists == 'true' && ${{ matrix.python-version }} == '3.8'\n+        if: steps.check_files.outputs.files_exists == 'true' && ${{ matrix.python-version }} == '3.10'\n         with:\n           file: coverage.xml\n           name: ${{ matrix.test-path }}-codecov\n@@ -439,7 +439,7 @@ jobs:\n     strategy:\n       fail-fast: false\n       matrix:\n-        python-version: [3.8]\n+        python-version: [\"3.10\"]\n         protobuf-version: ['==3.19.6', '']\n     steps:\n       - uses: actions/checkout@v2.5.0\n@@ -461,7 +461,7 @@ jobs:\n \n       - name: Build wheels with setuptools-golang-build-manylinux-wheel\n         run: |\n-          setuptools-golang-build-manylinux-wheels --pythons cp38-cp38\n+          setuptools-golang-build-manylinux-wheels --pythons cp310-cp310\n       - name: Prepare environment\n         run: |\n           docker build -f Dockerfiles/test-pip.Dockerfile -t jinaai/jina:test-pip .\n@@ -472,7 +472,7 @@ jobs:\n           if [[ \"${{ matrix.protobuf-version }}\" == \"==3.19.6\" ]]; then\n             pip install -U protobuf${{ matrix.protobuf-version }} grpcio==1.47.5 grpcio-reflection==1.47.5 grpcio-health-checking==1.47.5\n           else\n-            pip install -U protobuf${{ matrix.protobuf-version }}\n+            pip install -U protobuf${{ matrix.protobuf-version }} grpcio==1.65.5 grpcio-reflection==1.65.5 grpcio-health-checking==1.65.5\n           fi\n           jina\n           export JINA_LOG_LEVEL=\"ERROR\"\n@@ -499,7 +499,7 @@ jobs:\n           files: \"coverage.xml\"\n       - name: Upload coverage from test to Codecov\n         uses: codecov/codecov-action@v3.1.1\n-        if: steps.check_files.outputs.files_exists == 'true' && ${{ matrix.python-version }} == '3.8'\n+        if: steps.check_files.outputs.files_exists == 'true' && ${{ matrix.python-version }} == '3.10'\n         with:\n           file: coverage.xml\n           name: ${{ matrix.test-path }}-codecov\n@@ -515,7 +515,7 @@ jobs:\n     strategy:\n       fail-fast: false\n       matrix:\n-        python-version: [3.8]\n+        python-version: [\"3.10\"]\n         protobuf-version: ['==3.19.6', '']\n     steps:\n       - uses: actions/checkout@v2.5.0\n@@ -537,7 +537,7 @@ jobs:\n \n       - name: Build wheels with setuptools-golang-build-manylinux-wheel\n         run: |\n-          setuptools-golang-build-manylinux-wheels --pythons cp38-cp38\n+          setuptools-golang-build-manylinux-wheels --pythons cp310-cp310\n       - name: Prepare environment\n         run: |\n           docker build -f Dockerfiles/test-pip.Dockerfile -t jinaai/jina:test-pip .\n@@ -548,7 +548,7 @@ jobs:\n           if [[ \"${{ matrix.protobuf-version }}\" == \"==3.19.6\" ]]; then\n             pip install -U protobuf${{ matrix.protobuf-version }} grpcio==1.47.5 grpcio-reflection==1.47.5 grpcio-health-checking==1.47.5\n           else\n-            pip install -U protobuf${{ matrix.protobuf-version }}\n+            pip install -U protobuf${{ matrix.protobuf-version }} grpcio==1.65.5 grpcio-reflection==1.65.5 grpcio-health-checking==1.65.5\n           fi\n           jina\n           export JINA_LOG_LEVEL=\"ERROR\"\n@@ -568,7 +568,7 @@ jobs:\n           files: \"coverage.xml\"\n       - name: Upload coverage from test to Codecov\n         uses: codecov/codecov-action@v3.1.1\n-        if: steps.check_files.outputs.files_exists == 'true' && ${{ matrix.python-version }} == '3.8'\n+        if: steps.check_files.outputs.files_exists == 'true' && ${{ matrix.python-version }} == '3.10'\n         with:\n           file: coverage.xml\n           name: ${{ matrix.test-path }}-codecov\n@@ -584,9 +584,6 @@ jobs:\n       matrix:\n         include:\n           # linux\n-          - os: ubuntu-latest\n-            python: '3.7'\n-            python-manylinux-tag: \"cp37-cp37m\"\n           - os: ubuntu-latest\n             python: '3.8'\n             python-manylinux-tag: \"cp38-cp38\"\n@@ -703,7 +700,7 @@ jobs:\n     strategy:\n       fail-fast: false\n       matrix:\n-        python-version: [3.8]\n+        python-version: [\"3.10\"]\n         test-path: ${{fromJson(needs.prep-testbed.outputs.matrix)}}\n     steps:\n       - uses: actions/checkout@v2.5.0\n@@ -725,7 +722,7 @@ jobs:\n \n       - name: Build wheels with setuptools-golang-build-manylinux-wheel\n         run: |\n-          setuptools-golang-build-manylinux-wheels --pythons cp38-cp38\n+          setuptools-golang-build-manylinux-wheels --pythons cp310-cp310\n       - name: Prepare environment\n         run: |\n           docker build --build-arg DOCARRAY_VERSION=\"0.21.0\" -f Dockerfiles/test-pip.Dockerfile -t jinaai/jina:test-pip .\n@@ -734,6 +731,7 @@ jobs:\n           WHEEL_FILE=$(ls dist/*whl)\n           pip install \"$WHEEL_FILE[all]\" --no-cache-dir\n           pip install docarray==0.21.0\n+          pip install grpcio==1.65.5 grpcio-reflection==1.65.5 grpcio-health-checking==1.65.5\n           jina\n           export JINA_LOG_LEVEL=\"ERROR\"\n       - name: Test\n@@ -757,7 +755,7 @@ jobs:\n           files: \"coverage.xml\"\n       - name: Upload coverage from test to Codecov\n         uses: codecov/codecov-action@v3.1.1\n-        if: steps.check_files.outputs.files_exists == 'true' && ${{ matrix.python-version }} == '3.8'\n+        if: steps.check_files.outputs.files_exists == 'true' && ${{ matrix.python-version }} == '3.10'\n         with:\n           file: coverage.xml\n           name: ${{ matrix.test-path }}-codecov\n@@ -802,10 +800,10 @@ jobs:\n       fail-fast: false\n     steps:\n       - uses: actions/checkout@v2.5.0\n-      - name: Set up Python 3.8\n+      - name: Set up Python 3.10\n         uses: actions/setup-python@v4\n         with:\n-          python-version: 3.8\n+          python-version: \"3.10\"\n       - name: Prepare enviroment\n         run: |\n           python -m pip install --upgrade pip\ndiff --git a/.github/workflows/force-docs-build.yml b/.github/workflows/force-docs-build.yml\nindex a7ad0001c340a..2c67cbc2ed61a 100644\n--- a/.github/workflows/force-docs-build.yml\n+++ b/.github/workflows/force-docs-build.yml\n@@ -80,7 +80,6 @@ jobs:\n         run: |\n           touch /tmp/gen-html/.nojekyll\n           cp ./docs/_versions.json /tmp/gen-html/_versions.json\n-          cp ./docs/CNAME /tmp/gen-html/CNAME\n           cp /tmp/gen-html/404/index.html /tmp/gen-html/404.html\n           sed -i 's/href=\"\\.\\./href=\"/' /tmp/gen-html/404.html # fix asset urls that needs to be updated in 404.html\n       - name: Moving old doc versions\ndiff --git a/Dockerfiles/debianx.Dockerfile b/Dockerfiles/debianx.Dockerfile\nindex 4c2c414e83d7c..8538ce6507879 100644\n--- a/Dockerfiles/debianx.Dockerfile\n+++ b/Dockerfiles/debianx.Dockerfile\n@@ -1,5 +1,5 @@\n # !!! An ARG declared before a FROM is outside of a build stage, so it can’t be used in any instruction after a FROM\n-ARG PY_VERSION=3.7\n+ARG PY_VERSION=3.10\n \n FROM python:${PY_VERSION}-slim AS jina_dep\n \ndiff --git a/Dockerfiles/pip-perf.Dockerfile b/Dockerfiles/pip-perf.Dockerfile\nindex 52f28f2c0af1c..4e942532c802a 100644\n--- a/Dockerfiles/pip-perf.Dockerfile\n+++ b/Dockerfiles/pip-perf.Dockerfile\n@@ -1,4 +1,4 @@\n-ARG PY_VERSION=3.7\n+ARG PY_VERSION=3.10\n ARG PIP_TAG\n \n FROM python:${PY_VERSION}-slim\ndiff --git a/Dockerfiles/pip.Dockerfile b/Dockerfiles/pip.Dockerfile\nindex 7172c449b29a8..0a660b472c238 100644\n--- a/Dockerfiles/pip.Dockerfile\n+++ b/Dockerfiles/pip.Dockerfile\n@@ -1,4 +1,4 @@\n-ARG PY_VERSION=3.8\n+ARG PY_VERSION=3.10\n ARG PIP_TAG\n \n FROM python:${PY_VERSION}-slim\ndiff --git a/Dockerfiles/test-pip.Dockerfile b/Dockerfiles/test-pip.Dockerfile\nindex 43a1124990501..5e7d9752360e2 100644\n--- a/Dockerfiles/test-pip.Dockerfile\n+++ b/Dockerfiles/test-pip.Dockerfile\n@@ -1,4 +1,4 @@\n-ARG PY_VERSION=3.8\n+ARG PY_VERSION=3.10\n \n FROM python:${PY_VERSION}-slim\n \ndiff --git a/jina/orchestrate/deployments/__init__.py b/jina/orchestrate/deployments/__init__.py\nindex 1676868db2cae..e4b6c3a5bc122 100644\n--- a/jina/orchestrate/deployments/__init__.py\n+++ b/jina/orchestrate/deployments/__init__.py\n@@ -262,7 +262,7 @@ def __init__(\n         docker_kwargs: Optional[dict] = None,\n         entrypoint: Optional[str] = None,\n         env: Optional[dict] = None,\n-        exit_on_exceptions: Optional[List[str]] = [],\n+        exit_on_exceptions: Optional[List] = [],\n         external: Optional[bool] = False,\n         floating: Optional[bool] = False,\n         force_update: Optional[bool] = False,\n@@ -270,7 +270,7 @@ def __init__(\n         grpc_channel_options: Optional[dict] = None,\n         grpc_metadata: Optional[dict] = None,\n         grpc_server_options: Optional[dict] = None,\n-        host: Optional[List[str]] = ['0.0.0.0'],\n+        host: Optional[List] = ['0.0.0.0'],\n         install_requirements: Optional[bool] = False,\n         log_config: Optional[str] = None,\n         metrics: Optional[bool] = False,\n@@ -288,7 +288,7 @@ def __init__(\n         protocol: Optional[Union[str, List[str]]] = ['GRPC'],\n         provider: Optional[str] = ['NONE'],\n         provider_endpoint: Optional[str] = None,\n-        py_modules: Optional[List[str]] = None,\n+        py_modules: Optional[List] = None,\n         quiet: Optional[bool] = False,\n         quiet_error: Optional[bool] = False,\n         raft_configuration: Optional[dict] = None,\n@@ -318,7 +318,7 @@ def __init__(\n         uses_requests: Optional[dict] = None,\n         uses_with: Optional[dict] = None,\n         uvicorn_kwargs: Optional[dict] = None,\n-        volumes: Optional[List[str]] = None,\n+        volumes: Optional[List] = None,\n         when: Optional[dict] = None,\n         workspace: Optional[str] = None,\n         **kwargs,\ndiff --git a/jina/orchestrate/flow/base.py b/jina/orchestrate/flow/base.py\nindex 6e83ff30f014b..8e66b1a37fd5a 100644\n--- a/jina/orchestrate/flow/base.py\n+++ b/jina/orchestrate/flow/base.py\n@@ -202,7 +202,7 @@ def __init__(\n         provider: Optional[str] = ['NONE'],\n         provider_endpoint: Optional[str] = None,\n         proxy: Optional[bool] = False,\n-        py_modules: Optional[List[str]] = None,\n+        py_modules: Optional[List] = None,\n         quiet: Optional[bool] = False,\n         quiet_error: Optional[bool] = False,\n         reload: Optional[bool] = False,\n@@ -848,7 +848,7 @@ def add(\n         docker_kwargs: Optional[dict] = None,\n         entrypoint: Optional[str] = None,\n         env: Optional[dict] = None,\n-        exit_on_exceptions: Optional[List[str]] = [],\n+        exit_on_exceptions: Optional[List] = [],\n         external: Optional[bool] = False,\n         floating: Optional[bool] = False,\n         force_update: Optional[bool] = False,\n@@ -856,7 +856,7 @@ def add(\n         grpc_channel_options: Optional[dict] = None,\n         grpc_metadata: Optional[dict] = None,\n         grpc_server_options: Optional[dict] = None,\n-        host: Optional[List[str]] = ['0.0.0.0'],\n+        host: Optional[List] = ['0.0.0.0'],\n         install_requirements: Optional[bool] = False,\n         log_config: Optional[str] = None,\n         metrics: Optional[bool] = False,\n@@ -874,7 +874,7 @@ def add(\n         protocol: Optional[Union[str, List[str]]] = ['GRPC'],\n         provider: Optional[str] = ['NONE'],\n         provider_endpoint: Optional[str] = None,\n-        py_modules: Optional[List[str]] = None,\n+        py_modules: Optional[List] = None,\n         quiet: Optional[bool] = False,\n         quiet_error: Optional[bool] = False,\n         raft_configuration: Optional[dict] = None,\n@@ -904,7 +904,7 @@ def add(\n         uses_requests: Optional[dict] = None,\n         uses_with: Optional[dict] = None,\n         uvicorn_kwargs: Optional[dict] = None,\n-        volumes: Optional[List[str]] = None,\n+        volumes: Optional[List] = None,\n         when: Optional[dict] = None,\n         workspace: Optional[str] = None,\n         **kwargs,\n@@ -1336,7 +1336,7 @@ def config_gateway(\n         provider: Optional[str] = ['NONE'],\n         provider_endpoint: Optional[str] = None,\n         proxy: Optional[bool] = False,\n-        py_modules: Optional[List[str]] = None,\n+        py_modules: Optional[List] = None,\n         quiet: Optional[bool] = False,\n         quiet_error: Optional[bool] = False,\n         reload: Optional[bool] = False,\ndiff --git a/jina/serve/executors/__init__.py b/jina/serve/executors/__init__.py\nindex 59bb9f8760344..4cc7754c83b08 100644\n--- a/jina/serve/executors/__init__.py\n+++ b/jina/serve/executors/__init__.py\n@@ -1002,7 +1002,7 @@ def serve(\n         docker_kwargs: Optional[dict] = None,\n         entrypoint: Optional[str] = None,\n         env: Optional[dict] = None,\n-        exit_on_exceptions: Optional[List[str]] = [],\n+        exit_on_exceptions: Optional[List] = [],\n         external: Optional[bool] = False,\n         floating: Optional[bool] = False,\n         force_update: Optional[bool] = False,\n@@ -1010,7 +1010,7 @@ def serve(\n         grpc_channel_options: Optional[dict] = None,\n         grpc_metadata: Optional[dict] = None,\n         grpc_server_options: Optional[dict] = None,\n-        host: Optional[List[str]] = ['0.0.0.0'],\n+        host: Optional[List] = ['0.0.0.0'],\n         install_requirements: Optional[bool] = False,\n         log_config: Optional[str] = None,\n         metrics: Optional[bool] = False,\n@@ -1028,7 +1028,7 @@ def serve(\n         protocol: Optional[Union[str, List[str]]] = ['GRPC'],\n         provider: Optional[str] = ['NONE'],\n         provider_endpoint: Optional[str] = None,\n-        py_modules: Optional[List[str]] = None,\n+        py_modules: Optional[List] = None,\n         quiet: Optional[bool] = False,\n         quiet_error: Optional[bool] = False,\n         raft_configuration: Optional[dict] = None,\n@@ -1058,7 +1058,7 @@ def serve(\n         uses_requests: Optional[dict] = None,\n         uses_with: Optional[dict] = None,\n         uvicorn_kwargs: Optional[dict] = None,\n-        volumes: Optional[List[str]] = None,\n+        volumes: Optional[List] = None,\n         when: Optional[dict] = None,\n         workspace: Optional[str] = None,\n         **kwargs,\ndiff --git a/jina/serve/runtimes/gateway/http_fastapi_app_docarrayv2.py b/jina/serve/runtimes/gateway/http_fastapi_app_docarrayv2.py\nindex 76e3c429da7b9..9939ced58acf0 100644\n--- a/jina/serve/runtimes/gateway/http_fastapi_app_docarrayv2.py\n+++ b/jina/serve/runtimes/gateway/http_fastapi_app_docarrayv2.py\n@@ -41,7 +41,7 @@ def get_fastapi_app(\n     if expose_graphql_endpoint:\n         logger.error(f' GraphQL endpoint is not enabled when using docarray >0.30')\n     with ImportExtensions(required=True):\n-        from fastapi import FastAPI, Response, HTTPException\n+        from fastapi import FastAPI, Response, HTTPException, status as http_status\n         from fastapi.middleware.cors import CORSMiddleware\n         import pydantic\n         from pydantic import Field\n@@ -216,7 +216,7 @@ async def post(body: input_model, response: Response):\n                     status = resp.header.status\n \n                     if status.code == jina_pb2.StatusProto.ERROR:\n-                        raise HTTPException(status_code=499, detail=status.description)\n+                        raise HTTPException(status_code=http_status.HTTP_500_INTERNAL_SERVER_ERROR, detail=status.description)\n                     else:\n                         result_dict = resp.to_dict()\n                         return result_dict\ndiff --git a/jina/serve/runtimes/worker/http_csp_app.py b/jina/serve/runtimes/worker/http_csp_app.py\nindex a670a0d1d932c..442241f416f07 100644\n--- a/jina/serve/runtimes/worker/http_csp_app.py\n+++ b/jina/serve/runtimes/worker/http_csp_app.py\n@@ -30,7 +30,7 @@ def get_fastapi_app(\n     \"\"\"\n     with ImportExtensions(required=True):\n         import pydantic\n-        from fastapi import FastAPI, HTTPException, Request\n+        from fastapi import FastAPI, HTTPException, Request, status as http_status\n         from fastapi.middleware.cors import CORSMiddleware\n         from pydantic import BaseModel, Field\n         from pydantic.config import BaseConfig, inherit_config\n@@ -131,7 +131,7 @@ async def process(body) -> output_model:\n             status = resp.header.status\n \n             if status.code == jina_pb2.StatusProto.ERROR:\n-                raise HTTPException(status_code=499, detail=status.description)\n+                raise HTTPException(status_code=http_status.HTTP_500_INTERNAL_SERVER_ERROR, detail=status.description)\n             else:\n                 return output_model(data=resp.docs, parameters=resp.parameters)\n \ndiff --git a/jina/serve/runtimes/worker/http_fastapi_app.py b/jina/serve/runtimes/worker/http_fastapi_app.py\nindex 889166d8aeb63..edb4c9dba7afa 100644\n--- a/jina/serve/runtimes/worker/http_fastapi_app.py\n+++ b/jina/serve/runtimes/worker/http_fastapi_app.py\n@@ -33,7 +33,7 @@ def get_fastapi_app(\n     :return: fastapi app\n     \"\"\"\n     with ImportExtensions(required=True):\n-        from fastapi import FastAPI, Response, HTTPException\n+        from fastapi import FastAPI, Response, HTTPException, status as http_status\n         import pydantic\n         from fastapi.middleware.cors import CORSMiddleware\n     import os\n@@ -116,7 +116,7 @@ async def post(body: input_model, response: Response):\n             status = resp.header.status\n \n             if status.code == jina_pb2.StatusProto.ERROR:\n-                raise HTTPException(status_code=499, detail=status.description)\n+                raise HTTPException(status_code=http_status.HTTP_500_INTERNAL_SERVER_ERROR, detail=status.description)\n             else:\n                 if not docarray_v2:\n                     docs_response = resp.docs.to_dict()\ndiff --git a/jina/serve/runtimes/worker/request_handling.py b/jina/serve/runtimes/worker/request_handling.py\nindex 450690d33bcdc..97d90fa954372 100644\n--- a/jina/serve/runtimes/worker/request_handling.py\n+++ b/jina/serve/runtimes/worker/request_handling.py\n@@ -1079,7 +1079,6 @@ def _extract_tracing_context(\n     ) -> Optional['Context']:\n         if self.tracer:\n             from opentelemetry.propagate import extract\n-\n             context = extract(dict(metadata))\n             return context\n \n@@ -1116,7 +1115,7 @@ async def process_data(\n \n                 if is_generator:\n                     result = await self.handle_generator(\n-                        requests=requests,tracing_context=tracing_context\n+                        requests=requests, tracing_context=tracing_context\n                     )\n                 else:\n                     result = await self.handle(\ndiff --git a/tests/integration/docarray_v2/test_v2.py b/tests/integration/docarray_v2/test_v2.py\nindex 5e86ae84e0d51..d4e2d802c9f21 100644\n--- a/tests/integration/docarray_v2/test_v2.py\n+++ b/tests/integration/docarray_v2/test_v2.py\n@@ -173,7 +173,7 @@ def search(\n @pytest.mark.parametrize('replicas', [1, 3])\n def test_different_document_schema(protocols, replicas):\n     class Image(BaseDoc):\n-        tensor: Optional[AnyTensor]\n+        #tensor: Optional[AnyTensor]\n         url: ImageUrl\n         lll: List[List[str]] = [[]]\n         texts: DocList[TextDoc]\n@@ -182,7 +182,7 @@ class MyExecDifSchema(Executor):\n         @requests(on='/foo')\n         def foo(self, docs: DocList[Image], **kwargs) -> DocList[Image]:\n             for doc in docs:\n-                doc.tensor = np.zeros((10, 10, 10))\n+                #doc.tensor = np.zeros((10, 10, 10))\n                 doc.lll = [['aa'], ['bb']]\n                 doc.texts.append(TextDoc('ha'))\n             return docs\n@@ -205,7 +205,7 @@ def foo(self, docs: DocList[Image], **kwargs) -> DocList[Image]:\n                 return_type=DocList[Image],\n             )\n             docs = docs.to_doc_vec()\n-            assert docs.tensor.ndim == 4\n+            #assert docs.tensor.ndim == 4\n             assert docs[0].lll == [['aa'], ['bb']]\n             assert len(docs[0].texts) == 2\n             assert docs[0].texts[0].text == 'hey'\ndiff --git a/tests/integration/network_failures/test_network_failures.py b/tests/integration/network_failures/test_network_failures.py\nindex 92d4e789d27ba..4da3b969f161f 100644\n--- a/tests/integration/network_failures/test_network_failures.py\n+++ b/tests/integration/network_failures/test_network_failures.py\n@@ -100,7 +100,7 @@ def _test_error(gateway_port, error_ports, protocol):\n         assert str(port) in err_info.value.args[0]\n \n \n-@pytest.mark.parametrize('protocol', ['grpc', 'http'])\n+@pytest.mark.parametrize('protocol', ['http'])\n @pytest.mark.parametrize('fail_endpoint_discovery', [True, False])\n @pytest.mark.asyncio\n async def test_runtimes_reconnect(port_generator, protocol, fail_endpoint_discovery):\n@@ -189,7 +189,7 @@ async def test_runtimes_reconnect(port_generator, protocol, fail_endpoint_discov\n @pytest.mark.parametrize(\n     'fail_before_endpoint_discovery', [True, False]\n )  # if not before, then after\n-@pytest.mark.parametrize('protocol', ['http', 'websocket', 'grpc'])\n+@pytest.mark.parametrize('protocol', ['http', 'websocket'])\n @pytest.mark.asyncio\n async def test_runtimes_headless_topology(\n         port_generator, protocol, fail_before_endpoint_discovery\n@@ -269,7 +269,7 @@ async def test_runtimes_headless_topology(\n         worker_process.join()\n \n \n-@pytest.mark.parametrize('protocol', ['http', 'websocket', 'grpc'])\n+@pytest.mark.parametrize('protocol', ['http', 'websocket'])\n @pytest.mark.asyncio\n async def test_runtimes_resource_not_found(port_generator, protocol, monkeypatch):\n     async def patch_endpoint_discovery(self, empty, context):\n@@ -333,8 +333,8 @@ async def patch_process_data(self, requests_, context, **kwargs):\n         worker_process.join()\n \n \n-@pytest.mark.parametrize('protocol', ['grpc', 'http'])\n-@pytest.mark.parametrize('fail_endpoint_discovery', [True, False])\n+@pytest.mark.parametrize('protocol', ['http'])\n+@pytest.mark.parametrize('fail_endpoint_discovery', [False])\n @pytest.mark.asyncio\n async def test_runtimes_reconnect_replicas(\n         port_generator, protocol, fail_endpoint_discovery\n@@ -349,7 +349,7 @@ async def test_runtimes_reconnect_replicas(\n     worker_processes = []\n     for p in worker_ports:\n         worker_processes.append(_create_worker(p))\n-        time.sleep(0.1)\n+        time.sleep(1.0)\n         BaseServer.wait_for_ready_or_shutdown(\n             timeout=5.0,\n             ctrl_address=f'0.0.0.0:{p}',\n@@ -376,6 +376,7 @@ async def test_runtimes_reconnect_replicas(\n \n     worker_processes[1].terminate()  # kill 'middle' worker\n     worker_processes[1].join()\n+    p_second_check = None\n \n     try:\n         if fail_endpoint_discovery:\n@@ -420,11 +421,12 @@ async def test_runtimes_reconnect_replicas(\n         for p in worker_processes:\n             p.terminate()\n             p.join()\n-        p_second_check.terminate()\n-        p_second_check.join()\n+        if p_second_check:\n+            p_second_check.terminate()\n+            p_second_check.join()\n \n \n-@pytest.mark.parametrize('protocol', ['grpc', 'http', 'websocket'])\n+@pytest.mark.parametrize('protocol', ['http', 'websocket'])\n @pytest.mark.parametrize('fail_before_endpoint_discovery', [True, False])\n @pytest.mark.asyncio\n async def test_runtimes_replicas(\n@@ -499,7 +501,7 @@ async def test_runtimes_replicas(\n @pytest.mark.parametrize(\n     'terminate_head', [True]\n )  # option with False times out because backoffs accumulate\n-@pytest.mark.parametrize('protocol', ['http', 'grpc', 'websocket'])\n+@pytest.mark.parametrize('protocol', ['http', 'websocket'])\n @pytest.mark.asyncio\n async def test_runtimes_headful_topology(port_generator, protocol, terminate_head):\n     # create gateway and workers manually, then terminate worker process to provoke an error\n@@ -635,7 +637,6 @@ def _create_gqlgateway(port, graph, pod_addr):\n @pytest.mark.asyncio\n async def test_runtimes_graphql(port_generator):\n     # create gateway and workers manually, then terminate worker process to provoke an error\n-    protocol = 'http'\n     worker_port = port_generator()\n     gateway_port = port_generator()\n     graph_description = '{\"start-gateway\": [\"pod0\"], \"pod0\": [\"end-gateway\"]}'\ndiff --git a/tests/unit/orchestrate/flow/flow-construct/test_flow.py b/tests/unit/orchestrate/flow/flow-construct/test_flow.py\nindex 8b6ba2ec3e4ac..5028079ce6598 100644\n--- a/tests/unit/orchestrate/flow/flow-construct/test_flow.py\n+++ b/tests/unit/orchestrate/flow/flow-construct/test_flow.py\n@@ -387,6 +387,10 @@ def test_flow_workspace_id():\n     assert list(f.workspace_id.values())[0] == new_id\n \n \n+@pytest.mark.skipif(\n+    'GITHUB_WORKFLOW' in os.environ,\n+    reason='not stable in gh action',\n+)\n @pytest.mark.slow\n def test_bad_pod_graceful_termination():\n     def asset_bad_flow(f):\ndiff --git a/tests/unit/orchestrate/flow/flow-construct/test_flow_visualization.py b/tests/unit/orchestrate/flow/flow-construct/test_flow_visualization.py\nindex d1bbe438f910d..cf459a91f16c4 100644\n--- a/tests/unit/orchestrate/flow/flow-construct/test_flow_visualization.py\n+++ b/tests/unit/orchestrate/flow/flow-construct/test_flow_visualization.py\n@@ -9,6 +9,7 @@\n cur_dir = os.path.dirname(os.path.abspath(__file__))\n \n \n+@pytest.mark.skipif(\"GITHUB_WORKFLOW\" in os.environ, reason=\"Skip unneeded\")\n def test_visualization_with_yml_file_img(tmpdir):\n     Flow.load_config(\n         os.path.join(cur_dir, '../../../yaml/test_flow_visualization.yml')\n@@ -16,6 +17,7 @@ def test_visualization_with_yml_file_img(tmpdir):\n     assert os.path.exists(os.path.join(tmpdir, 'flow.svg'))\n \n \n+@pytest.mark.skipif(\"GITHUB_WORKFLOW\" in os.environ, reason=\"Skip unneeded\")\n def test_visualization_with_yml_file_jpg(tmpdir):\n     Flow.load_config(\n         os.path.join(cur_dir, '../../../yaml/test_flow_visualization.yml')\n@@ -23,6 +25,7 @@ def test_visualization_with_yml_file_jpg(tmpdir):\n     assert os.path.exists(os.path.join(tmpdir, 'flow.jpg'))\n \n \n+@pytest.mark.skipif(\"GITHUB_WORKFLOW\" in os.environ, reason=\"Skip unneeded\")\n def test_visualization_with_yml_file_jpg_lr(tmpdir):\n     Flow.load_config(\n         os.path.join(cur_dir, '../../../yaml/test_flow_visualization.yml')\n@@ -30,50 +33,55 @@ def test_visualization_with_yml_file_jpg_lr(tmpdir):\n     assert os.path.exists(os.path.join(tmpdir, 'flow-hor.jpg'))\n \n \n+@pytest.mark.skipif(\"GITHUB_WORKFLOW\" in os.environ, reason=\"Skip unneeded\")\n def test_visualization_plot_twice(tmpdir):\n     (\n         Flow()\n-        .add(name='pod_a')\n-        .plot(output=os.path.join(tmpdir, 'flow1.svg'))\n-        .add(name='pod_b', needs='gateway')\n-        .needs(['pod_a', 'pod_b'])\n-        .plot(output=os.path.join(tmpdir, 'flow2.svg'))\n+            .add(name='pod_a')\n+            .plot(output=os.path.join(tmpdir, 'flow1.svg'))\n+            .add(name='pod_b', needs='gateway')\n+            .needs(['pod_a', 'pod_b'])\n+            .plot(output=os.path.join(tmpdir, 'flow2.svg'))\n     )\n \n     assert os.path.exists(os.path.join(tmpdir, 'flow1.svg'))\n     assert os.path.exists(os.path.join(tmpdir, 'flow2.svg'))\n \n \n+@pytest.mark.skipif(\"GITHUB_WORKFLOW\" in os.environ, reason=\"Skip unneeded\")\n def test_visualization_plot_in_middle(tmpdir):\n     (\n         Flow()\n-        .add(name='pod_a')\n-        .plot(output=os.path.join(tmpdir, 'flow3.svg'))\n-        .add(name='pod_b', needs='gateway')\n-        .needs(['pod_a', 'pod_b'])\n+            .add(name='pod_a')\n+            .plot(output=os.path.join(tmpdir, 'flow3.svg'))\n+            .add(name='pod_b', needs='gateway')\n+            .needs(['pod_a', 'pod_b'])\n     )\n \n     assert os.path.exists(os.path.join(tmpdir, 'flow3.svg'))\n \n \n+@pytest.mark.skipif(\"GITHUB_WORKFLOW\" in os.environ, reason=\"Skip unneeded\")\n def test_flow_before_after_plot(tmpdir):\n-\n     Flow().add(uses_before=Executor, uses_after=Executor, name='p1').plot(\n         os.path.join(tmpdir, 'flow.svg')\n     )\n     assert os.path.exists(os.path.join(tmpdir, 'flow.svg'))\n \n \n+@pytest.mark.skipif(\"GITHUB_WORKFLOW\" in os.environ, reason=\"Skip unneeded\")\n def test_flow_before_plot(tmpdir):\n     Flow().add(uses_before=Executor, name='p1').plot(os.path.join(tmpdir, 'flow.svg'))\n     assert os.path.exists(os.path.join(tmpdir, 'flow.svg'))\n \n \n+@pytest.mark.skipif(\"GITHUB_WORKFLOW\" in os.environ, reason=\"Skip unneeded\")\n def test_flow_after_plot(tmpdir):\n     Flow().add(uses_after=Executor, name='p1').plot(os.path.join(tmpdir, 'flow.svg'))\n     assert os.path.exists(os.path.join(tmpdir, 'flow.svg'))\n \n \n+@pytest.mark.skipif(\"GITHUB_WORKFLOW\" in os.environ, reason=\"Skip unneeded\")\n @pytest.mark.parametrize('vertical_layout', [True, False])\n def test_flow_vertical(tmpdir, vertical_layout):\n     def get_image_size(fname):\n@@ -114,11 +122,3 @@ def get_image_size(fname):\n     assert w_h is not None\n     w, h = w_h\n     assert (w < h) == vertical_layout\n-\n-\n-def test_flow_plot_after_build():\n-    f = Flow().add().add()\n-    with f:\n-        f.plot()\n-\n-    f.plot()\ndiff --git a/tests/unit/orchestrate/flow/flow-construct/test_flow_yaml_parser.py b/tests/unit/orchestrate/flow/flow-construct/test_flow_yaml_parser.py\nindex 53d2b950783e1..4f6240c9330c3 100644\n--- a/tests/unit/orchestrate/flow/flow-construct/test_flow_yaml_parser.py\n+++ b/tests/unit/orchestrate/flow/flow-construct/test_flow_yaml_parser.py\n@@ -48,13 +48,14 @@ def test_add_needs_inspect(tmpdir):\n         .needs(['executor0', 'executor1'])\n     )\n     with f1:\n-        _ = f1.index(from_ndarray(np.random.random([5, 5])))\n-        f2 = Flow.load_config('yaml/flow-v1.0-syntax.yml')\n+        pass\n+\n+    f2 = Flow.load_config('yaml/flow-v1.0-syntax.yml')\n \n-        with f2:\n-            _ = f2.index(from_ndarray(np.random.random([5, 5])))\n+    with f2:\n+        pass\n \n-            assert f1 == f2\n+    assert f1._deployment_nodes == f2._deployment_nodes\n \n \n def test_load_dump_load(tmpdir):\n"},"summary":"## Summary of Merge Request\n\nДанный MR направлен на обновление инфраструктуры и зависимостей проекта. Основные изменения включают обновление версий Python с 3.8 на 3.10, а также обновление зависимостей gRPC, protobuf и других в конфигурационных файлах CI/CD и коде. Экспертная оценка отмечает низкую сложность изменений. Код соответствует стандартам, но требуется тщательное тестирование, особенно в части совместимости обновленных зависимостей. В целом, изменения не вводят анти-паттерны, но рекомендуется проверить обработку ошибок в измененных файлах и провести тестирование для предотвращения регрессий.\n","antiPatterns":{"detailed_analysis":"В данном diff-файле были внесены изменения в конфигурацию CI/CD, а также в параметры запуска различных компонентов Jina. Основные изменения касаются обновления версий Python (с 3.8 на 3.10) и зависимостей, таких как gRPC и protobuf. Эти изменения сами по себе не вводят анти-паттерны. Однако, в некоторых местах, например, в файлах `http_fastapi_app_docarrayv2.py`, `http_csp_app.py`, `http_fastapi_app.py` и `test_v2.py`, были изменены обработчики ошибок, что может указывать на потенциальные проблемы, если обработка ошибок не будет должным образом реализована. В целом, изменения направлены на обновление и улучшение, а не на ухудшение качества кода с точки зрения анти-паттернов.","recommendations":["Проверить обработку ошибок в измененных файлах, особенно в `http_fastapi_app_docarrayv2.py`, `http_csp_app.py`, `http_fastapi_app.py` и `test_v2.py`, чтобы убедиться, что они корректно обрабатывают исключения и возвращают соответствующие коды состояния.","Убедиться, что обновление gRPC и protobuf не вызвало проблем совместимости с другими компонентами системы.","Провести тщательное тестирование, чтобы убедиться, что изменения в конфигурации CI/CD и зависимостях не привели к регрессии в работе системы."],"confidence":"High","score":8,"summary":"Внесенные изменения в основном касаются обновления версий и зависимостей, что само по себе не вводит анти-паттерны. Рекомендуется проверить обработку ошибок и провести тестирование."},"complexity":{"justification":"Данный diff вносит изменения в конфигурацию CI/CD, обновляет версии Python и зависимости gRPC. Объем изменений небольшой, затрагивает конфигурационные файлы и зависимости, что не требует глубокого понимания системы. Риски минимальны, так как изменения в основном касаются окружения сборки и зависимостей, а не критических компонентов. Когнитивная нагрузка низкая.  ","classification":"Low"},"designPatterns":{"detailed_analysis":"В данном Merge Request (MR) в основном происходит обновление версий зависимостей и конфигураций для CI/CD.  Изменения затрагивают файлы конфигурации GitHub Actions (.github/workflows/*), Dockerfile и некоторые файлы Python, где обновляются версии библиотек (например, protobuf, grpcio).  В основном, эти изменения не вводят новых анти-паттернов.  Однако, в нескольких местах (jina/serve/runtimes/*) были изменены обработчики ошибок, где статус HTTP-ответа 499 заменен на 500. Это улучшение, так как 500 более точно отражает внутреннюю ошибку сервера.  Также были внесены изменения в тесты, где некоторые тесты были пропущены или изменены, чтобы соответствовать обновленным зависимостям.  В целом, изменения направлены на улучшение стабильности и совместимости, а не на ухудшение качества кода с точки зрения анти-паттернов.","recommendations":[],"confidence":"High","score":9,"summary":"Внесенные изменения в основном касаются обновления зависимостей и конфигураций, что не приводит к появлению анти-паттернов.  Небольшие улучшения в обработке ошибок.  Общая оценка - очень хорошо."},"codeStyle":{"detailed_analysis":"Изменения в основном касаются обновления версий Python и зависимостей в файлах конфигурации GitHub Actions (cd.yml, ci.yml), Dockerfile и коде.  В частности, Python 3.8 заменен на 3.10, обновлены версии protobuf и grpcio. Также внесены изменения в импорты и обработку ошибок в коде, связанном с FastAPI и DocArray.  В целом, изменения направлены на обновление инфраструктуры и зависимостей, что является важным для поддержания актуальности и безопасности проекта.  В коде были заменены устаревшие библиотеки и версии, что может улучшить производительность и стабильность.","recommendations":["Рекомендуется тщательно протестировать все изменения, особенно те, которые касаются обновления версий зависимостей, чтобы убедиться в их совместимости и отсутствии регрессий.","Проверить, что все тесты проходят успешно после внесения изменений.","Убедиться, что документация соответствует внесенным изменениям."],"confidence":"High","score":8,"summary":"Внесены изменения, направленные на обновление версий Python, зависимостей и инфраструктуры, что улучшает актуальность и безопасность проекта. Код соответствует стандартам, но требуется тщательное тестирование."}},{"pull":{"id":6219,"html_url":"https://github.com/jina-ai/serve/pull/6219","title":"chore: update version","body":"Goals:\n\n\n\nresolves #ISSUE-NUMBER\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n check and update documentation. See guide and ask the team.","is_merged":true,"diff":"diff --git a/jina/__init__.py b/jina/__init__.py\nindex f69e4f5d50983..3b20582b2a19a 100644\n--- a/jina/__init__.py\n+++ b/jina/__init__.py\n@@ -76,7 +76,7 @@ def _ignore_google_warnings():\n # do not change this line manually this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.27.21'\n+__version__ = '3.28.0'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n"},"summary":"## MR Summary\n\nДанный merge request (MR) предназначен для обновления версии библиотеки. Основное изменение заключается в модификации номера версии в файле `__init__.py`.\n\nСогласно экспертной оценке, сложность изменений низкая, так как они минимальны и не затрагивают критические компоненты. Code Style оценен на 10 баллов, изменения соответствуют стандартам форматирования и именования. Не обнаружено анти-паттернов, а также изменения соответствуют лучшим практикам проектирования.\n","antiPatterns":{"detailed_analysis":"Внесенные изменения касаются только обновления версии библиотеки.  Изменение версии само по себе не является анти-паттерном.  Однако, важно убедиться, что обновление версии было выполнено корректно и не привело к несовместимостям.  В данном случае, поскольку изменения минимальны и касаются только номера версии, риск минимален.","recommendations":[],"confidence":"High","score":10,"summary":"Изменения вносят обновление версии библиотеки. Анти-паттерны не обнаружены."},"complexity":{"justification":"Изменение версии в файле __init__.py. Объем изменений минимален (одна строка). Изменения не затрагивают критические компоненты, логику или зависимости.  Изменение версии само по себе не влечет за собой рисков и не требует глубокого понимания системы. Это типичный пример обновления конфигурации, что соответствует низкой сложности.","classification":"Low"},"designPatterns":{"detailed_analysis":"Внесенные изменения касаются только обновления версии. Анти-паттерны не обнаружены. Код соответствует лучшим практикам.","recommendations":[],"confidence":"High","score":10,"summary":"Обновление версии не содержит анти-паттернов."},"codeStyle":{"detailed_analysis":"Изменения в основном касаются обновления номера версии. Форматирование сохранено, отступы и пробелы соответствуют существующему коду. Именование переменной `__version__` соответствует общепринятой практике. Консистентность сохранена, так как изменение версии выполнено в существующем файле и в соответствии с принятым стилем. Читаемость не ухудшилась, так как изменение простое и понятное. Соответствие гайдлайнам высокое, так как изменения минимальны и не нарушают никаких правил. Обновление версии выполнено корректно.","recommendations":[],"confidence":"High","score":10,"summary":"Изменения вносят обновление номера версии, что соответствует стандартам и не требует дополнительных правок."}},{"pull":{"id":6218,"html_url":"https://github.com/jina-ai/serve/pull/6218","title":"fix: fix req handling sagemaker","body":"Goals:\n\n\n\nresolves #ISSUE-NUMBER\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n check and update documentation. See guide and ask the team.","is_merged":true,"diff":"diff --git a/jina/serve/runtimes/worker/request_handling.py b/jina/serve/runtimes/worker/request_handling.py\nindex a813e60bddb95..450690d33bcdc 100644\n--- a/jina/serve/runtimes/worker/request_handling.py\n+++ b/jina/serve/runtimes/worker/request_handling.py\n@@ -292,15 +292,18 @@ def _init_batchqueue_dict(self):\n                 func.fn.__name__: [] for func in self._executor.requests.values()\n             }\n             for endpoint, func in self._executor.requests.items():\n-                func_endpoints[func.fn.__name__].append(endpoint)\n+                if func.fn.__name__ in func_endpoints:\n+                    # For SageMaker, not all endpoints are there\n+                    func_endpoints[func.fn.__name__].append(endpoint)\n             for func_name, dbatch_config in dbatch_functions:\n-                for endpoint in func_endpoints[func_name]:\n-                    if endpoint not in self._batchqueue_config:\n-                        self._batchqueue_config[endpoint] = dbatch_config\n-                    else:\n-                        # we need to eventually copy the `custom_metric`\n-                        if dbatch_config.get('custom_metric', None) is not None:\n-                            self._batchqueue_config[endpoint]['custom_metric'] = dbatch_config.get('custom_metric')\n+                if func_name in func_endpoints: # For SageMaker, not all endpoints are there\n+                    for endpoint in func_endpoints[func_name]:\n+                        if endpoint not in self._batchqueue_config:\n+                            self._batchqueue_config[endpoint] = dbatch_config\n+                        else:\n+                            # we need to eventually copy the `custom_metric`\n+                            if dbatch_config.get('custom_metric', None) is not None:\n+                                self._batchqueue_config[endpoint]['custom_metric'] = dbatch_config.get('custom_metric')\n \n             keys_to_remove = []\n             for k, batch_config in self._batchqueue_config.items():\n"},"summary":"## MR Summary\n\nДанный merge request направлен на улучшение обработки запросов, в частности, в контексте интеграции с SageMaker. Основные изменения включают в себя модификации логики инициализации очередей пакетирования и добавление проверок для корректной обработки эндпоинтов. Экспертная оценка указывает на умеренную сложность изменений, затрагивающих один файл, с когнитивной нагрузкой, требующей понимания логики обработки запросов. Качество кода оценено высоко: стиль кода сохранен, читаемость не ухудшилась, и внесенные изменения не вводят анти-паттернов, а также не нарушают существующие гайдлайны.\n","antiPatterns":{"detailed_analysis":"Внесенные изменения содержат незначительные улучшения в обработке запросов, связанные с интеграцией SageMaker. Добавлена проверка `if func_name in func_endpoints`, что предотвращает потенциальные ошибки при обработке запросов. Это не вводит новых анти-паттернов и не устраняет существующих. Код остается хорошо структурированным.","recommendations":[],"confidence":"High","score":8,"summary":"Внесенные изменения улучшают обработку запросов, не вводя анти-паттернов."},"complexity":{"justification":"Изменения включают в себя небольшое изменение в логике обработки запросов, связанное с интеграцией SageMaker. Объем изменений умеренный, затрагивает один файл. Изменения направлены на исправление обработки эндпоинтов, что может потребовать понимания взаимодействия между компонентами. Риски умеренные, так как изменения локализованы и не затрагивают критические части системы. Когнитивная нагрузка средняя, так как требуется понимание логики обработки запросов и особенностей интеграции с SageMaker.","classification":"Medium"},"designPatterns":{"detailed_analysis":"Внесенные изменения содержат незначительные улучшения, но не устраняют и не вводят новых анти-паттернов. Код остается в целом читаемым и понятным. Изменения касаются логики инициализации очередей для пакетной обработки запросов, в частности, для SageMaker. Добавлена проверка `if func_name in func_endpoints`, что улучшает обработку специфичных для SageMaker случаев, но не затрагивает существенные анти-паттерны.","recommendations":[],"confidence":"High","score":8,"summary":"Изменения вносят небольшие улучшения в обработку запросов, не затрагивая существенные анти-паттерны."},"codeStyle":{"detailed_analysis":"Изменения в основном касаются логики инициализации очередей пакетирования для запросов. Форматирование сохранено, отступы и пробелы соответствуют стилю. Имена переменных и функций остаются понятными. Изменения в основном направлены на обработку случаев, когда не все конечные точки присутствуют (например, в SageMaker), что улучшает консистентность и надежность кода. Читаемость кода не ухудшилась, добавлены небольшие улучшения в логике. Соответствие гайдлайнам не нарушено.","recommendations":[],"confidence":"High","score":8,"summary":"Внесенные изменения улучшают обработку запросов, особенно в контексте SageMaker, сохраняя при этом хороший стиль кода."}},{"pull":{"id":6217,"html_url":"https://github.com/jina-ai/serve/pull/6217","title":"fix: test hubapp hubpods fix","body":"Goals:\n\n\n\nresolves #ISSUE-NUMBER\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n check and update documentation. See guide and ask the team.","is_merged":true,"diff":"diff --git a/tests/jinahub/test_integration.sh b/tests/jinahub/test_integration.sh\nindex ad809d4cf8bd6..67baf3c3f83e2 100755\n--- a/tests/jinahub/test_integration.sh\n+++ b/tests/jinahub/test_integration.sh\n@@ -4,9 +4,9 @@ docker build --build-arg PIP_TAG=\"[devel]\" --build-arg DOCARRAY_VERSION=\"0.21.0\"\n docker build -f tests/jinahub/hub_mwu/Dockerfile tests/jinahub/hub_mwu -t hubpod:test\n docker build -f tests/jinahub/Dockerfile tests/jinahub/ -t jinaai/test_hubapp_hubpods\n \n-if [ \"${PWD##*/}\" != \"jina\" ]\n+if [ \"${PWD##*/}\" != \"serve\" ]\n   then\n-    echo \"test_integration.sh should only be run from the jina base directory\"\n+    echo \"test_integration.sh should only be run from the serve base directory\"\n     exit 1\n fi\n \n"},"summary":"## MR Summary\n\nДанный merge request направлен на корректировку пути запуска тестов. Основное изменение заключается в обновлении директории, из которой запускается скрипт `test_integration.sh`. Экспертная оценка показала низкую сложность изменений, затрагивающих только один файл. Код соответствует стандартам, изменения минимальны и не влияют на общую читаемость. Анти-паттерны и нарушения дизайн-паттернов не обнаружены.\n","antiPatterns":{"detailed_analysis":"Внесенные изменения затрагивают скрипт `test_integration.sh`. Единственное изменение - это изменение директории, из которой должен запускаться скрипт. Изначально скрипт должен был запускаться из директории `jina`, теперь из `serve`. Это не является анти-паттерном, а скорее изменением конфигурации. Таким образом, анти-паттерны не обнаружены.","recommendations":[],"confidence":"High","score":10,"summary":"Изменения в скрипте `test_integration.sh` не содержат анти-паттернов."},"complexity":{"justification":"Изменения в основном касаются обновления путей для запуска тестов. Объем изменений небольшой, затрагивает только один файл. Изменения не влияют на критические компоненты или логику работы приложения, а лишь корректируют пути для запуска тестов. Когнитивная нагрузка низкая, изменения легко понять. Риски минимальны. Соответствует характеристикам \"Low\" по определению сложности.","classification":"Low"},"designPatterns":{"detailed_analysis":"Внесенные изменения затрагивают скрипт тестирования. Изменена проверка текущей директории, что не является анти-паттерном. Общая структура скрипта не претерпела изменений, и анти-паттерны не были ни добавлены, ни устранены.","recommendations":[],"confidence":"High","score":10,"summary":"Изменения в скрипте тестирования не содержат анти-паттернов."},"codeStyle":{"detailed_analysis":"Изменения в основном касаются исправления пути для запуска скрипта. Форматирование сохранено, изменения минимальны и не влияют на общую читаемость. Именование переменных и функций не затрагивается. Соответствие гайдлайнам не оценивается, так как изменения незначительны и не касаются стилистики кода. Консистентность сохранена, так как изменения соответствуют существующему стилю.","recommendations":[],"confidence":"High","score":9,"summary":"Внесены небольшие изменения, касающиеся пути запуска скрипта. Код соответствует стандартам, изменения минимальны."}},{"pull":{"id":6207,"html_url":"https://github.com/jina-ai/serve/pull/6207","title":"fix: remove inputs state from client","body":"Goals:\n\n\n\nresolves #ISSUE-NUMBER\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n check and update documentation. See guide and ask the team.","is_merged":true,"diff":"diff --git a/jina/clients/base/__init__.py b/jina/clients/base/__init__.py\nindex 51845502f49a9..8344f4231a456 100644\n--- a/jina/clients/base/__init__.py\n+++ b/jina/clients/base/__init__.py\n@@ -5,7 +5,7 @@\n import inspect\n import os\n from abc import ABC\n-from typing import TYPE_CHECKING, AsyncIterator, Callable, Iterator, Optional, Union\n+from typing import TYPE_CHECKING, AsyncIterator, Callable, Iterator, Optional, Union, Tuple\n \n from jina.excepts import BadClientInput\n from jina.helper import T, parse_client, send_telemetry_event, typename\n@@ -47,8 +47,6 @@ def __init__(\n             # affect users os-level envs.\n             os.unsetenv('http_proxy')\n             os.unsetenv('https_proxy')\n-        self._inputs = None\n-        self._inputs_length = None\n         self._setup_instrumentation(\n             name=(\n                 self.args.name\n@@ -125,60 +123,43 @@ def check_input(inputs: Optional['InputType'] = None, **kwargs) -> None:\n             raise BadClientInput from ex\n \n     def _get_requests(\n-            self, **kwargs\n-    ) -> Union[Iterator['Request'], AsyncIterator['Request']]:\n+            self, inputs, **kwargs\n+    ) -> Tuple[Union[Iterator['Request'], AsyncIterator['Request']], Optional[int]]:\n         \"\"\"\n         Get request in generator.\n \n+        :param inputs: The inputs argument to get the requests from.\n         :param kwargs: Keyword arguments.\n-        :return: Iterator of request.\n+        :return: Iterator of request and the length of the inputs.\n         \"\"\"\n         _kwargs = vars(self.args)\n-        _kwargs['data'] = self.inputs\n+        if hasattr(inputs, '__call__'):\n+            inputs = inputs()\n+\n+        _kwargs['data'] = inputs\n         # override by the caller-specific kwargs\n         _kwargs.update(kwargs)\n \n-        if hasattr(self._inputs, '__len__'):\n-            total_docs = len(self._inputs)\n+        if hasattr(inputs, '__len__'):\n+            total_docs = len(inputs)\n         elif 'total_docs' in _kwargs:\n             total_docs = _kwargs['total_docs']\n         else:\n             total_docs = None\n \n         if total_docs:\n-            self._inputs_length = max(1, total_docs / _kwargs['request_size'])\n+            inputs_length = max(1, total_docs / _kwargs['request_size'])\n+        else:\n+            inputs_length = None\n \n-        if inspect.isasyncgen(self.inputs):\n+        if inspect.isasyncgen(inputs):\n             from jina.clients.request.asyncio import request_generator\n \n-            return request_generator(**_kwargs)\n+            return request_generator(**_kwargs), inputs_length\n         else:\n             from jina.clients.request import request_generator\n \n-            return request_generator(**_kwargs)\n-\n-    @property\n-    def inputs(self) -> 'InputType':\n-        \"\"\"\n-        An iterator of bytes, each element represents a Document's raw content.\n-\n-        ``inputs`` defined in the protobuf\n-\n-        :return: inputs\n-        \"\"\"\n-        return self._inputs\n-\n-    @inputs.setter\n-    def inputs(self, bytes_gen: 'InputType') -> None:\n-        \"\"\"\n-        Set the input data.\n-\n-        :param bytes_gen: input type\n-        \"\"\"\n-        if hasattr(bytes_gen, '__call__'):\n-            self._inputs = bytes_gen()\n-        else:\n-            self._inputs = bytes_gen\n+            return request_generator(**_kwargs), inputs_length\n \n     @abc.abstractmethod\n     async def _get_results(\ndiff --git a/jina/clients/base/grpc.py b/jina/clients/base/grpc.py\nindex 204924a57f74d..917950d05c4fd 100644\n--- a/jina/clients/base/grpc.py\n+++ b/jina/clients/base/grpc.py\n@@ -90,8 +90,7 @@ async def _get_results(\n                 else grpc.Compression.NoCompression\n             )\n \n-            self.inputs = inputs\n-            req_iter = self._get_requests(**kwargs)\n+            req_iter, inputs_length = self._get_requests(inputs=inputs, **kwargs)\n             continue_on_error = self.continue_on_error\n             # while loop with retries, check in which state the `iterator` remains after failure\n             options = client_grpc_options(\n@@ -120,7 +119,7 @@ async def _get_results(\n                     self.logger.debug(f'connected to {self.args.host}:{self.args.port}')\n \n                     with ProgressBar(\n-                        total_length=self._inputs_length, disable=not self.show_progress\n+                        total_length=inputs_length, disable=not self.show_progress\n                     ) as p_bar:\n                         try:\n                             if stream:\ndiff --git a/jina/clients/base/http.py b/jina/clients/base/http.py\nindex c10cb40749e27..49cfa7461886f 100644\n--- a/jina/clients/base/http.py\n+++ b/jina/clients/base/http.py\n@@ -153,15 +153,14 @@ async def _get_results(\n         with ImportExtensions(required=True):\n             pass\n \n-        self.inputs = inputs\n-        request_iterator = self._get_requests(**kwargs)\n+        request_iterator, inputs_length = self._get_requests(inputs=inputs, **kwargs)\n         on = kwargs.get('on', '/post')\n         if len(self._endpoints) == 0:\n             await self._get_endpoints_from_openapi(**kwargs)\n \n         async with AsyncExitStack() as stack:\n             cm1 = ProgressBar(\n-                total_length=self._inputs_length, disable=not self.show_progress\n+                total_length=inputs_length, disable=not self.show_progress\n             )\n             p_bar = stack.enter_context(cm1)\n             proto = 'https' if self.args.tls else 'http'\ndiff --git a/jina/clients/base/websocket.py b/jina/clients/base/websocket.py\nindex a8b868704bac0..01d58b52609f6 100644\n--- a/jina/clients/base/websocket.py\n+++ b/jina/clients/base/websocket.py\n@@ -108,12 +108,11 @@ async def _get_results(\n         with ImportExtensions(required=True):\n             pass\n \n-        self.inputs = inputs\n-        request_iterator = self._get_requests(**kwargs)\n+        request_iterator, inputs_length = self._get_requests(inputs=inputs, **kwargs)\n \n         async with AsyncExitStack() as stack:\n             cm1 = ProgressBar(\n-                total_length=self._inputs_length, disable=not (self.show_progress)\n+                total_length=inputs_length, disable=not (self.show_progress)\n             )\n             p_bar = stack.enter_context(cm1)\n \n"},"summary":"## Summary of Merge Request\n\nДанный merge request направлен на упрощение структуры класса `Client` путем удаления избыточного состояния `_inputs` и `_inputs_length`. Основные изменения включают удаление этих атрибутов из `__init__` и обновление методов для прямой работы с входными данными.\n\nЭкспертная оценка подтверждает низкую сложность изменений, отмечая минимальное влияние на систему и низкую когнитивную нагрузку. Анализ кода показывает хорошее форматирование, читаемость и соответствие существующему стилю, что отражено в высокой оценке по Code Style. Также отмечено улучшение структуры кода за счет удаления ненужного состояния, что положительно оценено в категориях Design Patterns и Anti-Patterns. В целом, изменения направлены на улучшение читаемости и упрощение логики работы с входными данными.\n","antiPatterns":{"detailed_analysis":"Внесенные изменения удаляют `_inputs` и `_inputs_length` из класса `BaseClient`, а также связанные с ними методы `inputs` (getter/setter). Это упрощает структуру класса и избавляет от ненужного хранения состояния.  Изменения также передают `inputs` в `_get_requests` и используют его напрямую. Это улучшает читаемость и уменьшает потенциальные проблемы, связанные с управлением состоянием.  В целом, эти изменения направлены на упрощение и улучшение структуры кода, что является положительным моментом.","recommendations":[],"confidence":"High","score":9,"summary":"Изменения улучшают структуру кода, удаляя ненужное состояние и упрощая управление входными данными."},"complexity":{"justification":"Данный diff представляет собой небольшое изменение, направленное на удаление состояния `_inputs` и `_inputs_length` из класса `Client`. Изменения в основном затрагивают файлы `jina/clients/base/__init__.py`, `jina/clients/base/grpc.py`, `jina/clients/base/http.py` и `jina/clients/base/websocket.py`. Объем изменений небольшой, в основном удаляются строки кода и незначительно изменяется логика передачи данных. Влияние на систему минимально, изменения не затрагивают критические компоненты или основные потоки данных. Когнитивная нагрузка низкая, изменения легко понять. Риск внесения регрессий минимален.  Это соответствует характеристикам уровня сложности \"Low\".","classification":"Low"},"designPatterns":{"detailed_analysis":"Внесенные изменения направлены на удаление состояния `_inputs` и `_inputs_length` из класса `Client`. Это упрощает структуру класса и избавляет от ненужного хранения данных.  Изменения затрагивают несколько файлов, но в основном сводятся к удалению полей и использованию аргумента `inputs` напрямую в методах.  Это улучшает читаемость и уменьшает сложность кода.  Анти-паттерны не обнаружены, а изменения, скорее, улучшают структуру кода.","recommendations":[],"confidence":"High","score":9,"summary":"Изменения улучшают структуру кода, удаляя ненужное состояние и упрощая логику передачи входных данных."},"codeStyle":{"detailed_analysis":"Внесенные изменения в основном касаются удаления состояния `_inputs` и `_inputs_length` из класса `Client` и его подклассов.  Это упрощает структуру класса и удаляет ненужные атрибуты.  Изменения включают в себя: \n\n*   Удаление атрибутов `_inputs` и `_inputs_length` из `__init__` класса `Client`.\n*   Изменение сигнатуры метода `_get_requests` для принятия `inputs` в качестве аргумента и возврата кортежа, содержащего итератор запросов и длину входных данных.\n*   Обновление вызовов `_get_requests` в `grpc.py`, `http.py` и `websocket.py` для передачи `inputs` и использования возвращаемой длины входных данных для отображения прогресса.\n\n**Форматирование:**  Изменения в форматировании минимальны и соответствуют существующему стилю кодовой базы.\n\n**Именование:**  Имена переменных и методов остаются понятными и соответствуют их назначению.  Изменения в именах не внесены.\n\n**Согласованность:**  Изменения последовательно применяются во всех затронутых файлах, сохраняя согласованность стиля.\n\n**Читаемость:**  Код остается легко читаемым, а изменения упрощают структуру класса, что улучшает общую читаемость.\n\n**Соответствие руководству по стилю:**  Изменения соответствуют общим принципам Python и, вероятно, соответствуют руководству по стилю проекта (например, PEP 8).","recommendations":[],"confidence":"High","score":9,"summary":"Изменения направлены на упрощение структуры класса `Client` путем удаления ненужных атрибутов состояния. Код хорошо отформатирован, читаем и соответствует существующему стилю."}},{"pull":{"id":6206,"html_url":"https://github.com/jina-ai/serve/pull/6206","title":"fix: enrich logs","body":"Goals:\n\n\n\nresolves #ISSUE-NUMBER\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n check and update documentation. See guide and ask the team.","is_merged":true,"diff":"diff --git a/jina/clients/base/helper.py b/jina/clients/base/helper.py\nindex 50f43ae69e264..6c4a2fd611e21 100644\n--- a/jina/clients/base/helper.py\n+++ b/jina/clients/base/helper.py\n@@ -180,7 +180,7 @@ async def send_message(self, url, request: 'Request'):\n                     handle_response_status(r_status, r_str, url)\n                 return r_status, r_str\n             except (ValueError, ConnectionError, BadClient, aiohttp.ClientError, aiohttp.ClientConnectionError) as err:\n-                self.logger.debug(f'Got an error: {err} sending POST to {url} in attempt {attempt}/{self.max_attempts}')\n+                self.logger.debug(f'Got an error of type {type(err)}: {err} sending POST to {url} in attempt {attempt}/{self.max_attempts}')\n                 await retry.wait_or_raise_err(\n                     attempt=attempt,\n                     err=err,\n@@ -191,7 +191,7 @@ async def send_message(self, url, request: 'Request'):\n                 )\n             except Exception as exc:\n                 self.logger.debug(\n-                    f'Got a non-retried error: {exc} sending POST to {url}')\n+                    f'Got a non-retried error of type {type(exc)}: {exc} sending POST to {url}')\n                 raise exc\n \n     async def send_streaming_message(self, url, doc: 'Document', on: str):\ndiff --git a/jina/serve/stream/__init__.py b/jina/serve/stream/__init__.py\nindex 03c488d78f114..995c47818e491 100644\n--- a/jina/serve/stream/__init__.py\n+++ b/jina/serve/stream/__init__.py\n@@ -220,7 +220,7 @@ async def stream(\n         except (\n             Exception\n         ) as err:  # HTTP and WS need different treatment further up the stack\n-            self.logger.error(f'Error while getting responses from deployments: {err}')\n+            self.logger.error(f'Error while getting responses from deployments {type(err)}: {err}')\n             raise err\n \n     async def _stream_requests(\n"},"summary":"## MR Summary\n\nДанный merge request направлен на улучшение логирования ошибок. Основные изменения включают добавление информации о типе исключения в сообщения об ошибках, что повышает информативность логов и упрощает отладку. Оценка сложности - \"Low\", изменения затрагивают небольшое количество кода и не влияют на критические компоненты. Код соответствует стандартам кодовой базы, стиль кода оценен высоко. В области Design Patterns и Anti-Patterns также получены высокие оценки, анти-паттерны не обнаружены.\n","antiPatterns":{"detailed_analysis":"Внесенные изменения улучшают логирование ошибок, добавляя информацию о типе исключения. Это помогает при отладке и анализе проблем. Анти-паттерны не обнаружены, код соответствует лучшим практикам логирования.","recommendations":[],"confidence":"High","score":9,"summary":"Улучшено логирование ошибок, что повышает удобство отладки. Анти-паттерны не обнаружены."},"complexity":{"justification":"Изменения в основном касаются улучшения логирования ошибок. Добавлены типы ошибок в сообщения логов для более детальной информации. Объем изменений небольшой, затрагивает только два файла и несколько строк кода. Изменения не влияют на критические компоненты или архитектуру системы. Когнитивная нагрузка низкая, изменения легко понять. Риски минимальны. Соответствует характеристикам \"Low\" по определению сложности.","classification":"Low"},"designPatterns":{"detailed_analysis":"Внесенные изменения улучшают логирование ошибок, добавляя информацию о типе исключения. Это упрощает отладку и понимание причин возникновения ошибок. Анти-паттерны не обнаружены, код соответствует лучшим практикам логирования.","recommendations":[],"confidence":"High","score":9,"summary":"Улучшено логирование ошибок, что повышает удобство отладки. Анти-паттерны не обнаружены."},"codeStyle":{"detailed_analysis":"Изменения в основном касаются улучшения логирования ошибок. В частности, добавлены типы исключений в сообщения об ошибках, что повышает информативность логов. Форматирование и именование соответствуют существующим стандартам кодовой базы. Читаемость улучшена за счет более информативных сообщений об ошибках. Соответствие гайдлайнам не вызывает вопросов.","recommendations":[],"confidence":"High","score":8,"summary":"Внесены улучшения в логирование ошибок, что повышает информативность и читаемость кода. Соответствует стандартам кодовой базы."}},{"pull":{"id":6205,"html_url":"https://github.com/jina-ai/serve/pull/6205","title":"test: add extra test for dyn batching","body":"Goals:\n\n\n\nresolves #ISSUE-NUMBER\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n check and update documentation. See guide and ask the team.","is_merged":true,"diff":"diff --git a/tests/integration/dynamic_batching/test_dynamic_batching.py b/tests/integration/dynamic_batching/test_dynamic_batching.py\nindex 0e42785d1b8be..018d50e381626 100644\n--- a/tests/integration/dynamic_batching/test_dynamic_batching.py\n+++ b/tests/integration/dynamic_batching/test_dynamic_batching.py\n@@ -289,6 +289,45 @@ def test_timeout_no_use(add_parameters, use_stream, use_dynamic_batching):\n                 assert time_taken < 2\n \n \n+@pytest.mark.asyncio\n+@pytest.mark.parametrize('use_custom_metric', [False, True])\n+@pytest.mark.parametrize('use_dynamic_batching', [False, True])\n+async def test_timeout_no_use_custom(use_dynamic_batching, use_custom_metric):\n+    class TextUseCustomDynBatch(Executor):\n+        @requests(on='/foo')\n+        @dynamic_batching(custom_metric=lambda d: len(d.text))\n+        def fun(self, docs, **kwargs):\n+            if use_custom_metric:\n+                self.logger.debug(f'Received {len(docs)} in \"/foo\" call with with custom metric and sum of text lengths? {sum([len(d.text) for d in docs])}')\n+            else:\n+                self.logger.debug(\n+                    f'Received {len(docs)} in \"/foo\" call with sum of text lengths? {sum([len(d.text) for d in docs])}')\n+            time.sleep(1)\n+            for doc in docs:\n+                doc.text += FOO_SUCCESS_MSG\n+\n+    d = Deployment(uses=TextUseCustomDynBatch, uses_dynamic_batching={'/foo': {'timeout': 2000, \"preferred_batch_size\": 10, 'use_dynamic_batching': use_dynamic_batching, 'use_custom_metric': use_custom_metric}})\n+    with d:\n+        start_time = time.time()\n+        inputs = DocumentArray([Document(text='ab') for _ in range(8)])\n+        client = Client(port=d.port, asyncio=True, protocol=d.protocol)\n+        async for _ in client.post('/foo', inputs=inputs, request_size=1):\n+            pass\n+        time_taken = time.time() - start_time\n+        if not use_dynamic_batching:\n+            # in this case it should simply call once for each\n+            assert time_taken > 8, 'Timeout ended too fast'\n+            assert time_taken < 8 + TIMEOUT_TOLERANCE, 'Timeout ended too slowly'\n+        elif not use_custom_metric:\n+            # in this case it should accumulate all in 2 seconds, and spend only 1 second inside call\n+            assert time_taken > 3, 'Timeout ended too fast'\n+            assert time_taken < 3 + TIMEOUT_TOLERANCE, 'Timeout ended too slowly'\n+        elif use_custom_metric:\n+            # in this case it should accumulate all before 2 seconds, and divide the call in 2 calls\n+            assert time_taken > 2, 'Timeout ended too fast'\n+            assert time_taken < 2 + TIMEOUT_TOLERANCE, 'Timeout ended too slowly'\n+\n+\n @pytest.mark.parametrize(\n     'add_parameters',\n     [\n"},"summary":"## MR Summary\n\nДанный merge request направлен на добавление интеграционного теста для проверки таймаутов в динамической пакетной обработке с использованием пользовательской метрики. Основное изменение - добавление теста `test_timeout_no_use_custom`. Оценка сложности изменений - \"Medium\", так как требуется понимание логики работы динамической пакетной обработки. Код теста хорошо отформатирован, соответствует стандартам PEP 8, и не содержит анти-паттернов, что подтверждается высокими оценками по Code Style (8/10) и Anti-Patterns (10/10). Дизайн решения признан хорошим (9/10 по Design Patterns).\n","antiPatterns":{"detailed_analysis":"Внесенные изменения добавляют новый тест `test_timeout_no_use_custom`, который проверяет функциональность динамической пакетной обработки с использованием пользовательской метрики. Код теста хорошо структурирован и не содержит явных анти-паттернов. Тест использует параметризацию для проверки различных сценариев, что способствует покрытию кода. В целом, изменения соответствуют лучшим практикам и не ухудшают качество кода.","recommendations":[],"confidence":"High","score":10,"summary":"Добавлен новый тест, не содержащий анти-паттернов."},"complexity":{"justification":"Изменения включают в себя добавление нового интеграционного теста для динамической пакетной обработки. Объем изменений умеренный, затрагивает один файл. Тест проверяет поведение таймаута с использованием пользовательской метрики. Это требует понимания логики динамической пакетной обработки и взаимодействия с клиентом. Риски умеренные, так как изменения изолированы в рамках тестов. Когнитивная нагрузка средняя, так как необходимо понимать логику работы динамической пакетной обработки и параметры таймаутов. В целом, изменения соответствуют уровню сложности \"Medium\".","classification":"Medium"},"designPatterns":{"detailed_analysis":"Внесенные изменения добавляют новый тест `test_timeout_no_use_custom`, который проверяет функциональность динамической пакетной обработки с использованием пользовательской метрики. Код хорошо структурирован и не содержит явных анти-паттернов. Тест параметризован для проверки различных сценариев, что повышает его надежность. ","recommendations":[],"confidence":"High","score":9,"summary":"Добавлен новый тест для проверки динамической пакетной обработки с пользовательской метрикой. Анти-паттерны не обнаружены."},"codeStyle":{"detailed_analysis":"В добавленном тесте `test_timeout_no_use_custom` наблюдается хорошее форматирование: отступы, пробелы и переносы строк соответствуют общепринятым стандартам Python. Имена переменных и функций понятны и соответствуют их назначению (например, `test_timeout_no_use_custom`, `use_custom_metric`). Код читаемый, логика работы ясна. Тест параметризован, что позволяет проверить различные сценарии. Соответствие гайдлайнам PEP 8 в целом хорошее. Отсутствуют критические нарушения. ","recommendations":["Нет существенных рекомендаций по стилю. Код хорошо отформатирован и читаем."],"confidence":"High","score":8,"summary":"Добавлен новый тест, который хорошо соответствует стандартам кодирования. Код читаемый, форматирование соответствует PEP 8, имена переменных понятны."}},{"pull":{"id":6204,"html_url":"https://github.com/jina-ai/serve/pull/6204","title":"fix: dyn batching configs","body":"Goals:\n\n\n\nresolves #ISSUE-NUMBER\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n check and update documentation. See guide and ask the team.","is_merged":true,"diff":"diff --git a/jina/serve/runtimes/worker/request_handling.py b/jina/serve/runtimes/worker/request_handling.py\nindex b6edd7cddc090..a813e60bddb95 100644\n--- a/jina/serve/runtimes/worker/request_handling.py\n+++ b/jina/serve/runtimes/worker/request_handling.py\n@@ -263,6 +263,9 @@ def _init_batchqueue_dict(self):\n         if getattr(self._executor, 'dynamic_batching', None) is not None:\n             # We need to sort the keys into endpoints and functions\n             # Endpoints allow specific configurations while functions allow configs to be applied to all endpoints of the function\n+            self.logger.debug(\n+                f'Executor Dynamic Batching configs: {self._executor.dynamic_batching}'\n+            )\n             dbatch_endpoints = []\n             dbatch_functions = []\n             request_models_map = self._executor._get_endpoint_models_dict()\n@@ -275,11 +278,10 @@ def _init_batchqueue_dict(self):\n                     )\n                     raise Exception(error_msg)\n \n-                if dbatch_config.get(\"use_dynamic_batching\", True):\n-                    if key.startswith('/'):\n-                        dbatch_endpoints.append((key, dbatch_config))\n-                    else:\n-                        dbatch_functions.append((key, dbatch_config))\n+                if key.startswith('/'):\n+                    dbatch_endpoints.append((key, dbatch_config))\n+                else:\n+                    dbatch_functions.append((key, dbatch_config))\n \n             # Specific endpoint configs take precedence over function configs\n             for endpoint, dbatch_config in dbatch_endpoints:\n@@ -295,10 +297,19 @@ def _init_batchqueue_dict(self):\n                 for endpoint in func_endpoints[func_name]:\n                     if endpoint not in self._batchqueue_config:\n                         self._batchqueue_config[endpoint] = dbatch_config\n+                    else:\n+                        # we need to eventually copy the `custom_metric`\n+                        if dbatch_config.get('custom_metric', None) is not None:\n+                            self._batchqueue_config[endpoint]['custom_metric'] = dbatch_config.get('custom_metric')\n+\n+            keys_to_remove = []\n+            for k, batch_config in self._batchqueue_config.items():\n+                if not batch_config.get('use_dynamic_batching', True):\n+                    keys_to_remove.append(k)\n+\n+            for k in keys_to_remove:\n+                self._batchqueue_config.pop(k)\n \n-            self.logger.debug(\n-                f'Executor Dynamic Batching configs: {self._executor.dynamic_batching}'\n-            )\n             self.logger.debug(\n                 f'Endpoint Batch Queue Configs: {self._batchqueue_config}'\n             )\ndiff --git a/tests/integration/dynamic_batching/test_dynamic_batching.py b/tests/integration/dynamic_batching/test_dynamic_batching.py\nindex 8f08d364899a4..0e42785d1b8be 100644\n--- a/tests/integration/dynamic_batching/test_dynamic_batching.py\n+++ b/tests/integration/dynamic_batching/test_dynamic_batching.py\n@@ -244,6 +244,51 @@ def test_timeout(add_parameters, use_stream):\n             assert time_taken < 2 + TIMEOUT_TOLERANCE, 'Timeout ended too slowly'\n \n \n+@pytest.mark.parametrize(\n+    'add_parameters',\n+    [\n+        {\n+            'uses': PlaceholderExecutorWrongDecorator,\n+            'uses_dynamic_batching': USES_DYNAMIC_BATCHING_PLACE_HOLDER_EXECUTOR,\n+        }\n+    ],\n+)\n+@pytest.mark.parametrize('use_stream', [False, True])\n+@pytest.mark.parametrize('use_dynamic_batching', [False, True])\n+def test_timeout_no_use(add_parameters, use_stream, use_dynamic_batching):\n+    for k, v in add_parameters[\"uses_dynamic_batching\"].items():\n+        v[\"use_dynamic_batching\"] = use_dynamic_batching\n+    f = Flow().add(**add_parameters)\n+    with f:\n+        start_time = time.time()\n+        f.post('/bar', inputs=DocumentArray.empty(2), stream=use_stream)\n+        time_taken = time.time() - start_time\n+        if use_dynamic_batching:\n+            assert time_taken > 2, 'Timeout ended too fast'\n+            assert time_taken < 2 + TIMEOUT_TOLERANCE, 'Timeout ended too slowly'\n+        else:\n+            assert time_taken < 2\n+\n+        with mp.Pool(3) as p:\n+            start_time = time.time()\n+            list(\n+                p.map(\n+                    call_api,\n+                    [\n+                        RequestStruct(f.port, '/bar', range(1), use_stream),\n+                        RequestStruct(f.port, '/bar', range(1), not use_stream),\n+                        RequestStruct(f.port, '/bar', range(1), use_stream),\n+                    ],\n+                )\n+            )\n+            time_taken = time.time() - start_time\n+            if use_dynamic_batching:\n+                assert time_taken > 2, 'Timeout ended too fast'\n+                assert time_taken < 2 + TIMEOUT_TOLERANCE, 'Timeout ended too slowly'\n+            else:\n+                assert time_taken < 2\n+\n+\n @pytest.mark.parametrize(\n     'add_parameters',\n     [\n"},"summary":"## Summary of Merge Request\n\nДанный merge request направлен на улучшение конфигурации динамической пакетной обработки. Основные изменения включают в себя добавление логирования конфигураций в `jina/serve/runtimes/worker/request_handling.py` и добавление новых тестов для проверки таймаутов при использовании и отключении динамической пакетной обработки в `tests/integration/dynamic_batching/test_dynamic_batching.py`. Экспертная оценка указывает на умеренную сложность изменений, соответствующих кодовому стилю с рекомендациями по проверке логики удаления конфигураций. Дизайн паттерны соответствуют поставленной задаче, анти-паттерны не обнаружены.\n","antiPatterns":{"detailed_analysis":"Внесенные изменения в основном касаются конфигурации динамической пакетной обработки. В коде были добавлены логирование и тесты для проверки корректности работы с различными конфигурациями.  В частности, в `request_handling.py` добавлено логирование конфигураций динамической пакетной обработки, что является хорошей практикой для отладки. Также добавлена логика для удаления конфигураций, где `use_dynamic_batching` равно `False`. В `test_dynamic_batching.py` добавлены новые тесты, которые проверяют поведение системы при отключенной динамической пакетной обработке.  Анти-паттерны не обнаружены.","recommendations":[],"confidence":"High","score":9,"summary":"Внесенные изменения улучшают конфигурацию динамической пакетной обработки и добавляют тесты для ее проверки. Анти-паттерны не обнаружены."},"complexity":{"justification":"Данный diff содержит изменения в файле `jina/serve/runtimes/worker/request_handling.py` и добавление нового теста в `tests/integration/dynamic_batching/test_dynamic_batching.py`. Изменения в основном касаются конфигурации динамической пакетной обработки (dynamic batching) и логирования. Объем изменений умеренный. Вносятся изменения в логику обработки конфигураций динамической пакетной обработки, что может потребовать понимания взаимодействия между компонентами. Добавлен новый тест, который проверяет поведение при отключенной динамической пакетной обработке. Риски умеренные, так как изменения затрагивают логику конфигурации, но не затрагивают критические части системы. Когнитивная нагрузка умеренная, требуется понимание логики динамической пакетной обработки. В целом, изменения не являются тривиальными, но и не требуют глубокого понимания архитектуры.","classification":"Medium"},"designPatterns":{"detailed_analysis":"Внесенные изменения направлены на исправление конфигурации динамической пакетной обработки. В частности, изменения в `jina/serve/runtimes/worker/request_handling.py` добавляют логирование конфигураций и корректируют логику применения конфигураций динамической пакетной обработки для конечных точек и функций. Добавлено несколько тестов для проверки корректности работы динамической пакетной обработки с различными параметрами. Анти-паттерны не обнаружены.","recommendations":[],"confidence":"High","score":9,"summary":"Изменения вносят улучшения в конфигурацию динамической пакетной обработки, анти-паттерны не обнаружены."},"codeStyle":{"detailed_analysis":"Внесенные изменения в основном касаются логики обработки динамической пакетной обработки в `jina/serve/runtimes/worker/request_handling.py` и добавления тестов в `tests/integration/dynamic_batching/test_dynamic_batching.py`.  В `request_handling.py` добавлено логирование конфигураций динамической пакетной обработки.  В `test_dynamic_batching.py` добавлены новые тесты для проверки таймаутов с использованием и без использования динамической пакетной обработки.  Форматирование в целом соответствует существующему коду. Имена переменных и функций понятны. Соответствие гайдлайнам в основном соблюдено.  В коде присутствует небольшое изменение логики, которое может потребовать дополнительного анализа, но в целом код читаемый и понятный.","recommendations":["Проверить логику удаления конфигураций `use_dynamic_batching` в `request_handling.py`.","Убедиться, что новые тесты покрывают все необходимые сценарии использования динамической пакетной обработки."],"confidence":"High","score":8,"summary":"Внесенные изменения улучшают обработку динамической пакетной обработки и добавляют тесты для проверки таймаутов. Код соответствует стандартам, но требует небольшой доработки."}},{"pull":{"id":6203,"html_url":"https://github.com/jina-ai/serve/pull/6203","title":"feat: use dynamic batching param","body":"Goals:\n\n\n\nresolves #ISSUE-NUMBER\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n check and update documentation. See guide and ask the team.","is_merged":true,"diff":"diff --git a/extra-requirements.txt b/extra-requirements.txt\nindex 2c8de1b058d8d..025ccc10625f7 100644\n--- a/extra-requirements.txt\n+++ b/extra-requirements.txt\n@@ -71,7 +71,7 @@ mock:                       test\n requests-mock:              test\n pytest-custom_exit_code:    test\n black==24.3.0:              test\n-kubernetes>=18.20.0:        test\n+kubernetes>=18.20.0,<31.0.0: test\n pytest-kind==22.11.1:       test\n pytest-lazy-fixture:        test\n torch:                      cicd\ndiff --git a/jina/clients/base/__init__.py b/jina/clients/base/__init__.py\nindex 41ec147fbd74b..51845502f49a9 100644\n--- a/jina/clients/base/__init__.py\n+++ b/jina/clients/base/__init__.py\n@@ -48,6 +48,7 @@ def __init__(\n             os.unsetenv('http_proxy')\n             os.unsetenv('https_proxy')\n         self._inputs = None\n+        self._inputs_length = None\n         self._setup_instrumentation(\n             name=(\n                 self.args.name\n@@ -144,8 +145,6 @@ def _get_requests(\n         else:\n             total_docs = None\n \n-        self._inputs_length = None\n-\n         if total_docs:\n             self._inputs_length = max(1, total_docs / _kwargs['request_size'])\n \ndiff --git a/jina/serve/executors/decorators.py b/jina/serve/executors/decorators.py\nindex b9072929cbed7..49fb6f4e17681 100644\n--- a/jina/serve/executors/decorators.py\n+++ b/jina/serve/executors/decorators.py\n@@ -419,6 +419,7 @@ def dynamic_batching(\n     flush_all: bool = False,\n     custom_metric: Optional[Callable[['DocumentArray'], Union[float, int]]] = None,\n     use_custom_metric: bool = False,\n+    use_dynamic_batching: bool = True,\n ):\n     \"\"\"\n     `@dynamic_batching` defines the dynamic batching behavior of an Executor.\n@@ -438,6 +439,7 @@ def dynamic_batching(\n         If this is true, `preferred_batch_size` is used as a trigger mechanism.\n     :param custom_metric: Potential lambda function to measure the \"weight\" of each request.\n     :param use_custom_metric: Determines if we need to use the `custom_metric` to determine preferred_batch_size.\n+    :param use_dynamic_batching: Determines if we should apply dynamic batching for this method.\n     :return: decorated function\n     \"\"\"\n \n@@ -486,6 +488,7 @@ def _inject_owner_attrs(self, owner, name):\n             owner.dynamic_batching[fn_name]['flush_all'] = flush_all\n             owner.dynamic_batching[fn_name]['use_custom_metric'] = use_custom_metric\n             owner.dynamic_batching[fn_name]['custom_metric'] = custom_metric\n+            owner.dynamic_batching[fn_name]['use_dynamic_batching'] = use_dynamic_batching\n             setattr(owner, name, self.fn)\n \n         def __set_name__(self, owner, name):\ndiff --git a/jina/serve/runtimes/worker/batch_queue.py b/jina/serve/runtimes/worker/batch_queue.py\nindex 56ba81e61e2a7..ac63f2d2c2dae 100644\n--- a/jina/serve/runtimes/worker/batch_queue.py\n+++ b/jina/serve/runtimes/worker/batch_queue.py\n@@ -29,6 +29,7 @@ def __init__(\n             timeout: int = 10_000,\n             custom_metric: Optional[Callable[['DocumentArray'], Union[int, float]]] = None,\n             use_custom_metric: bool = False,\n+            **kwargs,\n     ) -> None:\n         # To keep old user behavior, we use data lock when flush_all is true and no allow_concurrent\n         self.func = func\n@@ -285,7 +286,8 @@ def batch(iterable_1, iterable_2, n: Optional[int] = 1, iterable_metrics: Option\n         sum_from_previous_first_req_idx = 0\n         for docs_inner_batch, req_idxs in batch(\n                 big_doc_in_batch, requests_idxs_in_batch,\n-                self._preferred_batch_size if not self._flush_all else None, docs_metrics_in_batch if self._custom_metric is not None else None\n+                self._preferred_batch_size if not self._flush_all else None,\n+                docs_metrics_in_batch if self._custom_metric is not None else None\n         ):\n             involved_requests_min_indx = req_idxs[0]\n             involved_requests_max_indx = req_idxs[-1]\n@@ -360,7 +362,6 @@ def batch(iterable_1, iterable_2, n: Optional[int] = 1, iterable_metrics: Option\n                 requests_completed_in_batch,\n             )\n \n-\n     async def close(self):\n         \"\"\"Closes the batch queue by flushing pending requests.\"\"\"\n         if not self._is_closed:\ndiff --git a/jina/serve/runtimes/worker/request_handling.py b/jina/serve/runtimes/worker/request_handling.py\nindex 456c94a7bdf41..b6edd7cddc090 100644\n--- a/jina/serve/runtimes/worker/request_handling.py\n+++ b/jina/serve/runtimes/worker/request_handling.py\n@@ -275,10 +275,11 @@ def _init_batchqueue_dict(self):\n                     )\n                     raise Exception(error_msg)\n \n-                if key.startswith('/'):\n-                    dbatch_endpoints.append((key, dbatch_config))\n-                else:\n-                    dbatch_functions.append((key, dbatch_config))\n+                if dbatch_config.get(\"use_dynamic_batching\", True):\n+                    if key.startswith('/'):\n+                        dbatch_endpoints.append((key, dbatch_config))\n+                    else:\n+                        dbatch_functions.append((key, dbatch_config))\n \n             # Specific endpoint configs take precedence over function configs\n             for endpoint, dbatch_config in dbatch_endpoints:\ndiff --git a/tests/integration/dynamic_batching/test_dynamic_batching.py b/tests/integration/dynamic_batching/test_dynamic_batching.py\nindex f7940289d6154..8f08d364899a4 100644\n--- a/tests/integration/dynamic_batching/test_dynamic_batching.py\n+++ b/tests/integration/dynamic_batching/test_dynamic_batching.py\n@@ -706,8 +706,8 @@ def foo(self, docs, **kwargs):\n \n \n @pytest.mark.asyncio\n-@pytest.mark.parametrize('use_custom_metric', [True])\n-@pytest.mark.parametrize('flush_all', [True])\n+@pytest.mark.parametrize('use_custom_metric', [True, False])\n+@pytest.mark.parametrize('flush_all', [True, False])\n async def test_dynamic_batching_custom_metric(use_custom_metric, flush_all):\n     class DynCustomBatchProcessor(Executor):\n \n@@ -719,7 +719,9 @@ def foo(self, docs, **kwargs):\n             for doc in docs:\n                 doc.text = f\"{total_len}\"\n \n-    depl = Deployment(uses=DynCustomBatchProcessor, uses_dynamic_batching={'foo': {\"preferred_batch_size\": 10, \"timeout\": 2000, \"use_custom_metric\": use_custom_metric, \"flush_all\": flush_all}})\n+    depl = Deployment(uses=DynCustomBatchProcessor, uses_dynamic_batching={\n+        'foo': {\"preferred_batch_size\": 10, \"timeout\": 2000, \"use_custom_metric\": use_custom_metric,\n+                \"flush_all\": flush_all}})\n     da = DocumentArray([Document(text='aaaaa') for i in range(50)])\n     with depl:\n         cl = Client(protocol=depl.protocol, port=depl.port, asyncio=True)\n@@ -733,3 +735,44 @@ def foo(self, docs, **kwargs):\n         ):\n             res.extend(r)\n         assert len(res) == 50  # 1 request per input\n+\n+\n+@pytest.mark.asyncio\n+@pytest.mark.parametrize('use_dynamic_batching', [True, False])\n+async def test_use_dynamic_batching(use_dynamic_batching):\n+    class UseDynBatchProcessor(Executor):\n+\n+        @dynamic_batching(preferred_batch_size=10)\n+        @requests(on='/foo')\n+        def foo(self, docs, **kwargs):\n+            print(f'len docs {len(docs)}')\n+            for doc in docs:\n+                doc.text = f\"{len(docs)}\"\n+\n+    depl = Deployment(uses=UseDynBatchProcessor, uses_dynamic_batching={\n+        'foo': {\"preferred_batch_size\": 10, \"timeout\": 2000, \"use_dynamic_batching\": use_dynamic_batching,\n+                \"flush_all\": False}})\n+    da = DocumentArray([Document(text='aaaaa') for _ in range(50)])\n+    with depl:\n+        cl = Client(protocol=depl.protocol, port=depl.port, asyncio=True)\n+        res = []\n+        async for r in cl.post(\n+                on='/foo',\n+                inputs=da,\n+                request_size=1,\n+                continue_on_error=True,\n+                results_in_order=True,\n+        ):\n+            res.extend(r)\n+        assert len(res) == 50  # 1 request per input\n+        for doc in res:\n+            num_10 = 0\n+            if doc.text == \"10\":\n+                num_10 += 1\n+            if not use_dynamic_batching:\n+                assert doc.text == \"1\"\n+\n+        if use_dynamic_batching:\n+            assert num_10 > 0\n+        else:\n+            assert num_10 == 0\ndiff --git a/tests/k8s/conftest.py b/tests/k8s/conftest.py\nindex 886cd7e4de473..80f9bed5283c1 100644\n--- a/tests/k8s/conftest.py\n+++ b/tests/k8s/conftest.py\n@@ -30,14 +30,14 @@ def __init__(self, kind_cluster: KindCluster, logger: JinaLogger) -> None:\n         self._loaded_images = set()\n \n     def _linkerd_install_cmd(\n-        self, kind_cluster: KindCluster, cmd, tool_name: str\n+            self, kind_cluster: KindCluster, cmd, tool_name: str\n     ) -> None:\n         self._log.info(f'Installing {tool_name} to Cluster...')\n         kube_out = subprocess.check_output(\n             (str(kind_cluster.kubectl_path), 'version'),\n             env=os.environ,\n         )\n-        self._log.info(f'kuberbetes versions: {kube_out}')\n+        self._log.info(f'kubernetes versions: {kube_out}')\n \n         # since we need to pipe to commands and the linkerd output can bee too long\n         # there is a risk of deadlock and hanging tests: https://docs.python.org/3/library/subprocess.html#popen-objects\n@@ -86,7 +86,7 @@ def _install_linkerd(self, kind_cluster: KindCluster) -> None:\n             print(f'linkerd check yields {out.decode() if out else \"nothing\"}')\n         except subprocess.CalledProcessError as e:\n             print(\n-                f'linkerd check failed with error code { e.returncode } and output { e.output }, and stderr { e.stderr }'\n+                f'linkerd check failed with error code {e.returncode} and output {e.output}, and stderr {e.stderr}'\n             )\n             raise\n \n@@ -125,8 +125,9 @@ def install_linkerd_smi(self) -> None:\n             print(f'linkerd check yields {out.decode() if out else \"nothing\"}')\n         except subprocess.CalledProcessError as e:\n             print(\n-                f'linkerd check failed with error code { e.returncode } and output { e.output }'\n+                f'linkerd check failed with error code {e.returncode} and output {e.output}, and stderr {e.stderr}'\n             )\n+            raise\n \n     def _set_kube_config(self):\n         self._log.info(f'Setting KUBECONFIG to {self._kube_config_path}')\n@@ -134,7 +135,7 @@ def _set_kube_config(self):\n         load_cluster_config()\n \n     def load_docker_images(\n-        self, images: List[str], image_tag_map: Dict[str, str]\n+            self, images: List[str], image_tag_map: Dict[str, str]\n     ) -> None:\n         for image in images:\n             full_image_name = image + ':' + image_tag_map[image]\n@@ -213,9 +214,9 @@ def load_cluster_config() -> None:\n \n @pytest.fixture\n def docker_images(\n-    request: FixtureRequest,\n-    image_name_tag_map: Dict[str, str],\n-    k8s_cluster: KindClusterWrapper,\n+        request: FixtureRequest,\n+        image_name_tag_map: Dict[str, str],\n+        k8s_cluster: KindClusterWrapper,\n ) -> List[str]:\n     image_names: List[str] = request.param\n     k8s_cluster.load_docker_images(image_names, image_name_tag_map)\n@@ -227,7 +228,7 @@ def docker_images(\n \n @contextlib.contextmanager\n def shell_portforward(\n-    kubectl_path, pod_or_service, port1, port2, namespace, waiting: float = 1\n+        kubectl_path, pod_or_service, port1, port2, namespace, waiting: float = 1\n ):\n     try:\n         proc = subprocess.Popen(\ndiff --git a/tests/k8s/test_k8s_deployment.py b/tests/k8s/test_k8s_deployment.py\nindex 2f1fd9691fc94..1ab58d0accccc 100644\n--- a/tests/k8s/test_k8s_deployment.py\n+++ b/tests/k8s/test_k8s_deployment.py\n@@ -8,7 +8,6 @@\n from jina.serve.runtimes.servers import BaseServer\n \n from jina import Deployment, Client\n-from jina.helper import random_port\n from tests.k8s.conftest import shell_portforward\n \n cluster.KIND_VERSION = 'v0.11.1'\ndiff --git a/tests/unit/serve/executors/test_executor.py b/tests/unit/serve/executors/test_executor.py\nindex 344ebcaab7254..5c71b18a9f8e9 100644\n--- a/tests/unit/serve/executors/test_executor.py\n+++ b/tests/unit/serve/executors/test_executor.py\n@@ -614,15 +614,15 @@ class C(B):\n     [\n         (\n             dict(preferred_batch_size=4, timeout=5_000),\n-            dict(preferred_batch_size=4, timeout=5_000, flush_all=False, use_custom_metric=False, custom_metric=None),\n+            dict(preferred_batch_size=4, timeout=5_000, flush_all=False, use_custom_metric=False, custom_metric=None, use_dynamic_batching=True),\n         ),\n         (\n             dict(preferred_batch_size=4, timeout=5_000, flush_all=True),\n-            dict(preferred_batch_size=4, timeout=5_000, flush_all=True, use_custom_metric=False, custom_metric=None),\n+            dict(preferred_batch_size=4, timeout=5_000, flush_all=True, use_custom_metric=False, custom_metric=None, use_dynamic_batching=True),\n         ),\n         (\n             dict(preferred_batch_size=4),\n-            dict(preferred_batch_size=4, timeout=10_000, flush_all=False, use_custom_metric=False, custom_metric=None),\n+            dict(preferred_batch_size=4, timeout=10_000, flush_all=False, use_custom_metric=False, custom_metric=None, use_dynamic_batching=True),\n         ),\n     ],\n )\n@@ -641,15 +641,15 @@ def foo(self, docs, **kwargs):\n     [\n         (\n             dict(preferred_batch_size=4, timeout=5_000),\n-            dict(preferred_batch_size=4, timeout=5_000, flush_all=False, use_custom_metric=False, custom_metric=None),\n+            dict(preferred_batch_size=4, timeout=5_000, flush_all=False, use_custom_metric=False, custom_metric=None, use_dynamic_batching=True),\n         ),\n         (\n             dict(preferred_batch_size=4, timeout=5_000, flush_all=True),\n-            dict(preferred_batch_size=4, timeout=5_000, flush_all=True, use_custom_metric=False, custom_metric=None),\n+            dict(preferred_batch_size=4, timeout=5_000, flush_all=True, use_custom_metric=False, custom_metric=None, use_dynamic_batching=True),\n         ),\n         (\n             dict(preferred_batch_size=4),\n-            dict(preferred_batch_size=4, timeout=10_000, flush_all=False, use_custom_metric=False, custom_metric=None),\n+            dict(preferred_batch_size=4, timeout=10_000, flush_all=False, use_custom_metric=False, custom_metric=None, use_dynamic_batching=True),\n         ),\n     ],\n )\n"},"summary":"## Summary of Merge Request\n\nДанный MR направлен на добавление возможности отключения динамической пакетной обработки для отдельных методов. Основные изменения включают добавление параметра `use_dynamic_batching` в декоратор `@dynamic_batching` и его использование в `request_handling.py` и тестах. Экспертная оценка относит сложность изменений к \"Medium\". Анализ Code Style показывает хорошее соответствие гайдлайнам, с рекомендацией добавить больше тестов. В области Design Patterns изменения оцениваются положительно, улучшая гибкость управления динамической пакетной обработкой. Анти-паттерны не обнаружены.\n","antiPatterns":{"detailed_analysis":"Внесенные изменения добавляют параметр `use_dynamic_batching` в декоратор `@dynamic_batching` и соответствующую логику в `request_handling.py` и тесты. Это позволяет отключать динамическую пакетную обработку для отдельных методов, что предоставляет большую гибкость. Изменения в `extra-requirements.txt` и `clients/base/__init__.py` незначительны и не содержат анти-паттернов. В тестах добавлены новые тесты для проверки работы с `use_dynamic_batching`. В целом, изменения направлены на улучшение функциональности и не вводят новых анти-паттернов. ","recommendations":["Рекомендуется проверить, что отключение динамической пакетной обработки не приводит к ухудшению производительности в определенных сценариях."],"confidence":"High","score":9,"summary":"Внесенные изменения улучшают функциональность динамической пакетной обработки, добавляя возможность ее отключения. Анти-паттерны не обнаружены."},"complexity":{"justification":"Изменения включают в себя добавление нового параметра `use_dynamic_batching` в декоратор `@dynamic_batching` и его использование в нескольких местах, включая `request_handling.py` и тесты. Это влияет на логику динамической пакетной обработки, позволяя пользователям отключать ее для определенных методов. Объем изменений умеренный, затрагивает несколько файлов, но не вносит кардинальных изменений в архитектуру. Влияние на систему умеренное, затрагивает механизм динамической пакетной обработки. Когнитивная нагрузка умеренная, так как требуется понимание логики динамической пакетной обработки и влияния нового параметра. Риски умеренные, так как изменения в основном касаются конфигурации и управления существующей функциональностью.  Присутствуют изменения в тестах, что указывает на необходимость проверки нового функционала.  В целом, изменения соответствуют уровню сложности \"Medium\".","classification":"Medium"},"designPatterns":{"detailed_analysis":"Внесенные изменения в основном касаются добавления параметра `use_dynamic_batching` в декоратор `@dynamic_batching` и его использования в `request_handling.py` и тестах. Это позволяет более гибко управлять применением динамической пакетной обработки для отдельных методов. В `request_handling.py` добавлена проверка этого параметра, что позволяет включать или отключать динамическую пакетную обработку для конкретных конечных точек или функций. В тестах добавлены новые тесты для проверки корректности работы с этим параметром. Изменения не содержат явных анти-паттернов, а скорее улучшают гибкость и управляемость существующей функциональности. ","recommendations":["Рекомендуется убедиться, что документация обновлена в соответствии с добавленным параметром `use_dynamic_batching`."],"confidence":"High","score":9,"summary":"Внесенные изменения улучшают гибкость управления динамической пакетной обработкой, не вводя новых анти-паттернов."},"codeStyle":{"detailed_analysis":"Изменения включают в себя добавление параметра `use_dynamic_batching` в декоратор `@dynamic_batching` и соответствующие изменения в коде, чтобы позволить отключение динамической пакетной обработки для отдельных методов. Это включает в себя изменения в `jina/serve/executors/decorators.py`, `jina/serve/runtimes/worker/request_handling.py`, и добавление тестов в `tests/integration/dynamic_batching/test_dynamic_batching.py`. Изменения в основном касаются добавления нового параметра и его использования для управления включением/выключением динамической пакетной обработки. Форматирование соответствует стандартам, именование переменных понятное. Читаемость кода хорошая, добавлены тесты для проверки новой функциональности. Соответствие гайдлайнам хорошее.","recommendations":["Добавить больше тестов для покрытия различных сценариев использования `use_dynamic_batching`.","Проверить, что отключение динамической пакетной обработки не влияет на другие части системы."],"confidence":"High","score":8,"summary":"Внесены изменения для добавления возможности отключения динамической пакетной обработки для отдельных методов, что повышает гибкость и контроль над поведением Executor."}},{"pull":{"id":6202,"html_url":"https://github.com/jina-ai/serve/pull/6202","title":"fix: rewrite compatible","body":"Goals:\n\n\n\nresolves #ISSUE-NUMBER\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n check and update documentation. See guide and ask the team.","is_merged":true,"diff":"diff --git a/jina/serve/executors/__init__.py b/jina/serve/executors/__init__.py\nindex 9e00c8e77a98f..47ee7d6c22ffd 100644\n--- a/jina/serve/executors/__init__.py\n+++ b/jina/serve/executors/__init__.py\n@@ -655,11 +655,11 @@ def _validate_sagemaker(self):\n             return\n \n     def _add_dynamic_batching(self, _dynamic_batching: Optional[Dict]):\n-        import collections\n+        from collections.abc import Mapping\n \n         def deep_update(source, overrides):\n             for key, value in overrides.items():\n-                if isinstance(value, collections.Mapping) and value:\n+                if isinstance(value, Mapping) and value:\n                     returned = deep_update(source.get(key, {}), value)\n                     source[key] = returned\n                 else:\n"},"summary":"## Summary:\n\nДанный merge request направлен на улучшение кода, в основном затрагивая импорты и использование `collections.abc.Mapping` вместо `collections.Mapping`. Основные изменения включают в себя обновление импортов для повышения совместимости и соответствия современным стандартам Python. Оценка сложности - низкая, изменения простые и понятные. Экспертная оценка кода стиля высокая, с оценкой 8 баллов, отмечается хорошее форматирование и читаемость. В области Design Patterns и Anti-Patterns также получены высокие оценки (9 баллов), подчеркивается отсутствие анти-паттернов и улучшение за счет более явного указания типов.\n","antiPatterns":{"detailed_analysis":"Внесенные изменения содержат незначительные улучшения в коде, связанные с импортом и обновлением словарей. Не обнаружено значительных анти-паттернов. Использование `collections.abc.Mapping` вместо `collections.Mapping` является улучшением, так как предоставляет более явное указание на тип.","recommendations":["Продолжать следовать лучшим практикам при внесении изменений в код.","Обратить внимание на использование более конкретных типов при импорте, когда это возможно."],"confidence":"High","score":9,"summary":"Изменения в основном касаются улучшения импорта и использования более конкретных типов, что положительно влияет на читаемость кода и его поддержку."},"complexity":{"justification":"Данный diff содержит незначительные изменения, затрагивающие импорт модуля. Изменения простые и понятные, не влияют на критические компоненты или логику работы. Объем изменений небольшой, когнитивная нагрузка низкая. Риск внесения регрессий минимален. Соответствует характеристикам \"Low\" по определению сложности.","classification":"Low"},"designPatterns":{"detailed_analysis":"Внесенные изменения содержат незначительные улучшения в коде, связанные с использованием `collections.abc.Mapping` вместо `collections.Mapping`. Это небольшое улучшение, которое делает код более явным и соответствует современным практикам Python. Анти-паттерны не обнаружены.","recommendations":[],"confidence":"High","score":9,"summary":"Внесенные изменения улучшают код, заменяя устаревший импорт. Анти-паттерны не обнаружены."},"codeStyle":{"detailed_analysis":"Изменения в основном касаются импортов и использования `collections.abc.Mapping` вместо `collections.Mapping`. Форматирование сохранено, отступы и пробелы соответствуют стилю. Именование переменных и функций осталось прежним, что обеспечивает консистентность. Читаемость кода не ухудшилась, а в некоторых аспектах даже улучшилась за счет более точного импорта. Соответствие гайдлайнам в целом хорошее, так как изменения направлены на улучшение совместимости и соответствия современным стандартам Python. Оценка 8 обусловлена незначительными изменениями, которые, тем не менее, улучшают код.","recommendations":["Нет существенных рекомендаций по улучшению."],"confidence":"High","score":8,"summary":"Внесены незначительные изменения, улучшающие совместимость и соответствие стандартам Python. Код хорошо отформатирован и читаем."}},{"pull":{"id":6201,"html_url":"https://github.com/jina-ai/serve/pull/6201","title":"test: test no data lock in batch queue","body":"Goals:\n\n\n\nresolves #ISSUE-NUMBER\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n check and update documentation. See guide and ask the team.","is_merged":true,"diff":"diff --git a/jina/serve/runtimes/worker/batch_queue.py b/jina/serve/runtimes/worker/batch_queue.py\nindex 31bac588d5efd..56ba81e61e2a7 100644\n--- a/jina/serve/runtimes/worker/batch_queue.py\n+++ b/jina/serve/runtimes/worker/batch_queue.py\n@@ -3,7 +3,6 @@\n from asyncio import Event, Task\n from typing import Callable, Dict, List, Optional, TYPE_CHECKING, Union\n from jina._docarray import docarray_v2\n-import contextlib\n \n if not docarray_v2:\n     from docarray import DocumentArray\n@@ -25,7 +24,6 @@ def __init__(\n             response_docarray_cls,\n             output_array_type: Optional[str] = None,\n             params: Optional[Dict] = None,\n-            allow_concurrent: bool = False,\n             flush_all: bool = False,\n             preferred_batch_size: int = 4,\n             timeout: int = 10_000,\n@@ -33,10 +31,6 @@ def __init__(\n             use_custom_metric: bool = False,\n     ) -> None:\n         # To keep old user behavior, we use data lock when flush_all is true and no allow_concurrent\n-        if allow_concurrent and flush_all:\n-            self._data_lock = contextlib.AsyncExitStack()\n-        else:\n-            self._data_lock = asyncio.Lock()\n         self.func = func\n         if params is None:\n             params = dict()\n@@ -64,7 +58,7 @@ def __str__(self) -> str:\n     def _reset(self) -> None:\n         \"\"\"Set all events and reset the batch queue.\"\"\"\n         self._requests: List[DataRequest] = []\n-        # a list of every request ID\n+        # a list of every request idx inside self._requests\n         self._request_idxs: List[int] = []\n         self._request_lens: List[int] = []\n         self._docs_metrics: List[int] = []\n@@ -116,26 +110,24 @@ async def push(self, request: DataRequest, http=False) -> asyncio.Queue:\n             # this push requests the data lock. The order of accessing the data lock guarantees that this request will be put in the `big_doc`\n             # before the `flush` task processes it.\n             self._start_timer()\n-        async with self._data_lock:\n-            if not self._flush_task:\n-                self._flush_task = asyncio.create_task(self._await_then_flush(http))\n-\n-            self._big_doc.extend(docs)\n-            next_req_idx = len(self._requests)\n-            num_docs = len(docs)\n-            metric_value = num_docs\n-            if self._custom_metric is not None:\n-                metrics = [self._custom_metric(doc) for doc in docs]\n-                metric_value += sum(metrics)\n-                self._docs_metrics.extend(metrics)\n-            self._metric_value += metric_value\n-            self._request_idxs.extend([next_req_idx] * num_docs)\n-            self._request_lens.append(num_docs)\n-            self._requests.append(request)\n-            queue = asyncio.Queue()\n-            self._requests_completed.append(queue)\n-            if self._metric_value >= self._preferred_batch_size:\n-                self._flush_trigger.set()\n+        if not self._flush_task:\n+            self._flush_task = asyncio.create_task(self._await_then_flush(http))\n+        self._big_doc.extend(docs)\n+        next_req_idx = len(self._requests)\n+        num_docs = len(docs)\n+        metric_value = num_docs\n+        if self._custom_metric is not None:\n+            metrics = [self._custom_metric(doc) for doc in docs]\n+            metric_value += sum(metrics)\n+            self._docs_metrics.extend(metrics)\n+        self._metric_value += metric_value\n+        self._request_idxs.extend([next_req_idx] * num_docs)\n+        self._request_lens.append(num_docs)\n+        self._requests.append(request)\n+        queue = asyncio.Queue()\n+        self._requests_completed.append(queue)\n+        if self._metric_value >= self._preferred_batch_size:\n+            self._flush_trigger.set()\n \n         return queue\n \n@@ -271,96 +263,76 @@ def batch(iterable_1, iterable_2, n: Optional[int] = 1, iterable_metrics: Option\n \n         await self._flush_trigger.wait()\n         # writes to shared data between tasks need to be mutually exclusive\n-        async with self._data_lock:\n-            big_doc_in_batch = copy.copy(self._big_doc)\n-            requests_idxs_in_batch = copy.copy(self._request_idxs)\n-            requests_lens_in_batch = copy.copy(self._request_lens)\n-            docs_metrics_in_batch = copy.copy(self._docs_metrics)\n-            requests_in_batch = copy.copy(self._requests)\n-            requests_completed_in_batch = copy.copy(self._requests_completed)\n-\n-            self._reset()\n-\n-            # At this moment, we have documents concatenated in big_doc_in_batch corresponding to requests in\n-            # requests_idxs_in_batch with its lengths stored in requests_lens_in_batch. For each requests, there is a queue to\n-            # communicate that the request has been processed properly.\n-\n-            if not docarray_v2:\n-                non_assigned_to_response_docs: DocumentArray = DocumentArray.empty()\n-            else:\n-                non_assigned_to_response_docs = self._response_docarray_cls()\n+        big_doc_in_batch = copy.copy(self._big_doc)\n+        requests_idxs_in_batch = copy.copy(self._request_idxs)\n+        requests_lens_in_batch = copy.copy(self._request_lens)\n+        docs_metrics_in_batch = copy.copy(self._docs_metrics)\n+        requests_in_batch = copy.copy(self._requests)\n+        requests_completed_in_batch = copy.copy(self._requests_completed)\n \n-            non_assigned_to_response_request_idxs = []\n-            sum_from_previous_first_req_idx = 0\n-            for docs_inner_batch, req_idxs in batch(\n-                    big_doc_in_batch, requests_idxs_in_batch,\n-                    self._preferred_batch_size if not self._flush_all else None, docs_metrics_in_batch if self._custom_metric is not None else None\n-            ):\n-                involved_requests_min_indx = req_idxs[0]\n-                involved_requests_max_indx = req_idxs[-1]\n-                input_len_before_call: int = len(docs_inner_batch)\n-                batch_res_docs = None\n-                try:\n-                    batch_res_docs = await self.func(\n-                        docs=docs_inner_batch,\n-                        parameters=self.params,\n-                        docs_matrix=None,  # joining manually with batch queue is not supported right now\n-                        tracing_context=None,\n-                    )\n-                    # Output validation\n-                    if (docarray_v2 and isinstance(batch_res_docs, DocList)) or (\n-                            not docarray_v2\n-                            and isinstance(batch_res_docs, DocumentArray)\n-                    ):\n-                        if not len(batch_res_docs) == input_len_before_call:\n-                            raise ValueError(\n-                                f'Dynamic Batching requires input size to equal output size. Expected output size {input_len_before_call}, but got {len(batch_res_docs)}'\n-                            )\n-                    elif batch_res_docs is None:\n-                        if not len(docs_inner_batch) == input_len_before_call:\n-                            raise ValueError(\n-                                f'Dynamic Batching requires input size to equal output size. Expected output size {input_len_before_call}, but got {len(docs_inner_batch)}'\n-                            )\n-                    else:\n-                        array_name = (\n-                            'DocumentArray' if not docarray_v2 else 'DocList'\n+        self._reset()\n+\n+        # At this moment, we have documents concatenated in big_doc_in_batch corresponding to requests in\n+        # requests_idxs_in_batch with its lengths stored in requests_lens_in_batch. For each requests, there is a queue to\n+        # communicate that the request has been processed properly.\n+\n+        if not docarray_v2:\n+            non_assigned_to_response_docs: DocumentArray = DocumentArray.empty()\n+        else:\n+            non_assigned_to_response_docs = self._response_docarray_cls()\n+\n+        non_assigned_to_response_request_idxs = []\n+        sum_from_previous_first_req_idx = 0\n+        for docs_inner_batch, req_idxs in batch(\n+                big_doc_in_batch, requests_idxs_in_batch,\n+                self._preferred_batch_size if not self._flush_all else None, docs_metrics_in_batch if self._custom_metric is not None else None\n+        ):\n+            involved_requests_min_indx = req_idxs[0]\n+            involved_requests_max_indx = req_idxs[-1]\n+            input_len_before_call: int = len(docs_inner_batch)\n+            batch_res_docs = None\n+            try:\n+                batch_res_docs = await self.func(\n+                    docs=docs_inner_batch,\n+                    parameters=self.params,\n+                    docs_matrix=None,  # joining manually with batch queue is not supported right now\n+                    tracing_context=None,\n+                )\n+                # Output validation\n+                if (docarray_v2 and isinstance(batch_res_docs, DocList)) or (\n+                        not docarray_v2\n+                        and isinstance(batch_res_docs, DocumentArray)\n+                ):\n+                    if not len(batch_res_docs) == input_len_before_call:\n+                        raise ValueError(\n+                            f'Dynamic Batching requires input size to equal output size. Expected output size {input_len_before_call}, but got {len(batch_res_docs)}'\n                         )\n-                        raise TypeError(\n-                            f'The return type must be {array_name} / `None` when using dynamic batching, '\n-                            f'but getting {batch_res_docs!r}'\n+                elif batch_res_docs is None:\n+                    if not len(docs_inner_batch) == input_len_before_call:\n+                        raise ValueError(\n+                            f'Dynamic Batching requires input size to equal output size. Expected output size {input_len_before_call}, but got {len(docs_inner_batch)}'\n                         )\n-                except Exception as exc:\n-                    # All the requests containing docs in this Exception should be raising it\n-                    for request_full in requests_completed_in_batch[\n-                                        involved_requests_min_indx: involved_requests_max_indx + 1\n-                                        ]:\n-                        await request_full.put(exc)\n                 else:\n-                    # We need to attribute the docs to their requests\n-                    non_assigned_to_response_docs.extend(\n-                        batch_res_docs or docs_inner_batch\n+                    array_name = (\n+                        'DocumentArray' if not docarray_v2 else 'DocList'\n                     )\n-                    non_assigned_to_response_request_idxs.extend(req_idxs)\n-                    num_assigned_docs = await _assign_results(\n-                        non_assigned_to_response_docs,\n-                        non_assigned_to_response_request_idxs,\n-                        sum_from_previous_first_req_idx,\n-                        requests_lens_in_batch,\n-                        requests_in_batch,\n-                        requests_completed_in_batch,\n+                    raise TypeError(\n+                        f'The return type must be {array_name} / `None` when using dynamic batching, '\n+                        f'but getting {batch_res_docs!r}'\n                     )\n-\n-                    sum_from_previous_first_req_idx = (\n-                            len(non_assigned_to_response_docs) - num_assigned_docs\n-                    )\n-                    non_assigned_to_response_docs = non_assigned_to_response_docs[\n-                                                    num_assigned_docs:\n-                                                    ]\n-                    non_assigned_to_response_request_idxs = (\n-                        non_assigned_to_response_request_idxs[num_assigned_docs:]\n-                    )\n-            if len(non_assigned_to_response_request_idxs) > 0:\n-                _ = await _assign_results(\n+            except Exception as exc:\n+                # All the requests containing docs in this Exception should be raising it\n+                for request_full in requests_completed_in_batch[\n+                                    involved_requests_min_indx: involved_requests_max_indx + 1\n+                                    ]:\n+                    await request_full.put(exc)\n+            else:\n+                # We need to attribute the docs to their requests\n+                non_assigned_to_response_docs.extend(\n+                    batch_res_docs or docs_inner_batch\n+                )\n+                non_assigned_to_response_request_idxs.extend(req_idxs)\n+                num_assigned_docs = await _assign_results(\n                     non_assigned_to_response_docs,\n                     non_assigned_to_response_request_idxs,\n                     sum_from_previous_first_req_idx,\n@@ -369,6 +341,26 @@ def batch(iterable_1, iterable_2, n: Optional[int] = 1, iterable_metrics: Option\n                     requests_completed_in_batch,\n                 )\n \n+                sum_from_previous_first_req_idx = (\n+                        len(non_assigned_to_response_docs) - num_assigned_docs\n+                )\n+                non_assigned_to_response_docs = non_assigned_to_response_docs[\n+                                                num_assigned_docs:\n+                                                ]\n+                non_assigned_to_response_request_idxs = (\n+                    non_assigned_to_response_request_idxs[num_assigned_docs:]\n+                )\n+        if len(non_assigned_to_response_request_idxs) > 0:\n+            _ = await _assign_results(\n+                non_assigned_to_response_docs,\n+                non_assigned_to_response_request_idxs,\n+                sum_from_previous_first_req_idx,\n+                requests_lens_in_batch,\n+                requests_in_batch,\n+                requests_completed_in_batch,\n+            )\n+\n+\n     async def close(self):\n         \"\"\"Closes the batch queue by flushing pending requests.\"\"\"\n         if not self._is_closed:\ndiff --git a/jina/serve/runtimes/worker/request_handling.py b/jina/serve/runtimes/worker/request_handling.py\nindex 52a5070ea83e4..456c94a7bdf41 100644\n--- a/jina/serve/runtimes/worker/request_handling.py\n+++ b/jina/serve/runtimes/worker/request_handling.py\n@@ -702,7 +702,6 @@ async def handle(\n                     ].response_schema,\n                     output_array_type=self.args.output_array_type,\n                     params=params,\n-                    allow_concurrent=self.args.allow_concurrent,\n                     **self._batchqueue_config[exec_endpoint],\n                 )\n             # This is necessary because push might need to await for the queue to be emptied\ndiff --git a/tests/integration/dynamic_batching/test_dynamic_batching.py b/tests/integration/dynamic_batching/test_dynamic_batching.py\nindex b55e8415c0aae..f7940289d6154 100644\n--- a/tests/integration/dynamic_batching/test_dynamic_batching.py\n+++ b/tests/integration/dynamic_batching/test_dynamic_batching.py\n@@ -218,9 +218,7 @@ def call_api_with_params(req: RequestStructParams):\n     ],\n )\n @pytest.mark.parametrize('use_stream', [False, True])\n-@pytest.mark.parametrize('allow_concurrent', [False, True])\n-def test_timeout(add_parameters, use_stream, allow_concurrent):\n-    add_parameters['allow_concurrent'] = allow_concurrent\n+def test_timeout(add_parameters, use_stream):\n     f = Flow().add(**add_parameters)\n     with f:\n         start_time = time.time()\n@@ -267,9 +265,7 @@ def test_timeout(add_parameters, use_stream, allow_concurrent):\n     ],\n )\n @pytest.mark.parametrize('use_stream', [False, True])\n-@pytest.mark.parametrize('allow_concurrent', [False, True])\n-def test_preferred_batch_size(add_parameters, use_stream, allow_concurrent):\n-    add_parameters['allow_concurrent'] = allow_concurrent\n+def test_preferred_batch_size(add_parameters, use_stream):\n     f = Flow().add(**add_parameters)\n     with f:\n         with mp.Pool(2) as p:\n@@ -319,9 +315,8 @@ def test_preferred_batch_size(add_parameters, use_stream, allow_concurrent):\n \n @pytest.mark.repeat(10)\n @pytest.mark.parametrize('use_stream', [False, True])\n-@pytest.mark.parametrize('allow_concurrent', [False, True])\n-def test_correctness(use_stream, allow_concurrent):\n-    f = Flow().add(uses=PlaceholderExecutor, allow_concurrent=allow_concurrent)\n+def test_correctness(use_stream):\n+    f = Flow().add(uses=PlaceholderExecutor)\n     with f:\n         with mp.Pool(2) as p:\n             results = list(\n@@ -641,14 +636,7 @@ def test_failure_propagation():\n         True\n     ],\n )\n-@pytest.mark.parametrize(\n-    'allow_concurrent',\n-    [\n-        False,\n-        True\n-    ],\n-)\n-def test_exception_handling_in_dynamic_batch(flush_all, allow_concurrent):\n+def test_exception_handling_in_dynamic_batch(flush_all):\n     class SlowExecutorWithException(Executor):\n \n         @dynamic_batching(preferred_batch_size=3, timeout=5000, flush_all=flush_all)\n@@ -658,7 +646,7 @@ def foo(self, docs, **kwargs):\n                 if doc.text == 'fail':\n                     raise Exception('Fail is in the Batch')\n \n-    depl = Deployment(uses=SlowExecutorWithException, allow_concurrent=allow_concurrent)\n+    depl = Deployment(uses=SlowExecutorWithException)\n \n     with depl:\n         da = DocumentArray([Document(text='good') for _ in range(50)])\n@@ -691,14 +679,7 @@ def foo(self, docs, **kwargs):\n         True\n     ],\n )\n-@pytest.mark.parametrize(\n-    'allow_concurrent',\n-    [\n-        False,\n-        True\n-    ],\n-)\n-async def test_num_docs_processed_in_exec(flush_all, allow_concurrent):\n+async def test_num_docs_processed_in_exec(flush_all):\n     class DynBatchProcessor(Executor):\n \n         @dynamic_batching(preferred_batch_size=5, timeout=5000, flush_all=flush_all)\n@@ -707,7 +688,7 @@ def foo(self, docs, **kwargs):\n             for doc in docs:\n                 doc.text = f\"{len(docs)}\"\n \n-    depl = Deployment(uses=DynBatchProcessor, protocol='http', allow_concurrent=allow_concurrent)\n+    depl = Deployment(uses=DynBatchProcessor, protocol='http')\n \n     with depl:\n         da = DocumentArray([Document(text='good') for _ in range(50)])\n@@ -722,25 +703,11 @@ def foo(self, docs, **kwargs):\n         ):\n             res.extend(r)\n         assert len(res) == 50  # 1 request per input\n-        if not flush_all:\n-            for d in res:\n-                assert int(d.text) <= 5\n-        else:\n-            larger_than_5 = 0\n-            smaller_than_5 = 0\n-            for d in res:\n-                if int(d.text) > 5:\n-                    larger_than_5 += 1\n-                if int(d.text) < 5:\n-                    smaller_than_5 += 1\n-\n-            assert smaller_than_5 == (1 if allow_concurrent else 0)\n-            assert larger_than_5 > 0\n \n \n @pytest.mark.asyncio\n-@pytest.mark.parametrize('use_custom_metric', [True, False])\n-@pytest.mark.parametrize('flush_all', [False, True])\n+@pytest.mark.parametrize('use_custom_metric', [True])\n+@pytest.mark.parametrize('flush_all', [True])\n async def test_dynamic_batching_custom_metric(use_custom_metric, flush_all):\n     class DynCustomBatchProcessor(Executor):\n \n@@ -766,37 +733,3 @@ def foo(self, docs, **kwargs):\n         ):\n             res.extend(r)\n         assert len(res) == 50  # 1 request per input\n-\n-    # If custom_metric and flush all\n-    if use_custom_metric and not flush_all:\n-        for doc in res:\n-            assert doc.text == \"10\"\n-\n-    elif not use_custom_metric and not flush_all:\n-        for doc in res:\n-            assert doc.text == \"50\"\n-\n-    elif use_custom_metric and flush_all:\n-        # There will be 2 \"10\" and the rest will be \"240\"\n-        num_10 = 0\n-        num_240 = 0\n-        for doc in res:\n-            if doc.text == \"10\":\n-                num_10 += 1\n-            elif doc.text == \"240\":\n-                num_240 += 1\n-\n-        assert num_10 == 2\n-        assert num_240 == 48\n-    elif not use_custom_metric and flush_all:\n-        # There will be 10 \"50\" and the rest will be \"200\"\n-        num_50 = 0\n-        num_200 = 0\n-        for doc in res:\n-            if doc.text == \"50\":\n-                num_50 += 1\n-            elif doc.text == \"200\":\n-                num_200 += 1\n-\n-        assert num_50 == 10\n-        assert num_200 == 40\ndiff --git a/tests/unit/serve/dynamic_batching/test_batch_queue.py b/tests/unit/serve/dynamic_batching/test_batch_queue.py\nindex 40622b478322d..21fafabddd8e3 100644\n--- a/tests/unit/serve/dynamic_batching/test_batch_queue.py\n+++ b/tests/unit/serve/dynamic_batching/test_batch_queue.py\n@@ -10,8 +10,7 @@\n \n @pytest.mark.asyncio\n @pytest.mark.parametrize('flush_all', [False, True])\n-@pytest.mark.parametrize('allow_concurrent', [False, True])\n-async def test_batch_queue_timeout(flush_all, allow_concurrent):\n+async def test_batch_queue_timeout(flush_all):\n     async def foo(docs, **kwargs):\n         await asyncio.sleep(0.1)\n         return DocumentArray([Document(text='Done') for _ in docs])\n@@ -23,7 +22,6 @@ async def foo(docs, **kwargs):\n         preferred_batch_size=4,\n         timeout=2000,\n         flush_all=flush_all,\n-        allow_concurrent=allow_concurrent,\n     )\n \n     three_data_requests = [DataRequest() for _ in range(3)]\n@@ -64,10 +62,8 @@ async def process_request(req):\n \n @pytest.mark.asyncio\n @pytest.mark.parametrize('flush_all', [False, True])\n-@pytest.mark.parametrize('allow_concurrent', [False, True])\n-async def test_batch_queue_timeout_does_not_wait_previous_batch(flush_all, allow_concurrent):\n+async def test_batch_queue_timeout_does_not_wait_previous_batch(flush_all):\n     batches_lengths_computed = []\n-    lock = asyncio.Lock()\n \n     async def foo(docs, **kwargs):\n         await asyncio.sleep(4)\n@@ -81,7 +77,6 @@ async def foo(docs, **kwargs):\n         preferred_batch_size=5,\n         timeout=3000,\n         flush_all=flush_all,\n-        allow_concurrent=allow_concurrent\n     )\n \n     data_requests = [DataRequest() for _ in range(3)]\n@@ -108,17 +103,12 @@ async def process_request(req, sleep=0):\n     if flush_all is False:\n         # TIME TAKEN: 8000 for first batch of requests, plus 4000 for second batch that is fired inmediately\n         # BEFORE FIX in https://github.com/jina-ai/jina/pull/6071, this would take: 8000 + 3000 + 4000 (Timeout would start counting too late)\n-        assert time_spent >= 12000\n-        assert time_spent <= 12500\n-    else:\n-        if not allow_concurrent:\n-            assert time_spent >= 8000\n-            assert time_spent <= 8500\n-        else:\n-            assert time_spent < 8000\n-    if flush_all is False:\n-        assert batches_lengths_computed == [5, 1, 2]\n+        assert time_spent >= 8000\n+        assert time_spent <= 8500\n+        assert batches_lengths_computed == [5, 2, 1]\n     else:\n+        assert time_spent >= 7000\n+        assert time_spent <= 7500\n         assert batches_lengths_computed == [6, 2]\n \n     await bq.close()\n@@ -126,8 +116,7 @@ async def process_request(req, sleep=0):\n \n @pytest.mark.asyncio\n @pytest.mark.parametrize('flush_all', [False, True])\n-@pytest.mark.parametrize('allow_concurrent', [False, True])\n-async def test_batch_queue_req_length_larger_than_preferred(flush_all, allow_concurrent):\n+async def test_batch_queue_req_length_larger_than_preferred(flush_all):\n     async def foo(docs, **kwargs):\n         await asyncio.sleep(0.1)\n         return DocumentArray([Document(text='Done') for _ in docs])\n@@ -139,7 +128,6 @@ async def foo(docs, **kwargs):\n         preferred_batch_size=4,\n         timeout=2000,\n         flush_all=flush_all,\n-        allow_concurrent=allow_concurrent,\n     )\n \n     data_requests = [DataRequest() for _ in range(3)]\n@@ -166,8 +154,7 @@ async def process_request(req):\n \n \n @pytest.mark.asyncio\n-@pytest.mark.parametrize('allow_concurrent', [False, True])\n-async def test_exception(allow_concurrent):\n+async def test_exception():\n     BAD_REQUEST_IDX = [2, 6]\n \n     async def foo(docs, **kwargs):\n@@ -185,7 +172,6 @@ async def foo(docs, **kwargs):\n         preferred_batch_size=1,\n         timeout=500,\n         flush_all=False,\n-        allow_concurrent=allow_concurrent\n     )\n \n     data_requests = [DataRequest() for _ in range(35)]\n@@ -215,8 +201,7 @@ async def process_request(req):\n \n \n @pytest.mark.asyncio\n-@pytest.mark.parametrize('allow_concurrent', [False, True])\n-async def test_exception_more_complex(allow_concurrent):\n+async def test_exception_more_complex():\n     TRIGGER_BAD_REQUEST_IDX = [2, 6]\n     EXPECTED_BAD_REQUESTS = [2, 3, 6, 7]\n \n@@ -238,7 +223,6 @@ async def foo(docs, **kwargs):\n         preferred_batch_size=2,\n         timeout=500,\n         flush_all=False,\n-        allow_concurrent=allow_concurrent\n     )\n \n     data_requests = [DataRequest() for _ in range(35)]\n@@ -271,8 +255,7 @@ async def process_request(req):\n \n @pytest.mark.asyncio\n @pytest.mark.parametrize('flush_all', [False, True])\n-@pytest.mark.parametrize('allow_concurrent', [False, True])\n-async def test_exception_all(flush_all, allow_concurrent):\n+async def test_exception_all(flush_all):\n     async def foo(docs, **kwargs):\n         raise AssertionError\n \n@@ -283,7 +266,6 @@ async def foo(docs, **kwargs):\n         preferred_batch_size=2,\n         flush_all=flush_all,\n         timeout=500,\n-        allow_concurrent=allow_concurrent\n     )\n \n     data_requests = [DataRequest() for _ in range(10)]\n@@ -322,9 +304,8 @@ async def foo(docs, **kwargs):\n @pytest.mark.parametrize('preferred_batch_size', [7, 61, 100])\n @pytest.mark.parametrize('timeout', [0.3, 500])\n @pytest.mark.parametrize('flush_all', [False, True])\n-@pytest.mark.parametrize('allow_concurrent', [False, True])\n @pytest.mark.asyncio\n-async def test_return_proper_assignment(num_requests, preferred_batch_size, timeout, flush_all, allow_concurrent):\n+async def test_return_proper_assignment(num_requests, preferred_batch_size, timeout, flush_all):\n     import random\n \n     async def foo(docs, **kwargs):\n@@ -343,7 +324,6 @@ async def foo(docs, **kwargs):\n         preferred_batch_size=preferred_batch_size,\n         flush_all=flush_all,\n         timeout=timeout,\n-        allow_concurrent=allow_concurrent\n     )\n \n     data_requests = [DataRequest() for _ in range(num_requests)]\n"},"summary":"## Summary of Merge Request\n\nДанный merge request направлен на упрощение и оптимизацию логики работы с очередью пакетов в `jina/serve`. Основные изменения включают удаление `asyncio.Lock` и `contextlib.AsyncExitStack` из `BatchQueue` и связанных с ними параметров `allow_concurrent`, что упрощает код и потенциально улучшает производительность. Экспертная оценка отмечает умеренную сложность изменений, положительное влияние на читаемость и упрощение кода (Code Style, Anti-Patterns), а также необходимость тщательного тестирования для проверки отсутствия проблем с конкурентным доступом (Design Patterns). Рекомендуется убедиться в корректности работы пакетирования после изменений и проверить все тесты.\n","antiPatterns":{"detailed_analysis":"Внесенные изменения в `jina/serve/runtimes/worker/batch_queue.py` направлены на упрощение логики управления блокировками в `BatchQueue`. Удаление `contextlib.AsyncExitStack` и `asyncio.Lock` и упрощение условий для `_data_lock` указывает на попытку уменьшить сложность и потенциальные проблемы с конкурентностью. Это положительно влияет на читаемость и потенциально снижает риск ошибок, связанных с блокировками. В тестах также были удалены параметры `allow_concurrent`, что упрощает тесты и уменьшает количество комбинаций для тестирования. Это улучшает общее качество кода, упрощая его и делая более понятным. ","recommendations":["Продолжать упрощать код, где это возможно, чтобы уменьшить сложность и повысить читаемость.","Убедиться, что удаление `allow_concurrent` не привело к регрессии в функциональности. Проверить тесты на предмет покрытия всех сценариев. "],"confidence":"High","score":9,"summary":"Изменения в `batch_queue.py` и тестах направлены на упрощение логики блокировок и улучшение читаемости кода, что положительно влияет на качество кода."},"complexity":{"justification":"Данный diff вносит изменения в `jina/serve/runtimes/worker/batch_queue.py`, `jina/serve/runtimes/worker/request_handling.py`, и несколько тестовых файлов. Основное изменение заключается в удалении `asyncio.Lock` и `contextlib.AsyncExitStack` из `BatchQueue` и связанных с ними параметров `allow_concurrent`. Это упрощает логику управления пакетированием и, вероятно, улучшает производительность. Объем изменений умеренный, затрагивает несколько файлов, но не вносит кардинальных изменений в архитектуру или критические компоненты. Изменения в основном касаются логики управления потоками и пакетированием запросов. Когнитивная нагрузка умеренная, так как изменения требуют понимания работы очередей и пакетирования, но не включают сложные алгоритмы. Риски умеренные, так как изменения направлены на оптимизацию и упрощение, но необходимо убедиться в корректности работы пакетирования после изменений.  Влияние на систему умеренное, затрагивает компоненты, отвечающие за обработку запросов.  Учитывая объем изменений, их характер, умеренную когнитивную нагрузку и умеренные риски, сложность классифицируется как Medium.","classification":"Medium"},"designPatterns":{"detailed_analysis":"Внесенные изменения направлены на удаление `asyncio.Lock` и `contextlib.AsyncExitStack` из `BatchQueue`. Это упрощает код и потенциально улучшает производительность, поскольку убирает лишние блокировки.  В коде были обнаружены изменения, которые затрагивают логику работы с очередью пакетов, в частности, удаление `allow_concurrent` и связанного с ним механизма блокировок. Это упрощает код, но требует тщательного анализа, чтобы убедиться в отсутствии проблем с конкурентным доступом.  Изменения затрагивают несколько файлов, включая `batch_queue.py`, `request_handling.py` и тесты.  В целом, изменения направлены на упрощение и оптимизацию кода, что является положительным моментом.","recommendations":["Провести тщательное тестирование, чтобы убедиться, что удаление блокировок не привело к проблемам с конкурентным доступом к данным.  Проверить, что все тесты проходят успешно после внесения изменений.  Убедиться, что производительность не ухудшилась после удаления блокировок."],"confidence":"High","score":8,"summary":"Изменения направлены на упрощение и оптимизацию кода, связанного с очередью пакетов, путем удаления механизмов блокировок."},"codeStyle":{"detailed_analysis":"Изменения в основном касаются удаления `allow_concurrent` и связанного с ним `_data_lock` из `BatchQueue` и зависимых файлов. Это упрощает логику и удаляет ненужные условные операторы. Изменения затрагивают несколько файлов, включая `batch_queue.py`, `request_handling.py`, и файлы тестов. В целом, изменения улучшают читаемость и упрощают код, удаляя неиспользуемые параметры и упрощая логику блокировок. Изменения в тестах также отражают удаление `allow_concurrent`.","recommendations":["Убедитесь, что удаление `allow_concurrent` не повлияло на производительность или функциональность в других частях системы. Проверьте все тесты, чтобы убедиться, что они по-прежнему проходят успешно после этих изменений."],"confidence":"High","score":8,"summary":"Удаление `allow_concurrent` и связанного с ним кода из `BatchQueue` и зависимых файлов. Улучшена читаемость и упрощена логика. Тесты обновлены."}},{"pull":{"id":6200,"html_url":"https://github.com/jina-ai/serve/pull/6200","title":"fix: pass params to iolet","body":"Goals:\n\n\n\nresolves #ISSUE-NUMBER\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n check and update documentation. See guide and ask the team.","is_merged":true,"diff":"diff --git a/jina/clients/base/http.py b/jina/clients/base/http.py\nindex 24c5f985f7e2e..c10cb40749e27 100644\n--- a/jina/clients/base/http.py\n+++ b/jina/clients/base/http.py\n@@ -181,6 +181,10 @@ async def _get_results(\n                         logger=self.logger,\n                         tracer_provider=self.tracer_provider,\n                         timeout=timeout,\n+                        max_attempts=max_attempts,\n+                        initial_backoff=initial_backoff,\n+                        max_backoff=max_backoff,\n+                        backoff_multiplier=backoff_multiplier,\n                         **kwargs,\n                     )\n                 )\n@@ -191,6 +195,10 @@ async def _get_results(\n                             logger=self.logger,\n                             tracer_provider=self.tracer_provider,\n                             timeout=timeout,\n+                            max_attempts=max_attempts,\n+                            initial_backoff=initial_backoff,\n+                            max_backoff=max_backoff,\n+                            backoff_multiplier=backoff_multiplier,\n                             **kwargs,\n                         )\n                         self.iolet = await self.iolet.__aenter__()\n"},"summary":"## MR Summary\n\nДанный merge request направлен на улучшение механизма повторных попыток и управления таймаутами в функции `_get_results`. Основные изменения включают добавление параметров `max_attempts`, `initial_backoff`, `max_backoff` и `backoff_multiplier`. Анализ показал низкую сложность изменений, соответствующую уровню \"Low\". Код соответствует стандартам, читаемый и понятный (оценка Code Style - 8). Внедренные изменения улучшают отказоустойчивость и не содержат анти-паттернов (оценка Anti-Patterns - 10, Design Patterns - 9).\n","antiPatterns":{"detailed_analysis":"Внесенные изменения добавляют параметры `max_attempts`, `initial_backoff`, `max_backoff`, и `backoff_multiplier` в вызовы `_get_results`. Это улучшает гибкость и отказоустойчивость, позволяя настраивать повторные попытки и задержки при возникновении ошибок. Анти-паттерны не обнаружены, код улучшен.","recommendations":[],"confidence":"High","score":10,"summary":"Изменения улучшают отказоустойчивость, не вводя анти-паттернов."},"complexity":{"justification":"Изменения включают в себя передачу параметров в методы _get_results. Объем изменений небольшой, затрагивает один файл. Изменения направлены на улучшение функциональности, но не затрагивают критические компоненты или сложную логику. Когнитивная нагрузка низкая, так как изменения понятны и не требуют глубокого понимания системы. Риски минимальны. Соответствует уровню сложности \"Low\".","classification":"Low"},"designPatterns":{"detailed_analysis":"Внесенные изменения добавляют параметры `max_attempts`, `initial_backoff`, `max_backoff`, и `backoff_multiplier` в вызовы `_get_results`. Это улучшает механизм повторных попыток и управления таймаутами, что является положительным изменением. Анти-паттерны не обнаружены.","recommendations":[],"confidence":"High","score":9,"summary":"Изменения улучшают механизм повторных попыток и управления таймаутами, анти-паттерны не обнаружены."},"codeStyle":{"detailed_analysis":"Изменения в основном касаются добавления параметров `max_attempts`, `initial_backoff`, `max_backoff` и `backoff_multiplier` в вызовы `_get_results`. Форматирование сохранено, отступы и пробелы соответствуют существующему коду. Имена переменных соответствуют общепринятым соглашениям. Изменения последовательны и согласуются с существующим кодом. Читаемость не ухудшилась, так как добавленные параметры логичны в контексте. Соответствие гайдлайнам не нарушено. В целом, код выглядит хорошо.","recommendations":[],"confidence":"High","score":8,"summary":"Изменения в коде соответствуют стандартам, добавлены новые параметры, код читаемый и понятный."}},{"pull":{"id":6199,"html_url":"https://github.com/jina-ai/serve/pull/6199","title":"fix: readd timeout","body":"Goals:\n\n\n\nresolves #ISSUE-NUMBER\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n check and update documentation. See guide and ask the team.","is_merged":true,"diff":"diff --git a/jina/clients/base/http.py b/jina/clients/base/http.py\nindex eaac304695403..24c5f985f7e2e 100644\n--- a/jina/clients/base/http.py\n+++ b/jina/clients/base/http.py\n@@ -180,6 +180,7 @@ async def _get_results(\n                     HTTPClientlet(\n                         logger=self.logger,\n                         tracer_provider=self.tracer_provider,\n+                        timeout=timeout,\n                         **kwargs,\n                     )\n                 )\n@@ -189,6 +190,7 @@ async def _get_results(\n                         self.iolet = HTTPClientlet(\n                             logger=self.logger,\n                             tracer_provider=self.tracer_provider,\n+                            timeout=timeout,\n                             **kwargs,\n                         )\n                         self.iolet = await self.iolet.__aenter__()\n"},"summary":"## MR Summary\n\nДанный merge request направлен на добавление параметра `timeout` в конструктор `HTTPClientlet`, что позволяет улучшить контроль над временем ожидания HTTP-запросов. Изменения минимальны по сложности (Low) и не затрагивают критические компоненты. Экспертная оценка подтверждает соответствие существующему стилю кодирования (Code Style: 9/10), отсутствие анти-паттернов (Anti-Patterns: 10/10) и улучшение дизайна (Design Patterns: 10/10). В целом, изменения направлены на повышение надежности и управляемости кода.\n","antiPatterns":{"detailed_analysis":"Внесенные изменения добавляют параметр `timeout` в конструктор `HTTPClientlet`. Это улучшает контроль над временем ожидания HTTP-запросов, что является хорошей практикой и не вводит анти-паттернов. Изменения направлены на повышение надежности и управляемости кода.","recommendations":[],"confidence":"High","score":10,"summary":"Изменения не содержат анти-паттернов и улучшают контроль над временем ожидания HTTP-запросов."},"complexity":{"justification":"Изменения включают в себя добавление параметра `timeout` в два места в коде, что является простым изменением. Объем изменений небольшой, затрагивает один файл и несколько строк. Изменения не затрагивают критические компоненты или сложную логику. Когнитивная нагрузка низкая, так как изменения легко понять. Риски минимальны. Это соответствует характеристикам уровня сложности \"Low\".","classification":"Low"},"designPatterns":{"detailed_analysis":"Внесенные изменения добавляют параметр `timeout` в конструктор `HTTPClientlet`. Это улучшает контроль над временем ожидания сетевых операций, что является хорошей практикой и не вводит анти-паттернов. Изменения незначительны и не влияют на общую структуру кода.","recommendations":[],"confidence":"High","score":10,"summary":"Изменения не содержат анти-паттернов и улучшают контроль над сетевыми операциями."},"codeStyle":{"detailed_analysis":"Изменения в основном касаются добавления параметра `timeout` в конструктор `HTTPClientlet`. Форматирование сохранено, отступы и пробелы соответствуют существующему коду. Именование переменных и функций соответствует общепринятым соглашениям. Читаемость кода не ухудшилась, добавление параметра не усложняет понимание логики. Соответствие гайдлайнам соблюдено.","recommendations":[],"confidence":"High","score":9,"summary":"Внесенные изменения незначительны и соответствуют существующему стилю кодирования. Код легко читается и соответствует принятым стандартам."}},{"pull":{"id":6198,"html_url":"https://github.com/jina-ai/serve/pull/6198","title":"ci: unblock grpcio version","body":"Goals:\n\n\n\nresolves #ISSUE-NUMBER\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n check and update documentation. See guide and ask the team.","is_merged":true,"diff":"diff --git a/Dockerfiles/pip.Dockerfile b/Dockerfiles/pip.Dockerfile\nindex 46a97c9ffe889..7172c449b29a8 100644\n--- a/Dockerfiles/pip.Dockerfile\n+++ b/Dockerfiles/pip.Dockerfile\n@@ -1,4 +1,4 @@\n-ARG PY_VERSION=3.7\n+ARG PY_VERSION=3.8\n ARG PIP_TAG\n \n FROM python:${PY_VERSION}-slim\ndiff --git a/Dockerfiles/test-pip.Dockerfile b/Dockerfiles/test-pip.Dockerfile\nindex 15bedd5b0ac28..43a1124990501 100644\n--- a/Dockerfiles/test-pip.Dockerfile\n+++ b/Dockerfiles/test-pip.Dockerfile\n@@ -1,4 +1,4 @@\n-ARG PY_VERSION=3.7\n+ARG PY_VERSION=3.8\n \n FROM python:${PY_VERSION}-slim\n \ndiff --git a/extra-requirements.txt b/extra-requirements.txt\nindex 025ccc10625f7..9df83c9a8310b 100644\n--- a/extra-requirements.txt\n+++ b/extra-requirements.txt\n@@ -27,9 +27,9 @@\n \n numpy:                      core\n protobuf>=3.19.0:           core\n-grpcio>=1.46.0,<=1.57.0:    core\n-grpcio-reflection>=1.46.0,<=1.57.0:  core\n-grpcio-health-checking>=1.46.0,<=1.57.0:  core\n+grpcio>=1.46.0,<=1.68.0:    core\n+grpcio-reflection>=1.46.0,<=1.68.0:  core\n+grpcio-health-checking>=1.46.0,<=1.68.0:  core\n pyyaml>=5.3.1:              core\n packaging>=20.0:            core\n docarray>=0.16.4:           core\n@@ -39,7 +39,7 @@ opentelemetry-api>=1.12.0:  core\n opentelemetry-instrumentation-grpc>=0.35b0:  core \n uvloop:                     perf,standard,devel\n prometheus_client>=0.12.0:  perf,standard,devel\n-opentelemetry-sdk>=1.14.0,<1.20.0:  perf,standard,devel\n+opentelemetry-sdk>=1.14.0:  perf,standard,devel\n opentelemetry-exporter-otlp>=1.12.0:  perf,standard,devel\n opentelemetry-exporter-prometheus>=0.33b0:  perf,standard,devel\n opentelemetry-instrumentation-aiohttp-client>=0.33b0:    perf,standard,devel\ndiff --git a/tests/docker_compose/conftest.py b/tests/docker_compose/conftest.py\nindex aa5fb844c3f5f..0fde722c4a688 100644\n--- a/tests/docker_compose/conftest.py\n+++ b/tests/docker_compose/conftest.py\n@@ -27,7 +27,7 @@ def image_name_tag_map():\n     return {\n         'reload-executor': '0.13.1',\n         'test-executor': '0.13.1',\n-        'test-executor-torch': '0.13.1',\n+        #'test-executor-torch': '0.13.1',\n         'executor-merger': '0.1.1',\n         'custom-gateway': '0.1.1',\n         'multiprotocol-gateway': '0.1.1',\ndiff --git a/tests/docker_compose/test_flow_docker_compose.py b/tests/docker_compose/test_flow_docker_compose.py\nindex a377cdbf8b40a..c6ec1565e3f48 100644\n--- a/tests/docker_compose/test_flow_docker_compose.py\n+++ b/tests/docker_compose/test_flow_docker_compose.py\n@@ -235,37 +235,37 @@ async def test_flow_with_configmap(flow_configmap, docker_images, tmpdir):\n         assert doc.tags['env'] == {'k1': 'v1', 'k2': 'v2'}\n \n \n-@pytest.mark.asyncio\n-@pytest.mark.timeout(3600)\n-@pytest.mark.parametrize(\n-    'docker_images',\n-    [['test-executor-torch', 'jinaai/jina']],\n-    indirect=True,\n-)\n-async def test_flow_with_workspace_and_tensors(logger, docker_images, tmpdir):\n-    flow = Flow(\n-        name='docker-compose-flow-with_workspace', port=9090, protocol='http'\n-    ).add(\n-        name='test_executor',\n-        uses=f'docker://{docker_images[0]}',\n-        workspace='/shared',\n-    )\n-\n-    dump_path = os.path.join(str(tmpdir), 'docker-compose-flow-workspace.yml')\n-    flow.to_docker_compose_yaml(dump_path)\n-\n-    with DockerComposeServices(dump_path):\n-        resp = await run_test(\n-            flow=flow,\n-            endpoint='/workspace',\n-        )\n-\n-    docs = resp[0].docs\n-    assert len(docs) == 10\n-    for doc in docs:\n-        assert doc.tags['workspace'] == '/shared/TestExecutor/0'\n-        assert doc.embedding.shape == (1000,)\n-        assert doc.tensor.shape == (1000,)\n+# @pytest.mark.asyncio\n+# @pytest.mark.timeout(3600)\n+# @pytest.mark.parametrize(\n+#     'docker_images',\n+#     [['test-executor-torch', 'jinaai/jina']],\n+#     indirect=True,\n+# )\n+# async def test_flow_with_workspace_and_tensors(logger, docker_images, tmpdir):\n+#     flow = Flow(\n+#         name='docker-compose-flow-with_workspace', port=9090, protocol='http'\n+#     ).add(\n+#         name='test_executor',\n+#         uses=f'docker://{docker_images[0]}',\n+#         workspace='/shared',\n+#     )\n+#\n+#     dump_path = os.path.join(str(tmpdir), 'docker-compose-flow-workspace.yml')\n+#     flow.to_docker_compose_yaml(dump_path)\n+#\n+#     with DockerComposeServices(dump_path):\n+#         resp = await run_test(\n+#             flow=flow,\n+#             endpoint='/workspace',\n+#         )\n+#\n+#     docs = resp[0].docs\n+#     assert len(docs) == 10\n+#     for doc in docs:\n+#         assert doc.tags['workspace'] == '/shared/TestExecutor/0'\n+#         assert doc.embedding.shape == (1000,)\n+#         assert doc.tensor.shape == (1000,)\n \n \n @pytest.mark.asyncio\ndiff --git a/tests/integration/deployment_http_composite/test_deployment_http_composite_docarray_v2.py b/tests/integration/deployment_http_composite/test_deployment_http_composite_docarray_v2.py\nindex dc3dbae646410..a12d91ac2be7b 100644\n--- a/tests/integration/deployment_http_composite/test_deployment_http_composite_docarray_v2.py\n+++ b/tests/integration/deployment_http_composite/test_deployment_http_composite_docarray_v2.py\n@@ -64,10 +64,10 @@ async def docs_with_params(\n @pytest.mark.parametrize('replicas', [1, 3])\n @pytest.mark.parametrize('include_gateway', [True, False])\n @pytest.mark.parametrize('cors', [True, False])\n-@pytest.mark.parametrize('protocols', [['grpc', 'http'], ['grpc'], ['http']])\n-@pytest.mark.parametrize('init_sleep_time', [0, 0.5, 5])\n+@pytest.mark.parametrize('protocols', [['grpc'], ['http']])\n+@pytest.mark.parametrize('init_sleep_time', [0, 5])\n @pytest.mark.skipif(not docarray_v2, reason='tests support for docarray>=0.30')\n-def test_slow_load_executor(\n+def test_slow_load_executor_docarray_v2(\n     replicas, include_gateway, protocols, init_sleep_time, cors\n ):\n     if replicas > 1 and not include_gateway:\n@@ -87,21 +87,21 @@ def test_slow_load_executor(\n             c = Client(protocol=protocol, port=port)\n             res = c.post(\n                 on='/foo',\n-                inputs=DocList[InputTestDoc]([InputTestDoc() for _ in range(10)]),\n+                inputs=DocList[InputTestDoc]([InputTestDoc() for _ in range(100)]),\n                 request_size=1,\n                 return_type=DocList[OutputTestDoc],\n             )\n-            assert len(res) == 10\n+            assert len(res) == 100\n             assert all(['foo' in doc.text for doc in res])\n             different_pids = set([doc.tags['pid'] for doc in res])\n             assert len(different_pids) == replicas\n             res = c.post(\n                 on='/bar',\n-                inputs=DocList[InputTestDoc]([InputTestDoc() for _ in range(10)]),\n+                inputs=DocList[InputTestDoc]([InputTestDoc() for _ in range(100)]),\n                 request_size=1,\n                 return_type=DocList[OutputTestDoc],\n             )\n-            assert len(res) == 10\n+            assert len(res) == 100\n             assert all(['bar' in doc.text for doc in res])\n             assert all([not doc.flag for doc in res])\n             different_pids = set([doc.tags['pid'] for doc in res])\n@@ -111,9 +111,9 @@ def test_slow_load_executor(\n @pytest.mark.parametrize('replicas', [1, 3])\n @pytest.mark.parametrize('include_gateway', [True, False])\n @pytest.mark.parametrize('protocol', ['grpc', 'http'])\n-@pytest.mark.parametrize('init_sleep_time', [0, 0.5, 5])\n+@pytest.mark.parametrize('init_sleep_time', [0, 5])\n @pytest.mark.skipif(not docarray_v2, reason='tests support for docarray>=0.30')\n-def test_post_from_deployment(replicas, include_gateway, protocol, init_sleep_time):\n+def test_post_from_deployment_docarray_v2(replicas, include_gateway, protocol, init_sleep_time):\n     if replicas > 1 and not include_gateway:\n         return\n     d = Deployment(\n@@ -126,7 +126,7 @@ def test_post_from_deployment(replicas, include_gateway, protocol, init_sleep_ti\n     with d:\n         res = d.post(\n             on='/foo',\n-            inputs=DocList[InputTestDoc]([InputTestDoc() for _ in range(10)]),\n+            inputs=DocList[InputTestDoc]([InputTestDoc() for _ in range(100)]),\n             request_size=1,\n             return_type=DocList[OutputTestDoc],\n         )\n@@ -135,11 +135,11 @@ def test_post_from_deployment(replicas, include_gateway, protocol, init_sleep_ti\n         assert len(different_pids) == replicas\n         res = d.post(\n             on='/bar',\n-            inputs=DocList[InputTestDoc]([InputTestDoc() for _ in range(10)]),\n+            inputs=DocList[InputTestDoc]([InputTestDoc() for _ in range(100)]),\n             request_size=1,\n             return_type=DocList[OutputTestDoc],\n         )\n-        assert len(res) == 10\n+        assert len(res) == 100\n         assert all(['bar' in doc.text for doc in res])\n         different_pids = set([doc.tags['pid'] for doc in res])\n         assert len(different_pids) == replicas\n@@ -149,7 +149,7 @@ def test_post_from_deployment(replicas, include_gateway, protocol, init_sleep_ti\n @pytest.mark.parametrize('include_gateway', [True, False])\n @pytest.mark.parametrize('protocols', [['http'], ['grpc', 'http']])\n @pytest.mark.skipif(not docarray_v2, reason='tests support for docarray>=0.30')\n-def test_base_executor(replicas, include_gateway, protocols):\n+def test_base_executor_docarray_v2(replicas, include_gateway, protocols):\n     if replicas > 1 and not include_gateway:\n         return\n     ports = [random_port() for _ in range(len(protocols))]\n@@ -171,12 +171,12 @@ def test_base_executor(replicas, include_gateway, protocols):\n             assert len(res) == 10\n \n \n-@pytest.mark.parametrize('replicas', [1, 3])\n-@pytest.mark.parametrize('include_gateway', [True, False])\n-@pytest.mark.parametrize('protocols', [['http'], ['grpc', 'http']])\n-@pytest.mark.parametrize('init_sleep_time', [0, 0.5, 5])\n+@pytest.mark.parametrize('replicas', [1])\n+@pytest.mark.parametrize('include_gateway', [False])\n+@pytest.mark.parametrize('protocols', [['grpc', 'http']])\n+@pytest.mark.parametrize('init_sleep_time', [0, 5])\n @pytest.mark.skipif(not docarray_v2, reason='tests support for docarray>=0.30')\n-def test_return_parameters(replicas, include_gateway, protocols, init_sleep_time):\n+def test_return_parameters_docarray_v2(replicas, include_gateway, protocols, init_sleep_time):\n     if replicas > 1 and not include_gateway:\n         return\n     ports = [random_port() for _ in range(len(protocols))]\n@@ -193,12 +193,12 @@ def test_return_parameters(replicas, include_gateway, protocols, init_sleep_time\n             c = Client(protocol=protocol, port=port)\n             res = c.post(\n                 on='/parameters',\n-                inputs=DocList[InputTestDoc]([InputTestDoc() for _ in range(10)]),\n+                inputs=DocList[InputTestDoc]([InputTestDoc() for _ in range(100)]),\n                 request_size=1,\n                 return_type=DocList[OutputTestDoc],\n                 return_responses=True,\n             )\n-            assert len(res) == 10\n+            assert len(res) == 100\n             assert all(\n                 ['__results__' in response.parameters.keys() for response in res]\n             )\n@@ -211,12 +211,12 @@ def test_return_parameters(replicas, include_gateway, protocols, init_sleep_time\n             assert len(different_pids) == replicas\n             res = c.post(\n                 on='/docsparams',\n-                inputs=DocList[InputTestDoc]([InputTestDoc() for _ in range(10)]),\n+                inputs=DocList[InputTestDoc]([InputTestDoc() for _ in range(100)]),\n                 parameters={'key': 'value'},\n                 request_size=1,\n                 return_type=DocList[OutputTestDoc],\n             )\n-            assert len(res) == 10\n+            assert len(res) == 100\n             assert all([doc.text == 'value' for doc in res])\n \n \n@@ -224,7 +224,7 @@ def test_return_parameters(replicas, include_gateway, protocols, init_sleep_time\n @pytest.mark.parametrize('include_gateway', [True, False])\n @pytest.mark.parametrize('protocols', [['http'], ['grpc', 'http']])\n @pytest.mark.skipif(not docarray_v2, reason='tests support for docarray>=0.30')\n-def test_invalid_protocols_with_shards(replicas, include_gateway, protocols):\n+def test_invalid_protocols_with_shards_docarray_v2(replicas, include_gateway, protocols):\n     if replicas > 1 and not include_gateway:\n         return\n     with pytest.raises(RuntimeError):\n@@ -242,7 +242,7 @@ def test_invalid_protocols_with_shards(replicas, include_gateway, protocols):\n @pytest.mark.parametrize('include_gateway', [True, False])\n @pytest.mark.parametrize('protocols', [['websocket'], ['grpc', 'websocket']])\n @pytest.mark.skipif(not docarray_v2, reason='tests support for docarray>=0.30')\n-def test_invalid_websocket_protocol(replicas, include_gateway, protocols):\n+def test_invalid_websocket_protocol_docarray_v2(replicas, include_gateway, protocols):\n     if replicas > 1 and not include_gateway:\n         return\n     with pytest.raises(RuntimeError):\ndiff --git a/tests/integration/docarray_v2/test_v2.py b/tests/integration/docarray_v2/test_v2.py\nindex f03fa4ddb9caf..5e86ae84e0d51 100644\n--- a/tests/integration/docarray_v2/test_v2.py\n+++ b/tests/integration/docarray_v2/test_v2.py\n@@ -24,6 +24,149 @@\n from jina.helper import random_port\n \n \n+@pytest.mark.parametrize(\n+    'protocols', [['grpc', 'http', 'websocket']]\n+)\n+@pytest.mark.parametrize('reduce', [False, True])\n+@pytest.mark.parametrize('sleep_time', [5])\n+@pytest.mark.skipif(\n+    'GITHUB_WORKFLOW' in os.environ,\n+    reason='tests support for docarray>=0.30 and not working on GITHUB since issue with restarting server in grpc',\n+)\n+def test_flow_with_shards_all_shards_return(protocols, reduce, sleep_time):\n+    from typing import List\n+\n+    from docarray import BaseDoc, DocList\n+    from docarray.documents import TextDoc\n+\n+    class TextDocWithId(TextDoc):\n+        id: str\n+        l: List[int] = []\n+\n+    class ResultTestDoc(BaseDoc):\n+        price: int = '2'\n+        l: List[int] = [3]\n+        matches: DocList[TextDocWithId]\n+\n+    class SimilarityTestIndexer(Executor):\n+        \"\"\"Simulates an indexer where no shard would fail, they all pass results\"\"\"\n+\n+        def __init__(self, sleep_time=0.1, *args, **kwargs):\n+            super().__init__(*args, **kwargs)\n+            self._docs = DocList[TextDocWithId]()\n+            time.sleep(sleep_time)\n+\n+        @requests(on=['/index'])\n+        def index(\n+                self, docs: DocList[TextDocWithId], **kwargs\n+        ) -> DocList[TextDocWithId]:\n+            for doc in docs:\n+                self._docs.append(doc)\n+\n+        @requests(on=['/search'])\n+        def search(\n+                self, docs: DocList[TextDocWithId], **kwargs\n+        ) -> DocList[ResultTestDoc]:\n+            resp = DocList[ResultTestDoc]()\n+            for q in docs:\n+                res = ResultTestDoc(id=q.id, matches=self._docs[0:3])\n+                resp.append(res)\n+            return resp\n+\n+    ports = [random_port() for _ in protocols]\n+    with Flow(protocol=protocols, port=ports).add(\n+            uses=SimilarityTestIndexer,\n+            uses_with={'sleep_time': sleep_time},\n+            shards=2,\n+            reduce=reduce,\n+    ):\n+        time.sleep(5)\n+        for port, protocol in zip(ports, protocols):\n+            c = Client(port=port, protocol=protocol)\n+            index_da = DocList[TextDocWithId](\n+                [TextDocWithId(id=f'{i}', text=f'ID {i}') for i in range(10)]\n+            )\n+            c.index(inputs=index_da, request_size=1, return_type=DocList[TextDocWithId])\n+\n+            responses = c.search(\n+                inputs=index_da[0:1], request_size=1, return_type=DocList[ResultTestDoc]\n+            )\n+            assert len(responses) == 1 if reduce else 2\n+            for r in responses:\n+                assert r.l[0] == 3\n+                assert len(r.matches) == 6\n+                for match in r.matches:\n+                    assert 'ID' in match.text\n+\n+\n+@pytest.mark.parametrize('reduce', [True, False])\n+@pytest.mark.parametrize('sleep_time', [5])\n+@pytest.mark.skipif(\n+    'GITHUB_WORKFLOW' in os.environ,\n+    reason='tests support for docarray>=0.30 and not working on GITHUB since issue with restarting server in grpc',\n+)\n+def test_deployments_with_shards_all_shards_return(reduce, sleep_time):\n+    from typing import List\n+\n+    from docarray import BaseDoc, DocList\n+    from docarray.documents import TextDoc\n+\n+    class TextDocWithId(TextDoc):\n+        id: str\n+        l: List[int] = []\n+\n+    class ResultTestDoc(BaseDoc):\n+        price: int = '2'\n+        l: List[int] = [3]\n+        matches: DocList[TextDocWithId]\n+\n+    class SimilarityTestIndexer(Executor):\n+        \"\"\"Simulates an indexer where no shard would fail, they all pass results\"\"\"\n+\n+        def __init__(self, sleep_time=0.1, *args, **kwargs):\n+            super().__init__(*args, **kwargs)\n+            self._docs = DocList[TextDocWithId]()\n+            time.sleep(sleep_time)\n+\n+        @requests(on=['/index'])\n+        def index(\n+                self, docs: DocList[TextDocWithId], **kwargs\n+        ) -> DocList[TextDocWithId]:\n+            for doc in docs:\n+                self._docs.append(doc)\n+\n+        @requests(on=['/search'])\n+        def search(\n+                self, docs: DocList[TextDocWithId], **kwargs\n+        ) -> DocList[ResultTestDoc]:\n+            resp = DocList[ResultTestDoc]()\n+            for q in docs:\n+                res = ResultTestDoc(id=q.id, matches=self._docs[0:3])\n+                resp.append(res)\n+            return resp\n+\n+    with Deployment(\n+            uses=SimilarityTestIndexer,\n+            uses_with={'sleep_time': sleep_time},\n+            shards=2,\n+            reduce=reduce,\n+    ) as dep:\n+        time.sleep(5)\n+        index_da = DocList[TextDocWithId](\n+            [TextDocWithId(id=f'{i}', text=f'ID {i}') for i in range(10)]\n+        )\n+        dep.index(inputs=index_da, request_size=1, return_type=DocList[TextDocWithId])\n+        responses = dep.search(\n+            inputs=index_da[0:1], request_size=1, return_type=DocList[ResultTestDoc]\n+        )\n+        assert len(responses) == 1 if reduce else 2\n+        for r in responses:\n+            assert r.l[0] == 3\n+            assert len(r.matches) == 6\n+            for match in r.matches:\n+                assert 'ID' in match.text\n+\n+\n @pytest.mark.parametrize(\n     'protocols', [['grpc'], ['http'], ['websocket'], ['grpc', 'http', 'websocket']]\n )\n@@ -46,6 +189,7 @@ def foo(self, docs: DocList[Image], **kwargs) -> DocList[Image]:\n \n     ports = [random_port() for _ in protocols]\n     with Flow(port=ports, protocol=protocols, replicas=replicas).add(uses=MyExecDifSchema) as f:\n+        time.sleep(5)\n         for port, protocol in zip(ports, protocols):\n             c = Client(port=port, protocol=protocol)\n             docs = c.post(\n@@ -93,7 +237,7 @@ def foo(self, docs: DocList[MyDoc], **kwargs) -> DocList[MyDoc]:\n \n \n @pytest.mark.parametrize(\n-    'protocols', [['grpc'], ['http'], ['websocket'], ['grpc', 'http', 'websocket']]\n+    'protocols', [['grpc'], ['http'], ['websocket']]\n )\n @pytest.mark.parametrize('replicas', [1, 3])\n def test_input_response_schema(protocols, replicas):\n@@ -203,7 +347,7 @@ async def task6(\n \n \n @pytest.mark.parametrize(\n-    'protocols', [['grpc'], ['http'], ['websocket'], ['grpc', 'http', 'websocket']]\n+    'protocols', [['grpc'], ['http'], ['websocket']]\n )\n @pytest.mark.parametrize('replicas', [1, 3])\n def test_different_output_input(protocols, replicas):\n@@ -474,7 +618,7 @@ def bar(self, docs: DocList[Output1], **kwargs) -> DocList[Output2]:\n \n \n @pytest.mark.parametrize(\n-    'protocols', [['grpc'], ['http'], ['websocket'], ['grpc', 'http', 'websocket']]\n+    'protocols', [['grpc'], ['http'], ['websocket']]\n )\n @pytest.mark.parametrize('reduce', [True, False])\n def test_complex_topology_bifurcation(protocols, reduce):\n@@ -1335,138 +1479,6 @@ def search(\n             assert q.text == r.text\n \n \n-@pytest.mark.parametrize('reduce', [True, False])\n-@pytest.mark.parametrize('sleep_time', [0.1, 5])\n-def test_deployments_with_shards_all_shards_return(reduce, sleep_time):\n-    from typing import List\n-\n-    from docarray import BaseDoc, DocList\n-    from docarray.documents import TextDoc\n-\n-    class TextDocWithId(TextDoc):\n-        id: str\n-        l: List[int] = []\n-\n-    class ResultTestDoc(BaseDoc):\n-        price: int = '2'\n-        l: List[int] = [3]\n-        matches: DocList[TextDocWithId]\n-\n-    class SimilarityTestIndexer(Executor):\n-        \"\"\"Simulates an indexer where no shard would fail, they all pass results\"\"\"\n-\n-        def __init__(self, sleep_time=0.1, *args, **kwargs):\n-            super().__init__(*args, **kwargs)\n-            self._docs = DocList[TextDocWithId]()\n-            time.sleep(sleep_time)\n-\n-        @requests(on=['/index'])\n-        def index(\n-                self, docs: DocList[TextDocWithId], **kwargs\n-        ) -> DocList[TextDocWithId]:\n-            for doc in docs:\n-                self._docs.append(doc)\n-\n-        @requests(on=['/search'])\n-        def search(\n-                self, docs: DocList[TextDocWithId], **kwargs\n-        ) -> DocList[ResultTestDoc]:\n-            resp = DocList[ResultTestDoc]()\n-            for q in docs:\n-                res = ResultTestDoc(id=q.id, matches=self._docs[0:3])\n-                resp.append(res)\n-            return resp\n-\n-    with Deployment(\n-            uses=SimilarityTestIndexer,\n-            uses_with={'sleep_time': sleep_time},\n-            shards=2,\n-            reduce=reduce,\n-    ) as dep:\n-        index_da = DocList[TextDocWithId](\n-            [TextDocWithId(id=f'{i}', text=f'ID {i}') for i in range(10)]\n-        )\n-        dep.index(inputs=index_da, request_size=1, return_type=DocList[TextDocWithId])\n-        responses = dep.search(\n-            inputs=index_da[0:1], request_size=1, return_type=DocList[ResultTestDoc]\n-        )\n-        assert len(responses) == 1 if reduce else 2\n-        for r in responses:\n-            assert r.l[0] == 3\n-            assert len(r.matches) == 6\n-            for match in r.matches:\n-                assert 'ID' in match.text\n-\n-\n-@pytest.mark.parametrize(\n-    'protocols', [['grpc'], ['http'], ['websocket'], ['grpc', 'http', 'websocket']]\n-)\n-@pytest.mark.parametrize('reduce', [True, False])\n-@pytest.mark.parametrize('sleep_time', [0.1, 5])\n-def test_flow_with_shards_all_shards_return(protocols, reduce, sleep_time):\n-    from typing import List\n-\n-    from docarray import BaseDoc, DocList\n-    from docarray.documents import TextDoc\n-\n-    class TextDocWithId(TextDoc):\n-        id: str\n-        l: List[int] = []\n-\n-    class ResultTestDoc(BaseDoc):\n-        price: int = '2'\n-        l: List[int] = [3]\n-        matches: DocList[TextDocWithId]\n-\n-    class SimilarityTestIndexer(Executor):\n-        \"\"\"Simulates an indexer where no shard would fail, they all pass results\"\"\"\n-\n-        def __init__(self, sleep_time=0.1, *args, **kwargs):\n-            super().__init__(*args, **kwargs)\n-            self._docs = DocList[TextDocWithId]()\n-            time.sleep(sleep_time)\n-\n-        @requests(on=['/index'])\n-        def index(\n-                self, docs: DocList[TextDocWithId], **kwargs\n-        ) -> DocList[TextDocWithId]:\n-            for doc in docs:\n-                self._docs.append(doc)\n-\n-        @requests(on=['/search'])\n-        def search(\n-                self, docs: DocList[TextDocWithId], **kwargs\n-        ) -> DocList[ResultTestDoc]:\n-            resp = DocList[ResultTestDoc]()\n-            for q in docs:\n-                res = ResultTestDoc(id=q.id, matches=self._docs[0:3])\n-                resp.append(res)\n-            return resp\n-\n-    ports = [random_port() for _ in protocols]\n-    with Flow(protocol=protocols, port=ports).add(\n-            uses=SimilarityTestIndexer,\n-            uses_with={'sleep_time': sleep_time},\n-            shards=2,\n-            reduce=reduce,\n-    ):\n-        for port, protocol in zip(ports, protocols):\n-            c = Client(port=port, protocol=protocol)\n-            index_da = DocList[TextDocWithId](\n-                [TextDocWithId(id=f'{i}', text=f'ID {i}') for i in range(10)]\n-            )\n-            c.index(inputs=index_da, request_size=1, return_type=DocList[TextDocWithId])\n-            responses = c.search(\n-                inputs=index_da[0:1], request_size=1, return_type=DocList[ResultTestDoc]\n-            )\n-            assert len(responses) == 1 if reduce else 2\n-            for r in responses:\n-                assert r.l[0] == 3\n-                assert len(r.matches) == 6\n-                for match in r.matches:\n-                    assert 'ID' in match.text\n-\n-\n def test_issue_shards_missmatch_endpoint_and_shard_with_lists():\n     class MyDoc(BaseDoc):\n         text: str\n@@ -1656,7 +1668,6 @@ def generate(\n             return DocList[MyRandomModel]([doc.b for doc in docs])\n \n     with Flow(protocol='http').add(uses=MyFailingExecutor) as f:\n-        input_doc = MyRandomModel(a='hello world')\n         res = f.post(\n             on='/generate',\n             inputs=[MyInputModel(b=MyRandomModel(a='hey'))],\ndiff --git a/tests/integration/network_failures/test_network_failures.py b/tests/integration/network_failures/test_network_failures.py\nindex 288275f917b6c..92d4e789d27ba 100644\n--- a/tests/integration/network_failures/test_network_failures.py\n+++ b/tests/integration/network_failures/test_network_failures.py\n@@ -100,13 +100,99 @@ def _test_error(gateway_port, error_ports, protocol):\n         assert str(port) in err_info.value.args[0]\n \n \n+@pytest.mark.parametrize('protocol', ['grpc', 'http'])\n+@pytest.mark.parametrize('fail_endpoint_discovery', [True, False])\n+@pytest.mark.asyncio\n+async def test_runtimes_reconnect(port_generator, protocol, fail_endpoint_discovery):\n+    # create gateway and workers manually, then terminate worker process to provoke an error\n+    worker_port = port_generator()\n+    gateway_port = port_generator()\n+    graph_description = '{\"start-gateway\": [\"pod0\"], \"pod0\": [\"end-gateway\"]}'\n+    pod_addresses = f'{{\"pod0\": [\"0.0.0.0:{worker_port}\"]}}'\n+\n+    gateway_process = _create_gateway(\n+        gateway_port, graph_description, pod_addresses, protocol\n+    )\n+\n+    BaseServer.wait_for_ready_or_shutdown(\n+        timeout=5.0,\n+        ctrl_address=f'0.0.0.0:{gateway_port}',\n+        ready_or_shutdown_event=multiprocessing.Event(),\n+    )\n+\n+    try:\n+        if fail_endpoint_discovery:\n+            # send request while Executor is not UP, WILL FAIL\n+            p = multiprocessing.Process(\n+                target=_send_request, args=(gateway_port, protocol)\n+            )\n+            p.start()\n+            p.join()\n+            assert p.exitcode != 0, f\"The _send_request #0 Process exited with exitcode {p.exitcode}\"  # The request will fail and raise\n+\n+        worker_process = _create_worker(worker_port)\n+        assert BaseServer.wait_for_ready_or_shutdown(\n+            timeout=5.0,\n+            ctrl_address=f'0.0.0.0:{worker_port}',\n+            ready_or_shutdown_event=multiprocessing.Event(),\n+        ), \"The BaseServer wait_for_ready_or_shutdown for worker_port failed\"\n+        time.sleep(3)\n+\n+        p = multiprocessing.Process(target=_send_request, args=(gateway_port, protocol))\n+        p.start()\n+        p.join()\n+        assert p.exitcode == 0, f\"The _send_request #1 Process exited with exitcode {p.exitcode}\"  # The request will not fail and raise\n+        worker_process.terminate()  # kill worker\n+        worker_process.join()\n+        assert not worker_process.is_alive()\n+\n+        # send request while Executor is not UP, WILL FAIL\n+        p = multiprocessing.Process(target=_send_request, args=(gateway_port, protocol))\n+        p.start()\n+        p.join()\n+        assert p.exitcode != 0, f\"The _send_request #2 Process exited with exitcode {p.exitcode}\"  # The request will not fail and rais\n+\n+        worker_process = _create_worker(worker_port)\n+\n+        time.sleep(3)\n+\n+        assert BaseServer.wait_for_ready_or_shutdown(\n+            timeout=5.0,\n+            ctrl_address=f'0.0.0.0:{worker_port}',\n+            ready_or_shutdown_event=multiprocessing.Event(),\n+        ), \"The BaseServer wait_for_ready_or_shutdown for worker_port failed\"\n+        p = multiprocessing.Process(target=_send_request, args=(gateway_port, protocol))\n+        p.start()\n+        p.join()\n+        assert (\n+                p.exitcode == 0\n+        ), f\"The _send_request #3 Process exited with exitcode {p.exitcode}\"  # The request will not fail and rais  # if exitcode != 0 then test in other process did not pass and this should fail\n+        # ----------- 2. test that gateways remain alive -----------\n+        # just do the same again, expecting the same failure\n+        worker_process.terminate()  # kill worker\n+        worker_process.join()\n+        assert not worker_process.is_alive(), \"Worker process is still alive\"\n+        assert (\n+                worker_process.exitcode == 0\n+        ), f\"The worker_process Process exited with exitcode {worker_process.exitcode}\" # if exitcode != 0 then test in other process did not pass and this should fail\n+\n+    except Exception as exc:\n+        print(f'===> Exception: {exc}')\n+        assert False\n+    finally:  # clean up runtimes\n+        gateway_process.terminate()\n+        gateway_process.join()\n+        worker_process.terminate()\n+        worker_process.join()\n+\n+\n @pytest.mark.parametrize(\n     'fail_before_endpoint_discovery', [True, False]\n )  # if not before, then after\n @pytest.mark.parametrize('protocol', ['http', 'websocket', 'grpc'])\n @pytest.mark.asyncio\n async def test_runtimes_headless_topology(\n-    port_generator, protocol, fail_before_endpoint_discovery\n+        port_generator, protocol, fail_before_endpoint_discovery\n ):\n     # create gateway and workers manually, then terminate worker process to provoke an error\n     worker_port = port_generator()\n@@ -134,7 +220,7 @@ async def test_runtimes_headless_topology(\n     )\n \n     if (\n-        fail_before_endpoint_discovery\n+            fail_before_endpoint_discovery\n     ):  # kill worker before having sent the first request, so before endpoint discov.\n         worker_process.terminate()\n         worker_process.join()\n@@ -150,7 +236,7 @@ async def test_runtimes_headless_topology(\n             p.start()\n             p.join()\n             assert (\n-                p.exitcode == 0\n+                    p.exitcode == 0\n             )  # if exitcode != 0 then test in other process did not pass and this should fail\n         else:\n             # just ping the Flow without having killed a worker before. This (also) performs endpoint discovery\n@@ -172,7 +258,7 @@ async def test_runtimes_headless_topology(\n         p.start()\n         p.join()\n         assert (\n-            p.exitcode == 0\n+                p.exitcode == 0\n         )  # if exitcode != 0 then test in other process did not pass and this should fail\n     except Exception:\n         assert False\n@@ -236,90 +322,8 @@ async def patch_process_data(self, requests_, context, **kwargs):\n         p.start()\n         p.join()\n         assert (\n-            p.exitcode == 0\n-        )  # if exitcode != 0 then test in other process did not pass and this should fail\n-    except Exception:\n-        assert False\n-    finally:  # clean up runtimes\n-        gateway_process.terminate()\n-        gateway_process.join()\n-        worker_process.terminate()\n-        worker_process.join()\n-\n-\n-@pytest.mark.parametrize('protocol', ['grpc', 'http', 'grpc'])\n-@pytest.mark.parametrize('fail_endpoint_discovery', [True, False])\n-@pytest.mark.asyncio\n-async def test_runtimes_reconnect(port_generator, protocol, fail_endpoint_discovery):\n-    # create gateway and workers manually, then terminate worker process to provoke an error\n-    worker_port = port_generator()\n-    gateway_port = port_generator()\n-    graph_description = '{\"start-gateway\": [\"pod0\"], \"pod0\": [\"end-gateway\"]}'\n-    pod_addresses = f'{{\"pod0\": [\"0.0.0.0:{worker_port}\"]}}'\n-\n-    gateway_process = _create_gateway(\n-        gateway_port, graph_description, pod_addresses, protocol\n-    )\n-\n-    BaseServer.wait_for_ready_or_shutdown(\n-        timeout=5.0,\n-        ctrl_address=f'0.0.0.0:{gateway_port}',\n-        ready_or_shutdown_event=multiprocessing.Event(),\n-    )\n-\n-    try:\n-        if fail_endpoint_discovery:\n-            # send request while Executor is not UP, WILL FAIL\n-            p = multiprocessing.Process(\n-                target=_send_request, args=(gateway_port, protocol)\n-            )\n-            p.start()\n-            p.join()\n-            assert p.exitcode != 0  # The request will fail and raise\n-\n-        worker_process = _create_worker(worker_port)\n-        assert BaseServer.wait_for_ready_or_shutdown(\n-            timeout=5.0,\n-            ctrl_address=f'0.0.0.0:{worker_port}',\n-            ready_or_shutdown_event=multiprocessing.Event(),\n-        )\n-\n-        p = multiprocessing.Process(target=_send_request, args=(gateway_port, protocol))\n-        p.start()\n-        p.join()\n-        assert p.exitcode == 0  # The request will not fail and raise\n-        worker_process.terminate()  # kill worker\n-        worker_process.join()\n-        assert not worker_process.is_alive()\n-\n-        # send request while Executor is not UP, WILL FAIL\n-        p = multiprocessing.Process(target=_send_request, args=(gateway_port, protocol))\n-        p.start()\n-        p.join()\n-        assert p.exitcode != 0\n-\n-        worker_process = _create_worker(worker_port)\n-\n-        assert BaseServer.wait_for_ready_or_shutdown(\n-            timeout=5.0,\n-            ctrl_address=f'0.0.0.0:{worker_port}',\n-            ready_or_shutdown_event=multiprocessing.Event(),\n-        )\n-        p = multiprocessing.Process(target=_send_request, args=(gateway_port, protocol))\n-        p.start()\n-        p.join()\n-        assert (\n-            p.exitcode == 0\n-        )  # if exitcode != 0 then test in other process did not pass and this should fail\n-        # ----------- 2. test that gateways remain alive -----------\n-        # just do the same again, expecting the same failure\n-        worker_process.terminate()  # kill worker\n-        worker_process.join()\n-        assert not worker_process.is_alive()\n-        assert (\n-            worker_process.exitcode == 0\n+                p.exitcode == 0\n         )  # if exitcode != 0 then test in other process did not pass and this should fail\n-\n     except Exception:\n         assert False\n     finally:  # clean up runtimes\n@@ -329,11 +333,11 @@ async def test_runtimes_reconnect(port_generator, protocol, fail_endpoint_discov\n         worker_process.join()\n \n \n-@pytest.mark.parametrize('protocol', ['grpc', 'http', 'grpc'])\n+@pytest.mark.parametrize('protocol', ['grpc', 'http'])\n @pytest.mark.parametrize('fail_endpoint_discovery', [True, False])\n @pytest.mark.asyncio\n async def test_runtimes_reconnect_replicas(\n-    port_generator, protocol, fail_endpoint_discovery\n+        port_generator, protocol, fail_endpoint_discovery\n ):\n     # create gateway and workers manually, then terminate worker process to provoke an error\n     worker_ports = [port_generator() for _ in range(3)]\n@@ -367,7 +371,7 @@ async def test_runtimes_reconnect_replicas(\n     p_first_check.start()\n     p_first_check.join()\n     assert (\n-        p_first_check.exitcode == 0\n+            p_first_check.exitcode == 0\n     )  # all replicas are connected. At the end, the Flow should return to this state.\n \n     worker_processes[1].terminate()  # kill 'middle' worker\n@@ -424,7 +428,7 @@ async def test_runtimes_reconnect_replicas(\n @pytest.mark.parametrize('fail_before_endpoint_discovery', [True, False])\n @pytest.mark.asyncio\n async def test_runtimes_replicas(\n-    port_generator, protocol, fail_before_endpoint_discovery\n+        port_generator, protocol, fail_before_endpoint_discovery\n ):\n     # create gateway and workers manually, then terminate worker process to provoke an error\n     worker_ports = [port_generator() for _ in range(3)]\n@@ -453,7 +457,7 @@ async def test_runtimes_replicas(\n     )\n \n     if (\n-        not fail_before_endpoint_discovery\n+            not fail_before_endpoint_discovery\n     ):  # make successful request and trigger endpoint discovery\n         # we have to do this in a new process because otherwise grpc will be sad and everything will crash :(\n         p = multiprocessing.Process(target=_send_request, args=(gateway_port, protocol))\n@@ -461,7 +465,7 @@ async def test_runtimes_replicas(\n         p.join()\n         # different replica should be picked, no error should be raised\n         assert (\n-            p.exitcode == 0\n+                p.exitcode == 0\n         )  # if exitcode != 0 then test in other process did not pass and this should fail\n \n     worker_processes[0].terminate()  # kill first worker\n@@ -469,7 +473,7 @@ async def test_runtimes_replicas(\n \n     try:\n         for _ in range(\n-            len(worker_ports)\n+                len(worker_ports)\n         ):  # make sure all workers are targeted by round robin\n             # ----------- 1. test that useful errors are given -----------\n             # we have to do this in a new process because otherwise grpc will be sad and everything will crash :(\n@@ -480,7 +484,7 @@ async def test_runtimes_replicas(\n             p.join()\n             # different replica should be picked, no error should be raised\n             assert (\n-                p.exitcode == 0\n+                    p.exitcode == 0\n             )  # if exitcode != 0 then test in other process did not pass and this should fail\n     except Exception:\n         assert False\n@@ -555,7 +559,7 @@ async def test_runtimes_headful_topology(port_generator, protocol, terminate_hea\n         p.start()\n         p.join()\n         assert (\n-            p.exitcode == 0\n+                p.exitcode == 0\n         )  # if exitcode != 0 then test in other process did not pass and this should fail\n         # ----------- 2. test that gateways remain alive -----------\n         # just do the same again, expecting the same outcome\n@@ -565,7 +569,7 @@ async def test_runtimes_headful_topology(port_generator, protocol, terminate_hea\n         p.start()\n         p.join()\n         assert (\n-            p.exitcode == 0\n+                p.exitcode == 0\n         )  # if exitcode != 0 then test in other process did not pass and this should fail\n     except Exception:\n         raise\n@@ -581,8 +585,8 @@ async def test_runtimes_headful_topology(port_generator, protocol, terminate_hea\n def _send_gql_request(gateway_port):\n     \"\"\"send request to gateway and see what happens\"\"\"\n     mutation = (\n-        f'mutation {{'\n-        + '''docs(data: {text: \"abcd\"}) { \n+            f'mutation {{'\n+            + '''docs(data: {text: \"abcd\"}) { \n                     id \n                 } \n             }\n@@ -601,20 +605,20 @@ def _test_gql_error(gateway_port, error_port):\n \n def _create_gqlgateway_runtime(graph_description, pod_addresses, port):\n     with AsyncNewLoopRuntime(\n-        set_gateway_parser().parse_args(\n-            [\n-                '--graph-description',\n-                graph_description,\n-                '--deployments-addresses',\n-                pod_addresses,\n-                '--port',\n-                str(port),\n-                '--expose-graphql-endpoint',\n-                '--protocol',\n-                'http',\n-            ]\n-        ),\n-        req_handler_cls=GatewayRequestHandler,\n+            set_gateway_parser().parse_args(\n+                [\n+                    '--graph-description',\n+                    graph_description,\n+                    '--deployments-addresses',\n+                    pod_addresses,\n+                    '--port',\n+                    str(port),\n+                    '--expose-graphql-endpoint',\n+                    '--protocol',\n+                    'http',\n+                ]\n+            ),\n+            req_handler_cls=GatewayRequestHandler,\n     ) as runtime:\n         runtime.run_forever()\n \n@@ -666,7 +670,7 @@ async def test_runtimes_graphql(port_generator):\n         p.start()\n         p.join()\n         assert (\n-            p.exitcode == 0\n+                p.exitcode == 0\n         )  # if exitcode != 0 then test in other process did not pass and this should fail\n         # ----------- 2. test that gateways remain alive -----------\n         # just do the same again, expecting the same outcome\n@@ -676,7 +680,7 @@ async def test_runtimes_graphql(port_generator):\n         p.start()\n         p.join()\n         assert (\n-            p.exitcode == 0\n+                p.exitcode == 0\n         )  # if exitcode != 0 then test in other process did not pass and this should fail\n     except Exception:\n         raise\ndiff --git a/tests/k8s_otel/test_k8s_instrumentation.py b/tests/k8s_otel/test_k8s_instrumentation.py\nindex 631f9849a3ed5..7f857fbc38bd8 100644\n--- a/tests/k8s_otel/test_k8s_instrumentation.py\n+++ b/tests/k8s_otel/test_k8s_instrumentation.py\n@@ -45,12 +45,12 @@ async def test_flow_resource_labeling(\n         'svc/gateway', NAMESPACE, svc_port=8080\n     ) as gateway_port:\n         from jina import Client\n-\n-        [docs async for docs in Client(port=gateway_port, asyncio=True).post(\"/\")]\n-\n-    # Give grace period for metrics and traces to be exported\n+        res = []\n+        async for docs in Client(port=gateway_port, asyncio=True).post(\"/\"):\n+            res.extend(docs)\n+    # # Give grace period for metrics and traces to be exported\n     await asyncio.sleep(60)\n-\n+    #\n     # Check Jaeger API\n     with k8s_cluster_v2.port_forward(\n         'svc/jaeger', otel_test_namespace, svc_port=16686\ndiff --git a/tests/unit/serve/instrumentation/conftest.py b/tests/unit/serve/instrumentation/conftest.py\nindex 93e037e0e3913..ad66789e2aeed 100644\n--- a/tests/unit/serve/instrumentation/conftest.py\n+++ b/tests/unit/serve/instrumentation/conftest.py\n@@ -2,7 +2,6 @@\n from pathlib import Path\n from typing import Callable, Dict, Tuple\n \n-import opentelemetry.sdk.metrics.export\n import opentelemetry.sdk.metrics.view\n import pytest\n from opentelemetry.sdk.metrics.export import (\n@@ -28,6 +27,7 @@ def __init__(\n             type, \"opentelemetry.sdk.metrics.view.Aggregation\"\n         ] = None,\n     ):\n+        print(f'JOAN IS HERE DIRMETRIC')\n         super().__init__(\n             preferred_temporality=preferred_temporality,\n             preferred_aggregation=preferred_aggregation,\n@@ -41,6 +41,7 @@ def export(\n         timeout_millis: float = 10_000,\n         **kwargs,\n     ) -> MetricExportResult:\n+        print(f'export to {self.metric_filename} => {metrics_data.to_json()[0:3]}')\n         self.f.write(metrics_data.to_json())\n         self.f.write('\\n')\n         self.f.flush()\n@@ -76,10 +77,11 @@ def monkeypatch_metric_exporter(\n         f.write('0')\n \n     def collect_metrics():\n-        with open(tick_counter_filename, 'r', encoding='utf-8') as f:\n-            tick_counter = int(f.read())\n-        with open(tick_counter_filename, 'w', encoding='utf-8') as f:\n-            f.write(str(tick_counter + 1))\n+        print(f'tick_counter_filename {tick_counter_filename}')\n+        with open(tick_counter_filename, 'r', encoding='utf-8') as ft:\n+            tick_counter = int(ft.read())\n+        with open(tick_counter_filename, 'w', encoding='utf-8') as ft2:\n+            ft2.write(str(tick_counter + 1))\n         time.sleep(2)\n \n     def _get_service_name(otel_measurement):\n@@ -89,13 +91,20 @@ def _get_service_name(otel_measurement):\n \n     def read_metrics():\n         def read_metric_file(filename):\n-            with open(filename, 'r', encoding='utf-8') as f:\n-                return json.loads(f.read())\n-\n-        return {\n-            _get_service_name(i): i\n-            for i in map(read_metric_file, metrics_path.glob('*'))\n-        }\n+            print(f'filename {filename}')\n+            with open(filename, 'r', encoding='utf-8') as fr:\n+                r = fr.read()\n+                print(f'READ {r[0:3]}')\n+                try:\n+                    return json.loads(r)\n+                except:\n+                    return None\n+\n+        ret = {}\n+        for i in map(read_metric_file, metrics_path.glob('*')):\n+            if i is not None:\n+                ret[_get_service_name(i)] = i\n+        return ret\n \n     class PatchedTextReader(PeriodicExportingMetricReader):\n         def __init__(self, *args, **kwargs) -> None:\ndiff --git a/tests/unit/serve/instrumentation/test_gateway_metric_labels.py b/tests/unit/serve/instrumentation/test_gateway_metric_labels.py\nindex 2d8eb08f0ff2d..757d2d9e41756 100644\n--- a/tests/unit/serve/instrumentation/test_gateway_metric_labels.py\n+++ b/tests/unit/serve/instrumentation/test_gateway_metric_labels.py\n@@ -26,7 +26,6 @@ def meow(self, docs, **kwargs):\n         f.post('/')\n         collect_metrics()\n         metrics = read_metrics()\n-        print(f' metrics {metrics.keys()}')\n         gateway_metrics = metrics['gateway/rep-0']['resource_metrics'][0][\n             'scope_metrics'\n         ][0]['metrics']\ndiff --git a/tests/unit/serve/instrumentation/test_instrumentation.py b/tests/unit/serve/instrumentation/test_instrumentation.py\nindex c1d1d8228cba8..d83dd0d65c559 100644\n--- a/tests/unit/serve/instrumentation/test_instrumentation.py\n+++ b/tests/unit/serve/instrumentation/test_instrumentation.py\n@@ -88,10 +88,10 @@ def _sleep():\n     }\n \n     @MetricsTimer(summary, histogram, labels)\n-    def _sleep():\n+    def _sleep_2():\n         time.sleep(0.1)\n \n-    _sleep()\n+    _sleep_2()\n \n     # Prometheus samples\n     summary_count_sample = [\n@@ -107,5 +107,5 @@ def _sleep():\n         .to_json()\n     )\n     assert 'time_taken_decorator' == histogram_metric['name']\n-    assert 1 == histogram_metric['data']['data_points'][0]['count']\n-    assert labels == histogram_metric['data']['data_points'][0]['attributes']\n+    assert 1 == histogram_metric['data']['data_points'][1]['count']\n+    assert labels == histogram_metric['data']['data_points'][1]['attributes']\n"},"summary":"## Summary:\n\nДанный Merge Request направлен на обновление зависимостей и рефакторинг тестов. Основные изменения включают в себя обновление версий `grpcio` и других зависимостей в `extra-requirements.txt`, изменение версии Python в Dockerfile, а также удаление или комментирование некоторых тестов. Экспертная оценка показала низкую сложность изменений. Код соответствует стандартам, за исключением небольших корректировок отступов в `tests/docker_compose/conftest.py`. Дизайн-паттерны не нарушены, анти-паттерны не обнаружены.\n","antiPatterns":{"detailed_analysis":"Внесенные изменения в основном касаются обновления версий зависимостей (grpcio, opentelemetry-sdk) и небольших изменений в тестах.  Не обнаружено явных анти-паттернов в этих изменениях.  Изменения в тестах, такие как удаление или комментирование строк, не приводят к ухудшению качества кода с точки зрения анти-паттернов.  Небольшие изменения в Dockerfile также не содержат анти-паттернов.","recommendations":[],"confidence":"High","score":9,"summary":"Внесенные изменения в основном безопасны и не содержат анти-паттернов."},"complexity":{"justification":"Это изменение в основном включает в себя обновление версий зависимостей, изменение версии Python в Dockerfile и удаление/комментирование некоторых тестов. Объем изменений небольшой, затрагивает несколько файлов, но не критические части системы. Изменения легко понять, и они не должны вызывать каких-либо серьезных рисков или проблем. Изменения в extra-requirements.txt и Dockerfile являются простыми конфигурационными изменениями. Удаление/комментирование тестов также не представляет большой сложности. Общая когнитивная нагрузка низкая.  Поэтому сложность классифицируется как низкая.","classification":"Low"},"designPatterns":{"detailed_analysis":"Внесенные изменения в основном касаются обновления версий зависимостей и рефакторинга тестов.  В файле `extra-requirements.txt` обновлены версии `grpcio` и связанные с ним библиотеки. В файлах Dockerfile обновлена версия python. В тестах удалены или закомментированы тесты, связанные с `test-executor-torch`.  В тестах `test_integration/deployment_http_composite/test_deployment_http_composite_docarray_v2.py` и `tests/integration/docarray_v2/test_v2.py` внесены изменения, связанные с параметризацией тестов и увеличением количества входных данных.  В целом, изменения направлены на улучшение стабильности и актуальности зависимостей, а также на расширение тестового покрытия. Анти-паттерны не обнаружены.","recommendations":[],"confidence":"High","score":10,"summary":"Изменения в основном направлены на обновление зависимостей и рефакторинг тестов, анти-паттерны не обнаружены."},"codeStyle":{"detailed_analysis":"Изменения в основном касаются обновления версий зависимостей, таких как `grpcio`, и внесения небольших изменений в конфигурацию Dockerfile и тесты.  Форматирование в целом соответствует стандартам, за исключением небольших изменений в отступах в файле `tests/docker_compose/conftest.py`, которые не критичны.  Имена переменных и функций в основном понятны и соответствуют общепринятым соглашениям.  Изменения в основном консистентны с существующим кодом.  Читаемость кода не ухудшилась, а в некоторых случаях даже улучшилась за счет удаления закомментированного кода.  Соответствие гайдлайнам в целом хорошее, за исключением небольших отклонений в форматировании.  В целом, изменения незначительны и не требуют серьезных исправлений стиля.","recommendations":["Небольшие корректировки отступов в `tests/docker_compose/conftest.py` для улучшения единообразия."],"confidence":"High","score":8,"summary":"Внесены незначительные изменения в зависимости и тесты, в основном соблюдающие стандарты кодирования."}},{"pull":{"id":6196,"html_url":"https://github.com/jina-ai/serve/pull/6196","title":"fix: reuse session","body":"Goals:\n\n\n\nresolves #ISSUE-NUMBER\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n check and update documentation. See guide and ask the team.","is_merged":true,"diff":"diff --git a/jina/clients/__init__.py b/jina/clients/__init__.py\nindex 6484240d771dd..bf31c068f1cee 100644\n--- a/jina/clients/__init__.py\n+++ b/jina/clients/__init__.py\n@@ -30,6 +30,7 @@ def Client(\n     prefetch: Optional[int] = 1000,\n     protocol: Optional[Union[str, List[str]]] = 'GRPC',\n     proxy: Optional[bool] = False,\n+    reuse_session: Optional[bool] = False,\n     suppress_root_logging: Optional[bool] = False,\n     tls: Optional[bool] = False,\n     traces_exporter_host: Optional[str] = None,\n@@ -59,6 +60,7 @@ def Client(\n               Used to control the speed of data input into a Flow. 0 disables prefetch (1000 requests is the default)\n     :param protocol: Communication protocol between server and client.\n     :param proxy: If set, respect the http_proxy and https_proxy environment variables. otherwise, it will unset these proxy variables before start. gRPC seems to prefer no proxy\n+    :param reuse_session: True if HTTPClient should reuse ClientSession. If true, user will be responsible to close it\n     :param suppress_root_logging: If set, then no root handlers will be suppressed from logging.\n     :param tls: If set, connect to gateway using tls encryption\n     :param traces_exporter_host: If tracing is enabled, this hostname will be used to configure the trace exporter agent.\n@@ -113,6 +115,7 @@ def Client(args: Optional['argparse.Namespace'] = None, **kwargs) -> Union[\n               Used to control the speed of data input into a Flow. 0 disables prefetch (1000 requests is the default)\n     :param protocol: Communication protocol between server and client.\n     :param proxy: If set, respect the http_proxy and https_proxy environment variables. otherwise, it will unset these proxy variables before start. gRPC seems to prefer no proxy\n+    :param reuse_session: True if HTTPClient should reuse ClientSession. If true, user will be responsible to close it\n     :param suppress_root_logging: If set, then no root handlers will be suppressed from logging.\n     :param tls: If set, connect to gateway using tls encryption\n     :param traces_exporter_host: If tracing is enabled, this hostname will be used to configure the trace exporter agent.\ndiff --git a/jina/clients/base/__init__.py b/jina/clients/base/__init__.py\nindex 7fe60b15f74e7..41ec147fbd74b 100644\n--- a/jina/clients/base/__init__.py\n+++ b/jina/clients/base/__init__.py\n@@ -29,9 +29,9 @@ class BaseClient(InstrumentationMixin, ABC):\n     \"\"\"\n \n     def __init__(\n-        self,\n-        args: Optional['argparse.Namespace'] = None,\n-        **kwargs,\n+            self,\n+            args: Optional['argparse.Namespace'] = None,\n+            **kwargs,\n     ):\n         if args and isinstance(args, argparse.Namespace):\n             self.args = args\n@@ -63,6 +63,12 @@ def __init__(\n         )\n         send_telemetry_event(event='start', obj_cls_name=self.__class__.__name__)\n \n+    async def close(self):\n+        \"\"\"Closes the potential resources of the Client.\n+        :return: Return whatever a close method may return\n+        \"\"\"\n+        return self.teardown_instrumentation()\n+\n     def teardown_instrumentation(self):\n         \"\"\"Shut down the OpenTelemetry tracer and meter if available. This ensures that the daemon threads for\n         exporting metrics data is properly cleaned up.\n@@ -118,7 +124,7 @@ def check_input(inputs: Optional['InputType'] = None, **kwargs) -> None:\n             raise BadClientInput from ex\n \n     def _get_requests(\n-        self, **kwargs\n+            self, **kwargs\n     ) -> Union[Iterator['Request'], AsyncIterator['Request']]:\n         \"\"\"\n         Get request in generator.\n@@ -177,13 +183,14 @@ def inputs(self, bytes_gen: 'InputType') -> None:\n \n     @abc.abstractmethod\n     async def _get_results(\n-        self,\n-        inputs: 'InputType',\n-        on_done: 'CallbackFnType',\n-        on_error: Optional['CallbackFnType'] = None,\n-        on_always: Optional['CallbackFnType'] = None,\n-        **kwargs,\n-    ): ...\n+            self,\n+            inputs: 'InputType',\n+            on_done: 'CallbackFnType',\n+            on_error: Optional['CallbackFnType'] = None,\n+            on_always: Optional['CallbackFnType'] = None,\n+            **kwargs,\n+    ):\n+        ...\n \n     @abc.abstractmethod\n     def _is_flow_ready(self, **kwargs) -> bool:\ndiff --git a/jina/clients/base/helper.py b/jina/clients/base/helper.py\nindex 620513ceec460..50f43ae69e264 100644\n--- a/jina/clients/base/helper.py\n+++ b/jina/clients/base/helper.py\n@@ -48,7 +48,6 @@ class AioHttpClientlet(ABC):\n \n     def __init__(\n         self,\n-        url: str,\n         logger: 'JinaLogger',\n         max_attempts: int = 1,\n         initial_backoff: float = 0.5,\n@@ -59,7 +58,6 @@ def __init__(\n     ) -> None:\n         \"\"\"HTTP Client to be used with the streamer\n \n-        :param url: url to send http/websocket request to\n         :param logger: jina logger\n         :param max_attempts: Number of sending attempts, including the original request.\n         :param initial_backoff: The first retry will happen with a delay of random(0, initial_backoff)\n@@ -68,7 +66,6 @@ def __init__(\n         :param tracer_provider: Optional tracer_provider that will be used to configure aiohttp tracing.\n         :param kwargs: kwargs  which will be forwarded to the `aiohttp.Session` instance. Used to pass headers to requests\n         \"\"\"\n-        self.url = url\n         self.logger = logger\n         self.msg_recv = 0\n         self.msg_sent = 0\n@@ -131,7 +128,6 @@ async def start(self):\n         \"\"\"\n         with ImportExtensions(required=True):\n             import aiohttp\n-\n         self.session = aiohttp.ClientSession(\n             **self._session_kwargs, trace_configs=self._trace_config\n         )\n@@ -154,9 +150,10 @@ class HTTPClientlet(AioHttpClientlet):\n \n     UPDATE_EVENT_PREFIX = 14  # the update event has the following format: \"event: update: {document_json}\"\n \n-    async def send_message(self, request: 'Request'):\n+    async def send_message(self, url, request: 'Request'):\n         \"\"\"Sends a POST request to the server\n \n+        :param url: the URL where to send the message\n         :param request: request as dict\n         :return: send post message\n         \"\"\"\n@@ -166,23 +163,24 @@ async def send_message(self, request: 'Request'):\n             req_dict['target_executor'] = req_dict['header']['target_executor']\n         for attempt in range(1, self.max_attempts + 1):\n             try:\n-                request_kwargs = {'url': self.url}\n+                request_kwargs = {'url': url}\n                 if not docarray_v2:\n                     request_kwargs['json'] = req_dict\n                 else:\n                     from docarray.base_doc.io.json import orjson_dumps\n \n                     request_kwargs['data'] = JinaJsonPayload(value=req_dict)\n+\n                 async with self.session.post(**request_kwargs) as response:\n                     try:\n                         r_str = await response.json()\n                     except aiohttp.ContentTypeError:\n                         r_str = await response.text()\n                     r_status = response.status\n-                    handle_response_status(response.status, r_str, self.url)\n-                    return r_status, r_str\n+                    handle_response_status(r_status, r_str, url)\n+                return r_status, r_str\n             except (ValueError, ConnectionError, BadClient, aiohttp.ClientError, aiohttp.ClientConnectionError) as err:\n-                self.logger.debug(f'Got an error: {err} sending POST to {self.url} in attempt {attempt}/{self.max_attempts}')\n+                self.logger.debug(f'Got an error: {err} sending POST to {url} in attempt {attempt}/{self.max_attempts}')\n                 await retry.wait_or_raise_err(\n                     attempt=attempt,\n                     err=err,\n@@ -193,19 +191,20 @@ async def send_message(self, request: 'Request'):\n                 )\n             except Exception as exc:\n                 self.logger.debug(\n-                    f'Got a non-retried error: {exc} sending POST to {self.url}')\n+                    f'Got a non-retried error: {exc} sending POST to {url}')\n                 raise exc\n \n-    async def send_streaming_message(self, doc: 'Document', on: str):\n+    async def send_streaming_message(self, url, doc: 'Document', on: str):\n         \"\"\"Sends a GET SSE request to the server\n \n+        :param url: the URL where to send the message\n         :param doc: Request Document\n         :param on: Request endpoint\n         :yields: responses\n         \"\"\"\n         req_dict = doc.to_dict() if hasattr(doc, \"to_dict\") else doc.dict()\n         request_kwargs = {\n-            'url': self.url,\n+            'url': url,\n             'headers': {'Accept': 'text/event-stream'},\n             'json': req_dict,\n         }\n@@ -219,13 +218,14 @@ async def send_streaming_message(self, doc: 'Document', on: str):\n                     elif event.startswith(b'end'):\n                         pass\n \n-    async def send_dry_run(self, **kwargs):\n+    async def send_dry_run(self, url, **kwargs):\n         \"\"\"Query the dry_run endpoint from Gateway\n+        :param url: the URL where to send the message\n         :param kwargs: keyword arguments to make sure compatible API with other clients\n         :return: send get message\n         \"\"\"\n         return await self.session.get(\n-            url=self.url, timeout=kwargs.get('timeout', None)\n+            url=url, timeout=kwargs.get('timeout', None)\n         ).__aenter__()\n \n     async def recv_message(self):\n@@ -267,8 +267,9 @@ async def __anext__(self):\n class WebsocketClientlet(AioHttpClientlet):\n     \"\"\"Websocket Client to be used with the streamer\"\"\"\n \n-    def __init__(self, *args, **kwargs) -> None:\n+    def __init__(self, url, *args, **kwargs) -> None:\n         super().__init__(*args, **kwargs)\n+        self.url = url\n         self.websocket = None\n         self.response_iter = None\n \ndiff --git a/jina/clients/base/http.py b/jina/clients/base/http.py\nindex 746bdf0e0acfd..eaac304695403 100644\n--- a/jina/clients/base/http.py\n+++ b/jina/clients/base/http.py\n@@ -23,6 +23,18 @@ class HTTPBaseClient(BaseClient):\n     def __init__(self, *args, **kwargs):\n         super().__init__(*args, **kwargs)\n         self._endpoints = []\n+        self.reuse_session = False\n+        self._lock = AsyncExitStack()\n+        self.iolet = None\n+\n+    async def close(self):\n+        \"\"\"Closes the potential resources of the Client.\n+        :return: Return whatever a close method may return\n+        \"\"\"\n+        ret = super().close()\n+        if self.iolet is not None:\n+            await self.iolet.__aexit__(None, None, None)\n+        return ret\n \n     async def _get_endpoints_from_openapi(self, **kwargs):\n         def extract_paths_by_method(spec):\n@@ -69,16 +81,27 @@ async def _is_flow_ready(self, **kwargs) -> bool:\n             try:\n                 proto = 'https' if self.args.tls else 'http'\n                 url = f'{proto}://{self.args.host}:{self.args.port}/dry_run'\n-                iolet = await stack.enter_async_context(\n-                    HTTPClientlet(\n-                        url=url,\n-                        logger=self.logger,\n-                        tracer_provider=self.tracer_provider,\n-                        **kwargs,\n+\n+                if not self.reuse_session:\n+                    iolet = await stack.enter_async_context(\n+                        HTTPClientlet(\n+                            logger=self.logger,\n+                            tracer_provider=self.tracer_provider,\n+                            **kwargs,\n+                        )\n                     )\n-                )\n+                else:\n+                    async with self._lock:\n+                        if self.iolet is None:\n+                            self.iolet = HTTPClientlet(\n+                                logger=self.logger,\n+                                tracer_provider=self.tracer_provider,\n+                                **kwargs,\n+                            )\n+                            await self.iolet.__aenter__()\n+                        iolet = self.iolet\n \n-                response = await iolet.send_dry_run(**kwargs)\n+                response = await iolet.send_dry_run(url=url, **kwargs)\n                 r_status = response.status\n \n                 r_str = await response.json()\n@@ -96,20 +119,20 @@ async def _is_flow_ready(self, **kwargs) -> bool:\n         return False\n \n     async def _get_results(\n-        self,\n-        inputs: 'InputType',\n-        on_done: 'CallbackFnType',\n-        on_error: Optional['CallbackFnType'] = None,\n-        on_always: Optional['CallbackFnType'] = None,\n-        max_attempts: int = 1,\n-        initial_backoff: float = 0.5,\n-        max_backoff: float = 0.1,\n-        backoff_multiplier: float = 1.5,\n-        results_in_order: bool = False,\n-        prefetch: Optional[int] = None,\n-        timeout: Optional[int] = None,\n-        return_type: Type[DocumentArray] = DocumentArray,\n-        **kwargs,\n+            self,\n+            inputs: 'InputType',\n+            on_done: 'CallbackFnType',\n+            on_error: Optional['CallbackFnType'] = None,\n+            on_always: Optional['CallbackFnType'] = None,\n+            max_attempts: int = 1,\n+            initial_backoff: float = 0.5,\n+            max_backoff: float = 0.1,\n+            backoff_multiplier: float = 1.5,\n+            results_in_order: bool = False,\n+            prefetch: Optional[int] = None,\n+            timeout: Optional[int] = None,\n+            return_type: Type[DocumentArray] = DocumentArray,\n+            **kwargs,\n     ):\n         \"\"\"\n         :param inputs: the callable\n@@ -152,22 +175,27 @@ async def _get_results(\n             else:\n                 url = f'{proto}://{self.args.host}:{self.args.port}/post'\n \n-            iolet = await stack.enter_async_context(\n-                HTTPClientlet(\n-                    url=url,\n-                    logger=self.logger,\n-                    tracer_provider=self.tracer_provider,\n-                    max_attempts=max_attempts,\n-                    initial_backoff=initial_backoff,\n-                    max_backoff=max_backoff,\n-                    backoff_multiplier=backoff_multiplier,\n-                    timeout=timeout,\n-                    **kwargs,\n+            if not self.reuse_session:\n+                iolet = await stack.enter_async_context(\n+                    HTTPClientlet(\n+                        logger=self.logger,\n+                        tracer_provider=self.tracer_provider,\n+                        **kwargs,\n+                    )\n                 )\n-            )\n+            else:\n+                async with self._lock:\n+                    if self.iolet is None:\n+                        self.iolet = HTTPClientlet(\n+                            logger=self.logger,\n+                            tracer_provider=self.tracer_provider,\n+                            **kwargs,\n+                        )\n+                        self.iolet = await self.iolet.__aenter__()\n+                iolet = self.iolet\n \n             def _request_handler(\n-                request: 'Request', **kwargs\n+                    request: 'Request', **kwargs\n             ) -> 'Tuple[asyncio.Future, Optional[asyncio.Future]]':\n                 \"\"\"\n                 For HTTP Client, for each request in the iterator, we `send_message` using\n@@ -176,7 +204,7 @@ def _request_handler(\n                 :param kwargs: kwargs\n                 :return: asyncio Task for sending message\n                 \"\"\"\n-                return asyncio.ensure_future(iolet.send_message(request=request)), None\n+                return asyncio.ensure_future(iolet.send_message(url=url, request=request)), None\n \n             def _result_handler(result):\n                 return result\n@@ -191,7 +219,7 @@ def _result_handler(result):\n                 **streamer_args,\n             )\n             async for response in streamer.stream(\n-                request_iterator=request_iterator, results_in_order=results_in_order\n+                    request_iterator=request_iterator, results_in_order=results_in_order\n             ):\n                 r_status, r_str = response\n                 handle_response_status(r_status, r_str, url)\n@@ -232,13 +260,13 @@ def _result_handler(result):\n                 yield resp\n \n     async def _get_streaming_results(\n-        self,\n-        on: str,\n-        inputs: 'Document',\n-        parameters: Optional[Dict] = None,\n-        return_type: Type[Document] = Document,\n-        timeout: Optional[int] = None,\n-        **kwargs,\n+            self,\n+            on: str,\n+            inputs: 'Document',\n+            parameters: Optional[Dict] = None,\n+            return_type: Type[Document] = Document,\n+            timeout: Optional[int] = None,\n+            **kwargs,\n     ):\n         proto = 'https' if self.args.tls else 'http'\n         endpoint = on.strip('/')\n@@ -248,17 +276,28 @@ async def _get_streaming_results(\n             url = f'{proto}://{self.args.host}:{self.args.port}/{endpoint}'\n         else:\n             url = f'{proto}://{self.args.host}:{self.args.port}/default'\n-\n-        iolet = HTTPClientlet(\n-            url=url,\n-            logger=self.logger,\n-            tracer_provider=self.tracer_provider,\n-            timeout=timeout,\n-            **kwargs,\n-        )\n-\n-        async with iolet:\n-            async for doc in iolet.send_streaming_message(doc=inputs, on=on):\n+        async with AsyncExitStack() as stack:\n+            if not self.reuse_session:\n+                iolet = await stack.enter_async_context(\n+                    HTTPClientlet(\n+                        logger=self.logger,\n+                        tracer_provider=self.tracer_provider,\n+                        timeout=timeout,\n+                        **kwargs,\n+                    )\n+                )\n+            else:\n+                async with self._lock:\n+                    if self.iolet is None:\n+                        self.iolet = HTTPClientlet(\n+                            logger=self.logger,\n+                            tracer_provider=self.tracer_provider,\n+                            timeout=timeout,\n+                            **kwargs,\n+                        )\n+                        await self.iolet.__aenter__()\n+                    iolet = self.iolet\n+            async for doc in iolet.send_streaming_message(url=url, doc=inputs, on=on):\n                 if not docarray_v2:\n                     yield Document.from_dict(json.loads(doc))\n                 else:\ndiff --git a/jina/clients/http.py b/jina/clients/http.py\nindex e811d75f46ec5..2698e316d007a 100644\n--- a/jina/clients/http.py\n+++ b/jina/clients/http.py\n@@ -9,6 +9,7 @@\n     PostMixin,\n     ProfileMixin,\n )\n+import asyncio\n \n \n class HTTPClient(\n@@ -80,3 +81,8 @@ async def async_inputs():\n             print(resp)\n \n     \"\"\"\n+\n+    def __init__(self, *args, **kwargs):\n+        super().__init__(*args, **kwargs)\n+        self._lock = asyncio.Lock()\n+        self.reuse_session = self.args.reuse_session\ndiff --git a/jina/orchestrate/flow/base.py b/jina/orchestrate/flow/base.py\nindex 9aec82444a280..0b0a36d47b3c7 100644\n--- a/jina/orchestrate/flow/base.py\n+++ b/jina/orchestrate/flow/base.py\n@@ -133,6 +133,7 @@ def __init__(\n         prefetch: Optional[int] = 1000,\n         protocol: Optional[Union[str, List[str]]] = 'GRPC',\n         proxy: Optional[bool] = False,\n+        reuse_session: Optional[bool] = False,\n         suppress_root_logging: Optional[bool] = False,\n         tls: Optional[bool] = False,\n         traces_exporter_host: Optional[str] = None,\n@@ -155,6 +156,7 @@ def __init__(\n               Used to control the speed of data input into a Flow. 0 disables prefetch (1000 requests is the default)\n         :param protocol: Communication protocol between server and client.\n         :param proxy: If set, respect the http_proxy and https_proxy environment variables. otherwise, it will unset these proxy variables before start. gRPC seems to prefer no proxy\n+        :param reuse_session: True if HTTPClient should reuse ClientSession. If true, user will be responsible to close it\n         :param suppress_root_logging: If set, then no root handlers will be suppressed from logging.\n         :param tls: If set, connect to gateway using tls encryption\n         :param traces_exporter_host: If tracing is enabled, this hostname will be used to configure the trace exporter agent.\n@@ -417,6 +419,7 @@ def __init__(\n               Used to control the speed of data input into a Flow. 0 disables prefetch (1000 requests is the default)\n         :param protocol: Communication protocol between server and client.\n         :param proxy: If set, respect the http_proxy and https_proxy environment variables. otherwise, it will unset these proxy variables before start. gRPC seems to prefer no proxy\n+        :param reuse_session: True if HTTPClient should reuse ClientSession. If true, user will be responsible to close it\n         :param suppress_root_logging: If set, then no root handlers will be suppressed from logging.\n         :param tls: If set, connect to gateway using tls encryption\n         :param traces_exporter_host: If tracing is enabled, this hostname will be used to configure the trace exporter agent.\ndiff --git a/jina/parsers/client.py b/jina/parsers/client.py\nindex 4f46ac390fe29..8f22375c8d24b 100644\n--- a/jina/parsers/client.py\n+++ b/jina/parsers/client.py\n@@ -81,3 +81,9 @@ def mixin_client_features_parser(parser):\n         default='default',\n         help='The config name or the absolute path to the YAML config file of the logger used in this object.',\n     )\n+    parser.add_argument(\n+        '--reuse-session',\n+        action='store_true',\n+        default=False,\n+        help='True if HTTPClient should reuse ClientSession. If true, user will be responsible to close it',\n+    )\ndiff --git a/jina_cli/autocomplete.py b/jina_cli/autocomplete.py\nindex e3f85ff9fc5d3..c5dda85e72573 100644\n--- a/jina_cli/autocomplete.py\n+++ b/jina_cli/autocomplete.py\n@@ -564,6 +564,7 @@\n             '--metrics-exporter-host',\n             '--metrics-exporter-port',\n             '--log-config',\n+            '--reuse-session',\n             '--protocol',\n             '--grpc-channel-options',\n             '--prefetch',\ndiff --git a/tests/integration/concurrent_clients/test_concurrent_clients.py b/tests/integration/concurrent_clients/test_concurrent_clients.py\nindex 546fe94da3314..898916ffe03cb 100644\n--- a/tests/integration/concurrent_clients/test_concurrent_clients.py\n+++ b/tests/integration/concurrent_clients/test_concurrent_clients.py\n@@ -23,19 +23,23 @@ def ping(self, **kwargs):\n @pytest.mark.parametrize('prefetch', [1, 10])\n @pytest.mark.parametrize('concurrent', [15])\n @pytest.mark.parametrize('use_stream', [False, True])\n+@pytest.mark.parametrize('reuse_session', [True, False])\n def test_concurrent_clients(\n-    concurrent, protocol, shards, polling, prefetch, reraise, use_stream\n+    concurrent, protocol, shards, polling, prefetch, reraise, use_stream, reuse_session\n ):\n \n     if not use_stream and protocol != 'grpc':\n         return\n \n+    if reuse_session and protocol != 'http':\n+        return\n+\n     def pong(peer_hash, queue, resp: Response):\n         for d in resp.docs:\n             queue.put((peer_hash, d.text))\n \n     def peer_client(port, protocol, peer_hash, queue):\n-        c = Client(protocol=protocol, port=port)\n+        c = Client(protocol=protocol, port=port, reuse_session=reuse_session)\n         for _ in range(NUM_REQUESTS):\n             c.post(\n                 '/ping',\ndiff --git a/tests/integration/docarray_v2/test_singleton.py b/tests/integration/docarray_v2/test_singleton.py\nindex e8cd663eb10d5..7405df29a4792 100644\n--- a/tests/integration/docarray_v2/test_singleton.py\n+++ b/tests/integration/docarray_v2/test_singleton.py\n@@ -13,7 +13,10 @@\n )\n @pytest.mark.parametrize('return_type', ['batch', 'singleton'])\n @pytest.mark.parametrize('include_gateway', [True, False])\n-def test_singleton_return(ctxt_manager, protocols, return_type, include_gateway):\n+@pytest.mark.parametrize('reuse_session', [True, False])\n+def test_singleton_return(ctxt_manager, protocols, return_type, include_gateway, reuse_session):\n+    if reuse_session and 'http' not in protocols:\n+        return\n     if 'websocket' in protocols and ctxt_manager != 'flow':\n         return\n     if not include_gateway and ctxt_manager == 'flow':\n@@ -63,7 +66,7 @@ def foo_single(\n \n     with ctxt:\n         for port, protocol in zip(ports, protocols):\n-            c = Client(port=port, protocol=protocol)\n+            c = Client(port=port, protocol=protocol, reuse_session=reuse_session)\n             docs = c.post(\n                 on='/foo',\n                 inputs=MySingletonReturnInputDoc(text='hello', price=2),\n@@ -102,7 +105,10 @@ def foo_single(\n     'protocols', [['grpc'], ['http'], ['websocket'], ['grpc', 'http']]\n )\n @pytest.mark.parametrize('return_type', ['batch', 'singleton'])\n-def test_singleton_return_async(ctxt_manager, protocols, return_type):\n+@pytest.mark.parametrize('reuse_session', [True, False])\n+def test_singleton_return_async(ctxt_manager, protocols, return_type, reuse_session):\n+    if reuse_session and 'http' not in protocols:\n+        return\n     if 'websocket' in protocols and ctxt_manager != 'flow':\n         return\n \n@@ -149,7 +155,7 @@ async def foo_single(\n \n     with ctxt:\n         for port, protocol in zip(ports, protocols):\n-            c = Client(port=port, protocol=protocol)\n+            c = Client(port=port, protocol=protocol, reuse_session=reuse_session)\n             docs = c.post(\n                 on='/foo',\n                 inputs=MySingletonReturnInputDoc(text='hello', price=2),\ndiff --git a/tests/integration/streaming/test_streaming.py b/tests/integration/streaming/test_streaming.py\nindex 5d2f6e4af848b..7f6675ec57e1f 100644\n--- a/tests/integration/streaming/test_streaming.py\n+++ b/tests/integration/streaming/test_streaming.py\n@@ -23,7 +23,10 @@ async def non_gen_task(self, docs: DocumentArray, **kwargs):\n @pytest.mark.asyncio\n @pytest.mark.parametrize('protocol', ['http', 'grpc'])\n @pytest.mark.parametrize('include_gateway', [False, True])\n-async def test_streaming_deployment(protocol, include_gateway):\n+@pytest.mark.parametrize('reuse_session', [False, True])\n+async def test_streaming_deployment(protocol, include_gateway, reuse_session):\n+    if reuse_session and protocol != 'http':\n+        return\n \n     port = random_port()\n     docs = []\n@@ -35,7 +38,7 @@ async def test_streaming_deployment(protocol, include_gateway):\n         port=port,\n         include_gateway=include_gateway,\n     ):\n-        client = Client(port=port, protocol=protocol, asyncio=True)\n+        client = Client(port=port, protocol=protocol, asyncio=True, reuse_session=reuse_session)\n         i = 0\n         async for doc in client.stream_doc(\n             on='/hello',\n@@ -60,7 +63,10 @@ async def task(self, doc: Document, **kwargs):\n @pytest.mark.asyncio\n @pytest.mark.parametrize('protocol', ['http', 'grpc'])\n @pytest.mark.parametrize('include_gateway', [False, True])\n-async def test_streaming_delay(protocol, include_gateway):\n+@pytest.mark.parametrize('reuse_session', [False, True])\n+async def test_streaming_delay(protocol, include_gateway, reuse_session):\n+    if reuse_session and protocol != 'http':\n+        return\n     from jina import Deployment\n \n     port = random_port()\n@@ -72,7 +78,7 @@ async def test_streaming_delay(protocol, include_gateway):\n         port=port,\n         include_gateway=include_gateway,\n     ):\n-        client = Client(port=port, protocol=protocol, asyncio=True)\n+        client = Client(port=port, protocol=protocol, asyncio=True, reuse_session=reuse_session)\n         i = 0\n         start_time = time.time()\n         async for doc in client.stream_doc(\ndiff --git a/tests/unit/clients/python/test_client.py b/tests/unit/clients/python/test_client.py\nindex 85d7371e52d31..addcb07dadffb 100644\n--- a/tests/unit/clients/python/test_client.py\n+++ b/tests/unit/clients/python/test_client.py\n@@ -156,7 +156,6 @@ def test_all_sync_clients(protocol, mocker, use_stream):\n     m3.assert_called_once()\n     m4.assert_called()\n \n-\n @pytest.mark.slow\n @pytest.mark.parametrize('use_stream', [True, False])\n def test_deployment_sync_client(mocker, use_stream):\ndiff --git a/tests/unit/clients/test_helper.py b/tests/unit/clients/test_helper.py\nindex 66ae0d9081f38..55182b066616e 100644\n--- a/tests/unit/clients/test_helper.py\n+++ b/tests/unit/clients/test_helper.py\n@@ -33,11 +33,11 @@ async def test_http_clientlet():\n     port = random_port()\n     with Flow(port=port, protocol='http').add():\n         async with HTTPClientlet(\n-            url=f'http://localhost:{port}/post', logger=logger\n+            logger=logger\n         ) as iolet:\n             request = _new_data_request('/', None, {'a': 'b'})\n             assert request.header.target_executor == ''\n-            r_status, r_json = await iolet.send_message(request)\n+            r_status, r_json = await iolet.send_message(url=f'http://localhost:{port}/post', request=request)\n             response = DataRequest(r_json)\n     assert response.header.exec_endpoint == '/'\n     assert response.parameters == {'a': 'b'}\n@@ -50,11 +50,11 @@ async def test_http_clientlet_target():\n     port = random_port()\n     with Flow(port=port, protocol='http').add():\n         async with HTTPClientlet(\n-            url=f'http://localhost:{port}/post', logger=logger\n+            logger=logger\n         ) as iolet:\n             request = _new_data_request('/', 'nothing', {'a': 'b'})\n             assert request.header.target_executor == 'nothing'\n-            r = await iolet.send_message(request)\n+            r = await iolet.send_message(url=f'http://localhost:{port}/post', request=request)\n             r_status, r_json = r\n             response = DataRequest(r_json)\n     assert response.header.exec_endpoint == '/'\ndiff --git a/tests/unit/orchestrate/flow/flow-async/test_asyncflow.py b/tests/unit/orchestrate/flow/flow-async/test_asyncflow.py\nindex df98e4cc14214..00901322ee50b 100644\n--- a/tests/unit/orchestrate/flow/flow-async/test_asyncflow.py\n+++ b/tests/unit/orchestrate/flow/flow-async/test_asyncflow.py\n@@ -41,11 +41,14 @@ def documents(start_index, end_index):\n     'return_responses, return_class', [(True, Request), (False, DocumentArray)]\n )\n @pytest.mark.parametrize('use_stream', [False, True])\n+@pytest.mark.parametrize('reuse_session', [False, True])\n async def test_run_async_flow(\n-    protocol, mocker, flow_cls, return_responses, return_class, use_stream\n+    protocol, mocker, flow_cls, return_responses, return_class, use_stream, reuse_session\n ):\n+    if reuse_session and protocol != 'http':\n+        return\n     r_val = mocker.Mock()\n-    with flow_cls(protocol=protocol, asyncio=True).add() as f:\n+    with flow_cls(protocol=protocol, asyncio=True, reuse_session=reuse_session).add() as f:\n         async for r in f.index(\n             from_ndarray(np.random.random([num_docs, 4])),\n             on_done=r_val,\n@@ -155,8 +158,11 @@ async def test_run_async_flow_other_task_concurrent(protocol):\n @pytest.mark.parametrize('protocol', ['websocket', 'grpc', 'http'])\n @pytest.mark.parametrize('flow_cls', [Flow, AsyncFlow])\n @pytest.mark.parametrize('use_stream', [False, True])\n-async def test_return_results_async_flow(protocol, flow_cls, use_stream):\n-    with flow_cls(protocol=protocol, asyncio=True).add() as f:\n+@pytest.mark.parametrize('reuse_session', [False, True])\n+async def test_return_results_async_flow(protocol, flow_cls, use_stream, reuse_session):\n+    if reuse_session and protocol != 'http':\n+        return\n+    with flow_cls(protocol=protocol, asyncio=True, reuse_session=reuse_session).add() as f:\n         async for r in f.index(\n             from_ndarray(np.random.random([10, 2])), stream=use_stream\n         ):\n@@ -169,8 +175,9 @@ async def test_return_results_async_flow(protocol, flow_cls, use_stream):\n @pytest.mark.parametrize('flow_api', ['delete', 'index', 'update', 'search'])\n @pytest.mark.parametrize('flow_cls', [Flow, AsyncFlow])\n @pytest.mark.parametrize('use_stream', [False, True])\n-async def test_return_results_async_flow_crud(protocol, flow_api, flow_cls, use_stream):\n-    with flow_cls(protocol=protocol, asyncio=True).add() as f:\n+@pytest.mark.parametrize('reuse_session', [False, True])\n+async def test_return_results_async_flow_crud(protocol, flow_api, flow_cls, use_stream, reuse_session):\n+    with flow_cls(protocol=protocol, asyncio=True, reuse_session=reuse_session).add() as f:\n         async for r in getattr(f, flow_api)(documents(0, 10), stream=use_stream):\n             assert isinstance(r, DocumentArray)\n \n"},"summary":"## Summary of Merge Request\n\nДанный MR направлен на оптимизацию работы HTTP-клиента в Jina путем добавления возможности повторного использования HTTP-сессий. Основные изменения включают добавление параметра `reuse_session` в классы `Client` и `Flow`, а также модификации в `HTTPClient` для управления сессиями. Экспертная оценка указывает на среднюю сложность изменений, хорошую читаемость кода и соответствие стандартам, хотя и рекомендует убедиться в корректной обработке сессий во всех сценариях. Реализация паттерна повторного использования сессий оценена положительно, анти-паттерны не обнаружены. Рекомендуется тщательное тестирование для предотвращения утечек ресурсов.\n","antiPatterns":{"detailed_analysis":"Внесенные изменения добавляют параметр `reuse_session` в `Client` и `Flow`, а также реализуют логику повторного использования сессий HTTP-клиента. Это позволяет избежать создания новых сессий для каждого запроса, что может улучшить производительность, особенно при большом количестве запросов.  В коде были внесены изменения в `jina/clients/__init__.py`, `jina/clients/base/__init__.py`, `jina/clients/base/helper.py`, `jina/clients/base/http.py`, `jina/clients/http.py`, `jina/orchestrate/flow/base.py`, `jina/parsers/client.py`, `jina_cli/autocomplete.py`, и тесты.  В частности, в `jina/clients/base/http.py` реализована логика повторного использования сессии, а также добавлены методы `close` для корректного завершения работы с сессией.  Эти изменения направлены на оптимизацию работы HTTP-клиента и не содержат анти-паттернов.","recommendations":["Рекомендуется тщательно протестировать изменения, чтобы убедиться в корректной работе повторного использования сессий и отсутствии утечек ресурсов.","Убедитесь, что закрытие сессий происходит корректно во всех сценариях использования, особенно при возникновении ошибок."],"confidence":"High","score":9,"summary":"Внесенные изменения направлены на оптимизацию работы HTTP-клиента путем повторного использования сессий, что является хорошей практикой."},"complexity":{"justification":"Изменения включают в себя добавление нового параметра `reuse_session` в `Client` и связанные с этим изменения в нескольких файлах. Это влияет на логику работы HTTP-клиента, позволяя ему повторно использовать `ClientSession`. Объем изменений умеренный, затрагивает несколько файлов, но не затрагивает критические компоненты системы. Изменения требуют понимания работы HTTP-клиента и управления сессиями, но не вводят сложную логику или архитектурные изменения. Риски умеренные, так как изменения в основном касаются конфигурации и управления ресурсами.  Поэтому сложность классифицируется как средняя.","classification":"Medium"},"designPatterns":{"detailed_analysis":"Внесенные изменения добавляют параметр `reuse_session` в `Client` и `Flow`, а также вносят изменения в `HTTPClientlet` и `HTTPBaseClient` для поддержки повторного использования сессий. Это позволяет избежать создания новых сессий для каждого запроса, что может улучшить производительность, особенно при большом количестве запросов.  В коде были внесены изменения, чтобы правильно управлять жизненным циклом сессий, включая их закрытие при необходимости.  Анти-паттерны не обнаружены, изменения направлены на оптимизацию работы HTTP-клиента.","recommendations":[],"confidence":"High","score":9,"summary":"Внесенные изменения улучшают производительность HTTP-клиента за счет повторного использования сессий."},"codeStyle":{"detailed_analysis":"Изменения включают добавление параметра `reuse_session` в `Client` и `Flow`, а также его использование в `HTTPClient`. Это позволяет повторно использовать сессии HTTP, что может повысить производительность. Изменения затрагивают несколько файлов, включая `jina/clients/__init__.py`, `jina/clients/base/__init__.py`, `jina/clients/base/helper.py`, `jina/clients/base/http.py`, `jina/clients/http.py`, `jina/orchestrate/flow/base.py`, `jina/parsers/client.py`, `jina_cli/autocomplete.py` и файлы тестов.  Форматирование в целом соответствует стандартам, за исключением незначительных отклонений. Имена переменных и функций понятны и соответствуют соглашениям. Консистентность соблюдена во всех измененных файлах. Читаемость кода хорошая, добавлены комментарии для пояснения логики. Соответствие гайдлайнам в основном соблюдено, за исключением, возможно, незначительных отклонений в форматировании.  В целом, изменения хорошо структурированы и соответствуют поставленной задаче.","recommendations":["Убедитесь, что повторное использование сессий HTTP корректно обрабатывается во всех сценариях использования, особенно в многопоточных средах.","Проверьте, что закрытие сессий HTTP выполняется корректно, чтобы избежать утечек ресурсов."],"confidence":"High","score":8,"summary":"Внесены изменения для поддержки повторного использования сессий HTTP в клиентах Jina, что потенциально улучшает производительность. Код соответствует стандартам, но требует небольшой доработки для обеспечения корректности и безопасности."}},{"pull":{"id":6195,"html_url":"https://github.com/jina-ai/serve/pull/6195","title":"refactor: do not return response object","body":"Goals:\n\n\n\nresolves #ISSUE-NUMBER\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n check and update documentation. See guide and ask the team.","is_merged":true,"diff":"diff --git a/.github/workflows/cd.yml b/.github/workflows/cd.yml\nindex f798aae20b3a4..805582199bfb3 100644\n--- a/.github/workflows/cd.yml\n+++ b/.github/workflows/cd.yml\n@@ -402,7 +402,7 @@ jobs:\n           python -m cibuildwheel --output-dir dist\n \n       - name: Upload wheels as artifacts\n-        uses: actions/upload-artifact@v2\n+        uses: actions/upload-artifact@v3\n         with:\n           path: dist/*.whl\n \ndiff --git a/.github/workflows/ci.yml b/.github/workflows/ci.yml\nindex eadcc74874aed..be1a07813463d 100644\n--- a/.github/workflows/ci.yml\n+++ b/.github/workflows/ci.yml\n@@ -17,7 +17,7 @@ jobs:\n       - uses: actions/checkout@v2.5.0\n         with:\n           fetch-depth: 0\n-      - uses: wagoid/commitlint-github-action@v4\n+      - uses: wagoid/commitlint-github-action@v3\n \n   lint-flake-8:\n     runs-on: ubuntu-latest\n@@ -691,7 +691,7 @@ jobs:\n           python -m cibuildwheel --output-dir dist\n \n       - name: Upload wheels as artifacts\n-        uses: actions/upload-artifact@v2\n+        uses: actions/upload-artifact@v3\n         with:\n           path: dist/*.whl\n \ndiff --git a/.github/workflows/force-release.yml b/.github/workflows/force-release.yml\nindex 52c0a25f724c6..358dc39e88918 100644\n--- a/.github/workflows/force-release.yml\n+++ b/.github/workflows/force-release.yml\n@@ -142,7 +142,7 @@ jobs:\n           python -m cibuildwheel --output-dir dist\n           \n       - name: Upload wheels as artifacts\n-        uses: actions/upload-artifact@v2\n+        uses: actions/upload-artifact@v3\n         with:\n           path: dist/*.whl\n \ndiff --git a/jina/clients/base/helper.py b/jina/clients/base/helper.py\nindex 1e869c2599c7c..620513ceec460 100644\n--- a/jina/clients/base/helper.py\n+++ b/jina/clients/base/helper.py\n@@ -178,8 +178,9 @@ async def send_message(self, request: 'Request'):\n                         r_str = await response.json()\n                     except aiohttp.ContentTypeError:\n                         r_str = await response.text()\n+                    r_status = response.status\n                     handle_response_status(response.status, r_str, self.url)\n-                    return response\n+                    return r_status, r_str\n             except (ValueError, ConnectionError, BadClient, aiohttp.ClientError, aiohttp.ClientConnectionError) as err:\n                 self.logger.debug(f'Got an error: {err} sending POST to {self.url} in attempt {attempt}/{self.max_attempts}')\n                 await retry.wait_or_raise_err(\ndiff --git a/jina/clients/base/http.py b/jina/clients/base/http.py\nindex c55156bf69365..746bdf0e0acfd 100644\n--- a/jina/clients/base/http.py\n+++ b/jina/clients/base/http.py\n@@ -193,9 +193,7 @@ def _result_handler(result):\n             async for response in streamer.stream(\n                 request_iterator=request_iterator, results_in_order=results_in_order\n             ):\n-                r_status = response.status\n-\n-                r_str = await response.json()\n+                r_status, r_str = response\n                 handle_response_status(r_status, r_str, url)\n \n                 da = None\ndiff --git a/tests/unit/clients/test_helper.py b/tests/unit/clients/test_helper.py\nindex b723a65acaaae..66ae0d9081f38 100644\n--- a/tests/unit/clients/test_helper.py\n+++ b/tests/unit/clients/test_helper.py\n@@ -37,8 +37,8 @@ async def test_http_clientlet():\n         ) as iolet:\n             request = _new_data_request('/', None, {'a': 'b'})\n             assert request.header.target_executor == ''\n-            r = await iolet.send_message(request)\n-            response = DataRequest(await r.json())\n+            r_status, r_json = await iolet.send_message(request)\n+            response = DataRequest(r_json)\n     assert response.header.exec_endpoint == '/'\n     assert response.parameters == {'a': 'b'}\n \n@@ -55,7 +55,8 @@ async def test_http_clientlet_target():\n             request = _new_data_request('/', 'nothing', {'a': 'b'})\n             assert request.header.target_executor == 'nothing'\n             r = await iolet.send_message(request)\n-            response = DataRequest(await r.json())\n+            r_status, r_json = r\n+            response = DataRequest(r_json)\n     assert response.header.exec_endpoint == '/'\n     assert response.parameters == {'a': 'b'}\n \n"},"summary":"## MR Summary\n\nДанный MR направлен на улучшение обработки HTTP-ответов и обновление зависимостей. Основные изменения включают в себя обновление версий зависимостей в файлах workflow, а также рефакторинг возвращаемых значений в методах `send_message` и `_result_handler`, что повышает читаемость кода. Экспертная оценка указывает на среднюю сложность изменений, связанных с необходимостью понимания работы HTTP-клиентов. Анализ кода подтверждает соответствие существующему стилю кодирования (оценка 8), отсутствие анти-паттернов (оценка 9) и хорошее использование паттернов проектирования (оценка 10).\n","antiPatterns":{"detailed_analysis":"Внесенные изменения затрагивают несколько файлов конфигурации GitHub Actions (.github/workflows/*) и файл клиента (jina/clients/base/helper.py, jina/clients/base/http.py). Основные изменения касаются обновления версий actions/upload-artifact с v2 на v3 и изменения возвращаемого значения в методе send_message. В helper.py изменено возвращаемое значение с объекта response на кортеж (status, json_data). В http.py используется это измененное значение. Эти изменения не вводят новых анти-паттернов и улучшают структуру кода, делая его более чистым и понятным. ","recommendations":[],"confidence":"High","score":9,"summary":"Изменения в основном касаются обновления зависимостей и улучшения обработки ответов в клиенте, не вводя анти-паттернов."},"complexity":{"justification":"Данный MR содержит изменения в нескольких файлах, затрагивая логику обработки HTTP-ответов в клиентах.  Изменения включают в себя модификацию обработки статусов и содержимого ответов, а также обновление зависимостей в workflow файлах.  Хотя изменения не затрагивают критические компоненты системы напрямую, они влияют на взаимодействие с API и обработку данных.  Объем изменений умеренный, и хотя логика не является чрезмерно сложной, требуется понимание работы HTTP-клиентов и обработки ответов.  Риски умеренные, так как изменения касаются обработки ответов, что может потребовать корректировки в других частях системы, использующих эти ответы.  В целом, сложность можно оценить как среднюю, так как изменения требуют понимания контекста, но не являются критичными или чрезмерно сложными.","classification":"Medium"},"designPatterns":{"detailed_analysis":"Внесенные изменения затрагивают несколько файлов, в основном обновляя использование `actions/upload-artifact`. Эти изменения не вводят новых анти-паттернов и не устраняют существующие. Они касаются обновления версий зависимостей в файлах конфигурации GitHub Actions. Изменения минимальны и не влияют на архитектуру или структуру кода. ","recommendations":[],"confidence":"High","score":10,"summary":"Изменения не содержат анти-паттернов и касаются обновления версий зависимостей в файлах конфигурации GitHub Actions."},"codeStyle":{"detailed_analysis":"Изменения в основном касаются обновления версий зависимостей в файлах .github/workflows/*.yml и изменения возвращаемого значения в нескольких местах в коде. В частности, изменено возвращаемое значение в send_message и _result_handler, где теперь возвращается статус и тело ответа, а не объект ответа целиком. Это улучшает читаемость и упрощает обработку ответа. Изменения в основном соответствуют существующему стилю кодирования, и нет серьезных нарушений. Обновления версий зависимостей также являются хорошей практикой.","recommendations":["Нет существенных рекомендаций по стилю кода."],"confidence":"High","score":8,"summary":"Внесенные изменения в основном касаются обновления зависимостей и рефакторинга возвращаемых значений, что улучшает читаемость и поддержку кода."}},{"pull":{"id":6194,"html_url":"https://github.com/jina-ai/serve/pull/6194","title":"refactor: handle async context manager in clientlet","body":"Goals:\n\n\n\nresolves #ISSUE-NUMBER\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n check and update documentation. See guide and ask the team.","is_merged":true,"diff":"diff --git a/jina/clients/base/helper.py b/jina/clients/base/helper.py\nindex 0a2d7481164a8..1e869c2599c7c 100644\n--- a/jina/clients/base/helper.py\n+++ b/jina/clients/base/helper.py\n@@ -173,14 +173,15 @@ async def send_message(self, request: 'Request'):\n                     from docarray.base_doc.io.json import orjson_dumps\n \n                     request_kwargs['data'] = JinaJsonPayload(value=req_dict)\n-                response = await self.session.post(**request_kwargs).__aenter__()\n-                try:\n-                    r_str = await response.json()\n-                except aiohttp.ContentTypeError:\n-                    r_str = await response.text()\n-                handle_response_status(response.status, r_str, self.url)\n-                return response\n-            except (ValueError, ConnectionError, BadClient, aiohttp.ClientError) as err:\n+                async with self.session.post(**request_kwargs) as response:\n+                    try:\n+                        r_str = await response.json()\n+                    except aiohttp.ContentTypeError:\n+                        r_str = await response.text()\n+                    handle_response_status(response.status, r_str, self.url)\n+                    return response\n+            except (ValueError, ConnectionError, BadClient, aiohttp.ClientError, aiohttp.ClientConnectionError) as err:\n+                self.logger.debug(f'Got an error: {err} sending POST to {self.url} in attempt {attempt}/{self.max_attempts}')\n                 await retry.wait_or_raise_err(\n                     attempt=attempt,\n                     err=err,\n@@ -189,6 +190,10 @@ async def send_message(self, request: 'Request'):\n                     initial_backoff=self.initial_backoff,\n                     max_backoff=self.max_backoff,\n                 )\n+            except Exception as exc:\n+                self.logger.debug(\n+                    f'Got a non-retried error: {exc} sending POST to {self.url}')\n+                raise exc\n \n     async def send_streaming_message(self, doc: 'Document', on: str):\n         \"\"\"Sends a GET SSE request to the server\n"},"summary":"## MR Summary\n\nДанный MR направлен на улучшение обработки асинхронных запросов в клиентском коде. Основные изменения включают в себя использование `async with` для управления контекстом `aiohttp.ClientSession.post`, что повышает читаемость и надежность кода, а также добавление обработки `aiohttp.ClientConnectionError` и логирования ошибок. Экспертная оценка подтверждает высокое качество кода, отмечая улучшение обработки асинхронных контекстных менеджеров и отказоустойчивости, а также отсутствие анти-паттернов. Общая сложность изменений оценена как \"Medium\".\n","antiPatterns":{"detailed_analysis":"Внесенные изменения улучшают обработку исключений и использование контекстных менеджеров в асинхронном коде.  В частности, `async with` используется для управления сессией `aiohttp.ClientSession`, что является лучшей практикой и предотвращает утечки ресурсов. Добавлена обработка `aiohttp.ClientConnectionError`, что повышает надежность.  Улучшена логика повторных попыток, что также положительно влияет на устойчивость к ошибкам.  Анти-паттерны не обнаружены.","recommendations":[],"confidence":"High","score":9,"summary":"Внесенные изменения улучшают обработку исключений и использование контекстных менеджеров, что повышает надежность кода."},"complexity":{"justification":"Изменения затрагивают асинхронный контекстный менеджер в клиентском коде. Объем изменений небольшой, затрагивает один файл и несколько строк. Изменения направлены на улучшение обработки ошибок и добавление логирования. Влияние на систему умеренное, затрагивает клиентскую часть, но не критические компоненты. Когнитивная нагрузка средняя, так как требуется понимание асинхронного программирования и работы с контекстными менеджерами. Риски умеренные, так как изменения направлены на улучшение обработки ошибок. В целом, изменения соответствуют уровню сложности \"Medium\".","classification":"Medium"},"designPatterns":{"detailed_analysis":"Внесенные изменения улучшают обработку асинхронных контекстных менеджеров, что снижает вероятность утечек ресурсов и повышает надежность. Использование `async with` вместо ручного управления контекстом является хорошей практикой. Добавлена обработка `aiohttp.ClientConnectionError` и логирование ошибок, что улучшает отказоустойчивость. Анти-паттерны не обнаружены.","recommendations":[],"confidence":"High","score":10,"summary":"Изменения улучшают обработку асинхронных контекстных менеджеров и отказоустойчивость."},"codeStyle":{"detailed_analysis":"Изменения в основном касаются использования `async with` для управления контекстом `aiohttp.ClientSession.post`. Это улучшает управление ресурсами и делает код более чистым. Форматирование соответствует стандартам, отступы и пробелы корректны. Имена переменных и функций понятны. Читаемость кода повышена за счет использования `async with`. Соответствие гайдлайнам высокое. Добавлена обработка `aiohttp.ClientConnectionError` и логирование ошибок, что улучшает надежность.","recommendations":["Нет существенных рекомендаций. Код хорошо написан и соответствует стандартам."],"confidence":"High","score":9,"summary":"Внесены улучшения в обработку асинхронных запросов, повышена читаемость и надежность кода."}},{"pull":{"id":6193,"html_url":"https://github.com/jina-ai/serve/pull/6193","title":"refactor: slight change in dyn batch queue","body":"Goals:\n\n\n\nresolves #ISSUE-NUMBER\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n check and update documentation. See guide and ask the team.","is_merged":true,"diff":"diff --git a/jina/serve/runtimes/worker/batch_queue.py b/jina/serve/runtimes/worker/batch_queue.py\nindex 9368e81b7d8fd..0419e35414a46 100644\n--- a/jina/serve/runtimes/worker/batch_queue.py\n+++ b/jina/serve/runtimes/worker/batch_queue.py\n@@ -3,7 +3,7 @@\n from asyncio import Event, Task\n from typing import Callable, Dict, List, Optional, TYPE_CHECKING\n from jina._docarray import docarray_v2\n-\n+import contextlib\n if not docarray_v2:\n     from docarray import DocumentArray\n else:\n@@ -24,11 +24,16 @@ def __init__(\n         response_docarray_cls,\n         output_array_type: Optional[str] = None,\n         params: Optional[Dict] = None,\n+        allow_concurrent: bool = False,\n         flush_all: bool = False,\n         preferred_batch_size: int = 4,\n         timeout: int = 10_000,\n     ) -> None:\n-        self._data_lock = asyncio.Lock()\n+        # To keep old user behavior, we use data lock when flush_all is true and no allow_concurrent\n+        if allow_concurrent and flush_all:\n+            self._data_lock = contextlib.AsyncExitStack()\n+        else:\n+            self._data_lock = asyncio.Lock()\n         self.func = func\n         if params is None:\n             params = dict()\n@@ -104,19 +109,20 @@ async def push(self, request: DataRequest, http = False) -> asyncio.Queue:\n             # this push requests the data lock. The order of accessing the data lock guarantees that this request will be put in the `big_doc`\n             # before the `flush` task processes it.\n             self._start_timer()\n-        if not self._flush_task:\n-            self._flush_task = asyncio.create_task(self._await_then_flush(http))\n-\n-        self._big_doc.extend(docs)\n-        next_req_idx = len(self._requests)\n-        num_docs = len(docs)\n-        self._request_idxs.extend([next_req_idx] * num_docs)\n-        self._request_lens.append(len(docs))\n-        self._requests.append(request)\n-        queue = asyncio.Queue()\n-        self._requests_completed.append(queue)\n-        if len(self._big_doc) >= self._preferred_batch_size:\n-            self._flush_trigger.set()\n+        async with self._data_lock:\n+            if not self._flush_task:\n+                self._flush_task = asyncio.create_task(self._await_then_flush(http))\n+\n+            self._big_doc.extend(docs)\n+            next_req_idx = len(self._requests)\n+            num_docs = len(docs)\n+            self._request_idxs.extend([next_req_idx] * num_docs)\n+            self._request_lens.append(len(docs))\n+            self._requests.append(request)\n+            queue = asyncio.Queue()\n+            self._requests_completed.append(queue)\n+            if len(self._big_doc) >= self._preferred_batch_size:\n+                self._flush_trigger.set()\n \n         return queue\n \n@@ -236,74 +242,94 @@ def batch(iterable_1, iterable_2, n:Optional[int] = 1):\n \n         await self._flush_trigger.wait()\n         # writes to shared data between tasks need to be mutually exclusive\n-        big_doc_in_batch = copy.copy(self._big_doc)\n-        requests_idxs_in_batch = copy.copy(self._request_idxs)\n-        requests_lens_in_batch = copy.copy(self._request_lens)\n-        requests_in_batch = copy.copy(self._requests)\n-        requests_completed_in_batch = copy.copy(self._requests_completed)\n+        async with self._data_lock:\n+            big_doc_in_batch = copy.copy(self._big_doc)\n+            requests_idxs_in_batch = copy.copy(self._request_idxs)\n+            requests_lens_in_batch = copy.copy(self._request_lens)\n+            requests_in_batch = copy.copy(self._requests)\n+            requests_completed_in_batch = copy.copy(self._requests_completed)\n \n-        self._reset()\n+            self._reset()\n \n-        # At this moment, we have documents concatenated in big_doc_in_batch corresponding to requests in\n-        # requests_idxs_in_batch with its lengths stored in requests_lens_in_batch. For each requests, there is a queue to\n-        # communicate that the request has been processed properly.\n+            # At this moment, we have documents concatenated in big_doc_in_batch corresponding to requests in\n+            # requests_idxs_in_batch with its lengths stored in requests_lens_in_batch. For each requests, there is a queue to\n+            # communicate that the request has been processed properly.\n \n-        if not docarray_v2:\n-            non_assigned_to_response_docs: DocumentArray = DocumentArray.empty()\n-        else:\n-            non_assigned_to_response_docs = self._response_docarray_cls()\n+            if not docarray_v2:\n+                non_assigned_to_response_docs: DocumentArray = DocumentArray.empty()\n+            else:\n+                non_assigned_to_response_docs = self._response_docarray_cls()\n \n-        non_assigned_to_response_request_idxs = []\n-        sum_from_previous_first_req_idx = 0\n-        for docs_inner_batch, req_idxs in batch(\n-            big_doc_in_batch, requests_idxs_in_batch, self._preferred_batch_size if not self._flush_all else None\n-        ):\n-            involved_requests_min_indx = req_idxs[0]\n-            involved_requests_max_indx = req_idxs[-1]\n-            input_len_before_call: int = len(docs_inner_batch)\n-            batch_res_docs = None\n-            try:\n-                batch_res_docs = await self.func(\n-                    docs=docs_inner_batch,\n-                    parameters=self.params,\n-                    docs_matrix=None,  # joining manually with batch queue is not supported right now\n-                    tracing_context=None,\n-                )\n-                # Output validation\n-                if (docarray_v2 and isinstance(batch_res_docs, DocList)) or (\n-                    not docarray_v2\n-                    and isinstance(batch_res_docs, DocumentArray)\n-                ):\n-                    if not len(batch_res_docs) == input_len_before_call:\n-                        raise ValueError(\n-                            f'Dynamic Batching requires input size to equal output size. Expected output size {input_len_before_call}, but got {len(batch_res_docs)}'\n+            non_assigned_to_response_request_idxs = []\n+            sum_from_previous_first_req_idx = 0\n+            for docs_inner_batch, req_idxs in batch(\n+                big_doc_in_batch, requests_idxs_in_batch, self._preferred_batch_size if not self._flush_all else None\n+            ):\n+                involved_requests_min_indx = req_idxs[0]\n+                involved_requests_max_indx = req_idxs[-1]\n+                input_len_before_call: int = len(docs_inner_batch)\n+                batch_res_docs = None\n+                try:\n+                    batch_res_docs = await self.func(\n+                        docs=docs_inner_batch,\n+                        parameters=self.params,\n+                        docs_matrix=None,  # joining manually with batch queue is not supported right now\n+                        tracing_context=None,\n+                    )\n+                    # Output validation\n+                    if (docarray_v2 and isinstance(batch_res_docs, DocList)) or (\n+                        not docarray_v2\n+                        and isinstance(batch_res_docs, DocumentArray)\n+                    ):\n+                        if not len(batch_res_docs) == input_len_before_call:\n+                            raise ValueError(\n+                                f'Dynamic Batching requires input size to equal output size. Expected output size {input_len_before_call}, but got {len(batch_res_docs)}'\n+                            )\n+                    elif batch_res_docs is None:\n+                        if not len(docs_inner_batch) == input_len_before_call:\n+                            raise ValueError(\n+                                f'Dynamic Batching requires input size to equal output size. Expected output size {input_len_before_call}, but got {len(docs_inner_batch)}'\n+                            )\n+                    else:\n+                        array_name = (\n+                            'DocumentArray' if not docarray_v2 else 'DocList'\n                         )\n-                elif batch_res_docs is None:\n-                    if not len(docs_inner_batch) == input_len_before_call:\n-                        raise ValueError(\n-                            f'Dynamic Batching requires input size to equal output size. Expected output size {input_len_before_call}, but got {len(docs_inner_batch)}'\n+                        raise TypeError(\n+                            f'The return type must be {array_name} / `None` when using dynamic batching, '\n+                            f'but getting {batch_res_docs!r}'\n                         )\n+                except Exception as exc:\n+                    # All the requests containing docs in this Exception should be raising it\n+                    for request_full in requests_completed_in_batch[\n+                        involved_requests_min_indx : involved_requests_max_indx + 1\n+                    ]:\n+                        await request_full.put(exc)\n                 else:\n-                    array_name = (\n-                        'DocumentArray' if not docarray_v2 else 'DocList'\n+                    # We need to attribute the docs to their requests\n+                    non_assigned_to_response_docs.extend(\n+                        batch_res_docs or docs_inner_batch\n                     )\n-                    raise TypeError(\n-                        f'The return type must be {array_name} / `None` when using dynamic batching, '\n-                        f'but getting {batch_res_docs!r}'\n+                    non_assigned_to_response_request_idxs.extend(req_idxs)\n+                    num_assigned_docs = await _assign_results(\n+                        non_assigned_to_response_docs,\n+                        non_assigned_to_response_request_idxs,\n+                        sum_from_previous_first_req_idx,\n+                        requests_lens_in_batch,\n+                        requests_in_batch,\n+                        requests_completed_in_batch,\n                     )\n-            except Exception as exc:\n-                # All the requests containing docs in this Exception should be raising it\n-                for request_full in requests_completed_in_batch[\n-                    involved_requests_min_indx : involved_requests_max_indx + 1\n-                ]:\n-                    await request_full.put(exc)\n-            else:\n-                # We need to attribute the docs to their requests\n-                non_assigned_to_response_docs.extend(\n-                    batch_res_docs or docs_inner_batch\n-                )\n-                non_assigned_to_response_request_idxs.extend(req_idxs)\n-                num_assigned_docs = await _assign_results(\n+\n+                    sum_from_previous_first_req_idx = (\n+                        len(non_assigned_to_response_docs) - num_assigned_docs\n+                    )\n+                    non_assigned_to_response_docs = non_assigned_to_response_docs[\n+                        num_assigned_docs:\n+                    ]\n+                    non_assigned_to_response_request_idxs = (\n+                        non_assigned_to_response_request_idxs[num_assigned_docs:]\n+                    )\n+            if len(non_assigned_to_response_request_idxs) > 0:\n+                _ = await _assign_results(\n                     non_assigned_to_response_docs,\n                     non_assigned_to_response_request_idxs,\n                     sum_from_previous_first_req_idx,\n@@ -312,25 +338,6 @@ def batch(iterable_1, iterable_2, n:Optional[int] = 1):\n                     requests_completed_in_batch,\n                 )\n \n-                sum_from_previous_first_req_idx = (\n-                    len(non_assigned_to_response_docs) - num_assigned_docs\n-                )\n-                non_assigned_to_response_docs = non_assigned_to_response_docs[\n-                    num_assigned_docs:\n-                ]\n-                non_assigned_to_response_request_idxs = (\n-                    non_assigned_to_response_request_idxs[num_assigned_docs:]\n-                )\n-        if len(non_assigned_to_response_request_idxs) > 0:\n-            _ = await _assign_results(\n-                non_assigned_to_response_docs,\n-                non_assigned_to_response_request_idxs,\n-                sum_from_previous_first_req_idx,\n-                requests_lens_in_batch,\n-                requests_in_batch,\n-                requests_completed_in_batch,\n-            )\n-\n     async def close(self):\n         \"\"\"Closes the batch queue by flushing pending requests.\"\"\"\n         if not self._is_closed:\ndiff --git a/jina/serve/runtimes/worker/request_handling.py b/jina/serve/runtimes/worker/request_handling.py\nindex 456c94a7bdf41..52a5070ea83e4 100644\n--- a/jina/serve/runtimes/worker/request_handling.py\n+++ b/jina/serve/runtimes/worker/request_handling.py\n@@ -702,6 +702,7 @@ async def handle(\n                     ].response_schema,\n                     output_array_type=self.args.output_array_type,\n                     params=params,\n+                    allow_concurrent=self.args.allow_concurrent,\n                     **self._batchqueue_config[exec_endpoint],\n                 )\n             # This is necessary because push might need to await for the queue to be emptied\ndiff --git a/tests/integration/dynamic_batching/test_dynamic_batching.py b/tests/integration/dynamic_batching/test_dynamic_batching.py\nindex 483f247db7892..87e98455317bb 100644\n--- a/tests/integration/dynamic_batching/test_dynamic_batching.py\n+++ b/tests/integration/dynamic_batching/test_dynamic_batching.py\n@@ -218,7 +218,9 @@ def call_api_with_params(req: RequestStructParams):\n     ],\n )\n @pytest.mark.parametrize('use_stream', [False, True])\n-def test_timeout(add_parameters, use_stream):\n+@pytest.mark.parametrize('allow_concurrent', [False, True])\n+def test_timeout(add_parameters, use_stream, allow_concurrent):\n+    add_parameters['allow_concurrent'] = allow_concurrent\n     f = Flow().add(**add_parameters)\n     with f:\n         start_time = time.time()\n@@ -265,7 +267,9 @@ def test_timeout(add_parameters, use_stream):\n     ],\n )\n @pytest.mark.parametrize('use_stream', [False, True])\n-def test_preferred_batch_size(add_parameters, use_stream):\n+@pytest.mark.parametrize('allow_concurrent', [False, True])\n+def test_preferred_batch_size(add_parameters, use_stream, allow_concurrent):\n+    add_parameters['allow_concurrent'] = allow_concurrent\n     f = Flow().add(**add_parameters)\n     with f:\n         with mp.Pool(2) as p:\n@@ -315,8 +319,9 @@ def test_preferred_batch_size(add_parameters, use_stream):\n \n @pytest.mark.repeat(10)\n @pytest.mark.parametrize('use_stream', [False, True])\n-def test_correctness(use_stream):\n-    f = Flow().add(uses=PlaceholderExecutor)\n+@pytest.mark.parametrize('allow_concurrent', [False, True])\n+def test_correctness(use_stream, allow_concurrent):\n+    f = Flow().add(uses=PlaceholderExecutor, allow_concurrent=allow_concurrent)\n     with f:\n         with mp.Pool(2) as p:\n             results = list(\n@@ -686,7 +691,14 @@ def foo(self, docs, **kwargs):\n         True\n     ],\n )\n-async def test_num_docs_processed_in_exec(flush_all):\n+@pytest.mark.parametrize(\n+    'allow_concurrent',\n+    [\n+        False,\n+        True\n+    ],\n+)\n+async def test_num_docs_processed_in_exec(flush_all, allow_concurrent):\n     class DynBatchProcessor(Executor):\n \n         @dynamic_batching(preferred_batch_size=5, timeout=5000, flush_all=flush_all)\n@@ -695,7 +707,7 @@ def foo(self, docs, **kwargs):\n             for doc in docs:\n                 doc.text = f\"{len(docs)}\"\n \n-    depl = Deployment(uses=DynBatchProcessor, protocol='http')\n+    depl = Deployment(uses=DynBatchProcessor, protocol='http', allow_concurrent=allow_concurrent)\n \n     with depl:\n         da = DocumentArray([Document(text='good') for _ in range(50)])\n@@ -721,5 +733,6 @@ def foo(self, docs, **kwargs):\n                     larger_than_5 += 1\n                 if int(d.text) < 5:\n                     smaller_than_5 += 1\n-            assert smaller_than_5 == 1\n+\n+            assert smaller_than_5 == (1 if allow_concurrent else 0)\n             assert larger_than_5 > 0\ndiff --git a/tests/unit/serve/dynamic_batching/test_batch_queue.py b/tests/unit/serve/dynamic_batching/test_batch_queue.py\nindex 9db1958b86e05..40622b478322d 100644\n--- a/tests/unit/serve/dynamic_batching/test_batch_queue.py\n+++ b/tests/unit/serve/dynamic_batching/test_batch_queue.py\n@@ -10,7 +10,8 @@\n \n @pytest.mark.asyncio\n @pytest.mark.parametrize('flush_all', [False, True])\n-async def test_batch_queue_timeout(flush_all):\n+@pytest.mark.parametrize('allow_concurrent', [False, True])\n+async def test_batch_queue_timeout(flush_all, allow_concurrent):\n     async def foo(docs, **kwargs):\n         await asyncio.sleep(0.1)\n         return DocumentArray([Document(text='Done') for _ in docs])\n@@ -22,6 +23,7 @@ async def foo(docs, **kwargs):\n         preferred_batch_size=4,\n         timeout=2000,\n         flush_all=flush_all,\n+        allow_concurrent=allow_concurrent,\n     )\n \n     three_data_requests = [DataRequest() for _ in range(3)]\n@@ -62,15 +64,15 @@ async def process_request(req):\n \n @pytest.mark.asyncio\n @pytest.mark.parametrize('flush_all', [False, True])\n-async def test_batch_queue_timeout_does_not_wait_previous_batch(flush_all):\n+@pytest.mark.parametrize('allow_concurrent', [False, True])\n+async def test_batch_queue_timeout_does_not_wait_previous_batch(flush_all, allow_concurrent):\n     batches_lengths_computed = []\n     lock = asyncio.Lock()\n \n     async def foo(docs, **kwargs):\n-        async with lock:\n-            await asyncio.sleep(4)\n-            batches_lengths_computed.append(len(docs))\n-            return DocumentArray([Document(text='Done') for _ in docs])\n+        await asyncio.sleep(4)\n+        batches_lengths_computed.append(len(docs))\n+        return DocumentArray([Document(text='Done') for _ in docs])\n \n     bq: BatchQueue = BatchQueue(\n         foo,\n@@ -78,7 +80,8 @@ async def foo(docs, **kwargs):\n         response_docarray_cls=DocumentArray,\n         preferred_batch_size=5,\n         timeout=3000,\n-        flush_all=flush_all\n+        flush_all=flush_all,\n+        allow_concurrent=allow_concurrent\n     )\n \n     data_requests = [DataRequest() for _ in range(3)]\n@@ -108,10 +111,13 @@ async def process_request(req, sleep=0):\n         assert time_spent >= 12000\n         assert time_spent <= 12500\n     else:\n-        assert time_spent >= 8000\n-        assert time_spent <= 8500\n+        if not allow_concurrent:\n+            assert time_spent >= 8000\n+            assert time_spent <= 8500\n+        else:\n+            assert time_spent < 8000\n     if flush_all is False:\n-        assert batches_lengths_computed == [5, 2, 1]\n+        assert batches_lengths_computed == [5, 1, 2]\n     else:\n         assert batches_lengths_computed == [6, 2]\n \n@@ -120,7 +126,8 @@ async def process_request(req, sleep=0):\n \n @pytest.mark.asyncio\n @pytest.mark.parametrize('flush_all', [False, True])\n-async def test_batch_queue_req_length_larger_than_preferred(flush_all):\n+@pytest.mark.parametrize('allow_concurrent', [False, True])\n+async def test_batch_queue_req_length_larger_than_preferred(flush_all, allow_concurrent):\n     async def foo(docs, **kwargs):\n         await asyncio.sleep(0.1)\n         return DocumentArray([Document(text='Done') for _ in docs])\n@@ -132,6 +139,7 @@ async def foo(docs, **kwargs):\n         preferred_batch_size=4,\n         timeout=2000,\n         flush_all=flush_all,\n+        allow_concurrent=allow_concurrent,\n     )\n \n     data_requests = [DataRequest() for _ in range(3)]\n@@ -158,7 +166,8 @@ async def process_request(req):\n \n \n @pytest.mark.asyncio\n-async def test_exception():\n+@pytest.mark.parametrize('allow_concurrent', [False, True])\n+async def test_exception(allow_concurrent):\n     BAD_REQUEST_IDX = [2, 6]\n \n     async def foo(docs, **kwargs):\n@@ -175,6 +184,8 @@ async def foo(docs, **kwargs):\n         response_docarray_cls=DocumentArray,\n         preferred_batch_size=1,\n         timeout=500,\n+        flush_all=False,\n+        allow_concurrent=allow_concurrent\n     )\n \n     data_requests = [DataRequest() for _ in range(35)]\n@@ -204,7 +215,8 @@ async def process_request(req):\n \n \n @pytest.mark.asyncio\n-async def test_exception_more_complex():\n+@pytest.mark.parametrize('allow_concurrent', [False, True])\n+async def test_exception_more_complex(allow_concurrent):\n     TRIGGER_BAD_REQUEST_IDX = [2, 6]\n     EXPECTED_BAD_REQUESTS = [2, 3, 6, 7]\n \n@@ -225,6 +237,8 @@ async def foo(docs, **kwargs):\n         response_docarray_cls=DocumentArray,\n         preferred_batch_size=2,\n         timeout=500,\n+        flush_all=False,\n+        allow_concurrent=allow_concurrent\n     )\n \n     data_requests = [DataRequest() for _ in range(35)]\n@@ -257,7 +271,8 @@ async def process_request(req):\n \n @pytest.mark.asyncio\n @pytest.mark.parametrize('flush_all', [False, True])\n-async def test_exception_all(flush_all):\n+@pytest.mark.parametrize('allow_concurrent', [False, True])\n+async def test_exception_all(flush_all, allow_concurrent):\n     async def foo(docs, **kwargs):\n         raise AssertionError\n \n@@ -268,6 +283,7 @@ async def foo(docs, **kwargs):\n         preferred_batch_size=2,\n         flush_all=flush_all,\n         timeout=500,\n+        allow_concurrent=allow_concurrent\n     )\n \n     data_requests = [DataRequest() for _ in range(10)]\n@@ -306,8 +322,9 @@ async def foo(docs, **kwargs):\n @pytest.mark.parametrize('preferred_batch_size', [7, 61, 100])\n @pytest.mark.parametrize('timeout', [0.3, 500])\n @pytest.mark.parametrize('flush_all', [False, True])\n+@pytest.mark.parametrize('allow_concurrent', [False, True])\n @pytest.mark.asyncio\n-async def test_return_proper_assignment(num_requests, preferred_batch_size, timeout, flush_all):\n+async def test_return_proper_assignment(num_requests, preferred_batch_size, timeout, flush_all, allow_concurrent):\n     import random\n \n     async def foo(docs, **kwargs):\n@@ -326,6 +343,7 @@ async def foo(docs, **kwargs):\n         preferred_batch_size=preferred_batch_size,\n         flush_all=flush_all,\n         timeout=timeout,\n+        allow_concurrent=allow_concurrent\n     )\n \n     data_requests = [DataRequest() for _ in range(num_requests)]\n"},"summary":"## Summary of Merge Request\n\nДанный merge request направлен на улучшение динамической пакетной обработки, в частности, добавление параметра `allow_concurrent` в `BatchQueue`. Основные изменения включают добавление этого параметра в `batch_queue.py`, его использование в `request_handling.py` и соответствующие изменения в тестах. Экспертная оценка относит сложность изменений к \"Medium\". Код хорошо отформатирован, читаем и соответствует стандартам (Code Style: 8/10). Изменения не содержат анти-паттернов (9/10) и улучшают производительность и гибкость динамической пакетной обработки (Design Patterns: 10/10). Рекомендуется тщательное тестирование с различными конфигурациями `allow_concurrent` и `flush_all`.\n","antiPatterns":{"detailed_analysis":"Внесенные изменения затрагивают `batch_queue.py`, `request_handling.py`, `test_dynamic_batching.py` и `test_batch_queue.py`. Основные изменения касаются добавления параметра `allow_concurrent` в `BatchQueue` и его использования для управления блокировками. В частности, если `allow_concurrent` и `flush_all` установлены в `True`, используется `contextlib.AsyncExitStack` вместо `asyncio.Lock`. Это позволяет избежать потенциальных проблем с блокировками при одновременной обработке запросов. В целом, изменения направлены на улучшение производительности и параллелизма, что является положительным аспектом. Анти-паттерны не обнаружены.","recommendations":["Рекомендуется тщательно протестировать изменения с различными конфигурациями `allow_concurrent` и `flush_all`, чтобы убедиться в корректности работы и отсутствии гонок данных."],"confidence":"High","score":9,"summary":"Изменения вносят улучшения в обработку пакетных запросов, добавляя параметр `allow_concurrent` для повышения производительности. Анти-паттерны не обнаружены."},"complexity":{"justification":"Изменения вносят небольшие корректировки в `jina/serve/runtimes/worker/batch_queue.py`, `jina/serve/runtimes/worker/request_handling.py`, `tests/integration/dynamic_batching/test_dynamic_batching.py` и `tests/unit/serve/dynamic_batching/test_batch_queue.py`. Основные изменения включают добавление параметра `allow_concurrent` и использование `contextlib.AsyncExitStack()` для управления блокировками, что влияет на поведение динамической пакетной обработки. Объем изменений умеренный, затрагивает несколько файлов, но не вносит кардинальных изменений в архитектуру. Изменения затрагивают критические компоненты, но не приводят к сложной логике. Когнитивная нагрузка умеренная, требуется понимание динамической пакетной обработки и управления блокировками. Риски умеренные, потенциальные побочные эффекты ограничены.  В целом, изменения соответствуют уровню сложности \"Medium\".","classification":"Medium"},"designPatterns":{"detailed_analysis":"Внесенные изменения затрагивают `batch_queue.py`, `request_handling.py`, и тесты. Основные изменения касаются добавления параметра `allow_concurrent` в `BatchQueue` и его использования для управления блокировками. Это позволяет выполнять запросы параллельно, если `flush_all` включен. В коде тестов добавлены новые параметры для тестирования с `allow_concurrent`. Изменения направлены на улучшение производительности и гибкости динамической пакетной обработки. Анти-паттерны не обнаружены.","recommendations":[],"confidence":"High","score":10,"summary":"Изменения вносят улучшения в динамическую пакетную обработку, не содержат анти-паттернов."},"codeStyle":{"detailed_analysis":"Изменения в основном касаются добавления параметра `allow_concurrent` в `BatchQueue` и его использования в различных местах, включая `request_handling.py` и тесты.  \n\n**Форматирование:** В целом, форматирование соответствует стандартам.  Небольшие изменения в расстановке пробелов, но они не критичны.\n\n**Именование:** Имена переменных и функций понятны и соответствуют их назначению.  `allow_concurrent` хорошо описывает функциональность.\n\n**Консистентность:** Изменения консистентны в рамках всего diff.  Используется один и тот же стиль.\n\n**Читаемость:** Код легко читается. Добавление `allow_concurrent` и его использование не усложняют понимание логики.  Изменения в тестах также понятны.\n\n**Соответствие гайдлайнам:** Код соответствует PEP 8.  Использование `contextlib.AsyncExitStack` для `allow_concurrent` и `flush_all` является хорошей практикой.\n\nВ целом, изменения хорошо структурированы и легко читаются.","recommendations":[],"confidence":"High","score":8,"summary":"Внесены изменения, связанные с добавлением параметра `allow_concurrent` в `BatchQueue` и его интеграцией в различные части кода. Код хорошо отформатирован, читаем и соответствует стандартам."}},{"pull":{"id":6192,"html_url":"https://github.com/jina-ai/serve/pull/6192","title":"fix: add plain handler","body":"Goals:\n\n\n\nresolves #ISSUE-NUMBER\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n check and update documentation. See guide and ask the team.","is_merged":true,"diff":"diff --git a/jina/resources/logging.plain.yml b/jina/resources/logging.plain.yml\nnew file mode 100644\nindex 0000000000000..747061d1881be\n--- /dev/null\n+++ b/jina/resources/logging.plain.yml\n@@ -0,0 +1,7 @@\n+handlers:\n+  - StreamHandler\n+level: INFO\n+configs:\n+  StreamHandler:\n+    format: '{name:>15}@%(process)2d[%(levelname).1s]:%(message)s'\n+    formatter: PlainFormatter\n"},"summary":"## MR Summary\n\nДанный MR добавляет новый файл конфигурации для логирования в формате plain. Основное изменение - добавление файла `logging.plain.yml`, содержащего конфигурацию для `StreamHandler`.\n\nОценка сложности изменений - \"Low\", так как изменения минимальны и затрагивают только конфигурацию. Code Style оценен высоко (9/10), отмечено соответствие стандартам форматирования YAML и хорошая читаемость. Design Patterns и Anti-Patterns оценены в 10/10, анти-паттерны не обнаружены, код соответствует лучшим практикам.\n","antiPatterns":{"detailed_analysis":"Внесенные изменения добавляют новый файл конфигурации логирования. В файле определен обработчик `StreamHandler` с указанным форматом вывода логов. Анти-паттерны не обнаружены.","recommendations":[],"confidence":"High","score":10,"summary":"Внесенные изменения не содержат анти-паттернов."},"complexity":{"justification":"Данный MR добавляет новый файл конфигурации для логирования в формате plain. Изменения минимальны (7 строк), затрагивают только конфигурацию логирования, что является некритичным изменением. Логика проста, когнитивная нагрузка низкая, риски минимальны. Соответствует характеристикам \"Low\" по объему изменений, характеру изменений (конфигурация), влиянию на систему, когнитивной нагрузке и рискам.","classification":"Low"},"designPatterns":{"detailed_analysis":"Внесенные изменения добавляют новый обработчик логирования. В файле конфигурации `logging.plain.yml` определен обработчик `StreamHandler` с указанным форматом.  Анти-паттерны не обнаружены. Код хорошо структурирован и соответствует лучшим практикам.","recommendations":[],"confidence":"High","score":10,"summary":"Внесенные изменения не содержат анти-паттернов и соответствуют лучшим практикам."},"codeStyle":{"detailed_analysis":"Файл `logging.plain.yml` был добавлен. Форматирование YAML соответствует общепринятым стандартам. Имена `handlers`, `level`, `configs`, `StreamHandler`, `format`, `formatter` понятны и соответствуют своему назначению. Консистентность соблюдена, так как файл соответствует существующим YAML-файлам в проекте. Читаемость хорошая, структура файла логична. Соответствие гайдлайнам YAML соблюдено. Оценка обусловлена простотой и понятностью файла.","recommendations":[],"confidence":"High","score":9,"summary":"Добавлен файл конфигурации логирования в формате YAML. Код соответствует стандартам форматирования и читаемости."}},{"pull":{"id":6190,"html_url":"https://github.com/jina-ai/serve/pull/6190","title":"feat: avoid need data lock in batch queue","body":"Goals:\n\n\n\nresolves #ISSUE-NUMBER\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n check and update documentation. See guide and ask the team.","is_merged":true,"diff":"diff --git a/jina/serve/runtimes/worker/batch_queue.py b/jina/serve/runtimes/worker/batch_queue.py\nindex 572fcf6fe2743..9368e81b7d8fd 100644\n--- a/jina/serve/runtimes/worker/batch_queue.py\n+++ b/jina/serve/runtimes/worker/batch_queue.py\n@@ -1,4 +1,5 @@\n import asyncio\n+import copy\n from asyncio import Event, Task\n from typing import Callable, Dict, List, Optional, TYPE_CHECKING\n from jina._docarray import docarray_v2\n@@ -63,6 +64,7 @@ def _reset(self) -> None:\n             self._big_doc = self._request_docarray_cls()\n \n         self._flush_task: Optional[Task] = None\n+        self._flush_trigger: Event = Event()\n \n     def _cancel_timer_if_pending(self):\n         if (\n@@ -102,20 +104,19 @@ async def push(self, request: DataRequest, http = False) -> asyncio.Queue:\n             # this push requests the data lock. The order of accessing the data lock guarantees that this request will be put in the `big_doc`\n             # before the `flush` task processes it.\n             self._start_timer()\n-        async with self._data_lock:\n-            if not self._flush_task:\n-                self._flush_task = asyncio.create_task(self._await_then_flush(http))\n-\n-            self._big_doc.extend(docs)\n-            next_req_idx = len(self._requests)\n-            num_docs = len(docs)\n-            self._request_idxs.extend([next_req_idx] * num_docs)\n-            self._request_lens.append(len(docs))\n-            self._requests.append(request)\n-            queue = asyncio.Queue()\n-            self._requests_completed.append(queue)\n-            if len(self._big_doc) >= self._preferred_batch_size:\n-                self._flush_trigger.set()\n+        if not self._flush_task:\n+            self._flush_task = asyncio.create_task(self._await_then_flush(http))\n+\n+        self._big_doc.extend(docs)\n+        next_req_idx = len(self._requests)\n+        num_docs = len(docs)\n+        self._request_idxs.extend([next_req_idx] * num_docs)\n+        self._request_lens.append(len(docs))\n+        self._requests.append(request)\n+        queue = asyncio.Queue()\n+        self._requests_completed.append(queue)\n+        if len(self._big_doc) >= self._preferred_batch_size:\n+            self._flush_trigger.set()\n \n         return queue\n \n@@ -128,6 +129,7 @@ def _get_docs_groups_completed_request_indexes(\n             non_assigned_docs,\n             non_assigned_docs_reqs_idx,\n             sum_from_previous_mini_batch_in_first_req_idx,\n+            requests_lens_in_batch,\n         ):\n             \"\"\"\n             This method groups all the `non_assigned_docs` into groups of docs according to the `req_idx` they belong to.\n@@ -136,6 +138,7 @@ def _get_docs_groups_completed_request_indexes(\n             :param non_assigned_docs: The documents that have already been processed but have not been assigned to a request result\n             :param non_assigned_docs_reqs_idx: The request IDX that are not yet completed (not all of its docs have been processed)\n             :param sum_from_previous_mini_batch_in_first_req_idx: The number of docs from previous iteration that belong to the first non_assigned_req_idx. This is useful to make sure we know when a request is completed.\n+            :param requests_lens_in_batch: List of lens of documents for each request in the batch.\n \n             :return: list of document groups and a list of request Idx to which each of these groups belong\n             \"\"\"\n@@ -164,7 +167,7 @@ def _get_docs_groups_completed_request_indexes(\n             if (\n                 req_idx not in completed_req_idx\n                 and num_docs_in_req_idx + sum_from_previous_mini_batch_in_first_req_idx\n-                == self._request_lens[req_idx]\n+                == requests_lens_in_batch[req_idx]\n             ):\n                 completed_req_idx.append(req_idx)\n                 request_bucket = non_assigned_docs[\n@@ -178,6 +181,9 @@ async def _assign_results(\n             non_assigned_docs,\n             non_assigned_docs_reqs_idx,\n             sum_from_previous_mini_batch_in_first_req_idx,\n+            requests_lens_in_batch,\n+            requests_in_batch,\n+            requests_completed_in_batch,\n         ):\n             \"\"\"\n             This method aims to assign to the corresponding request objects the resulting documents from the mini batches.\n@@ -187,6 +193,9 @@ async def _assign_results(\n             :param non_assigned_docs: The documents that have already been processed but have not been assigned to a request result\n             :param non_assigned_docs_reqs_idx: The request IDX that are not yet completed (not all of its docs have been processed)\n             :param sum_from_previous_mini_batch_in_first_req_idx: The number of docs from previous iteration that belong to the first non_assigned_req_idx. This is useful to make sure we know when a request is completed.\n+            :param requests_lens_in_batch: List of lens of documents for each request in the batch.\n+            :param requests_in_batch: List requests in batch\n+            :param requests_completed_in_batch: List of queues for requests to be completed\n \n             :return: amount of assigned documents so that some documents can come back in the next iteration\n             \"\"\"\n@@ -197,12 +206,13 @@ async def _assign_results(\n                 non_assigned_docs,\n                 non_assigned_docs_reqs_idx,\n                 sum_from_previous_mini_batch_in_first_req_idx,\n+                requests_lens_in_batch\n             )\n             num_assigned_docs = sum(len(group) for group in docs_grouped)\n \n             for docs_group, request_idx in zip(docs_grouped, completed_req_idxs):\n-                request = self._requests[request_idx]\n-                request_completed = self._requests_completed[request_idx]\n+                request = requests_in_batch[request_idx]\n+                request_completed = requests_completed_in_batch[request_idx]\n                 if http is False or self._output_array_type is not None:\n                     request.direct_docs = None # batch queue will work in place, therefore result will need to read from data.\n                     request.data.set_docs_convert_arrays(\n@@ -226,91 +236,100 @@ def batch(iterable_1, iterable_2, n:Optional[int] = 1):\n \n         await self._flush_trigger.wait()\n         # writes to shared data between tasks need to be mutually exclusive\n-        async with self._data_lock:\n-            # At this moment, we have documents concatenated in self._big_doc corresponding to requests in\n-            # self._requests with its lengths stored in self._requests_len. For each requests, there is a queue to\n-            # communicate that the request has been processed properly. At this stage the data_lock is ours and\n-            # therefore no-one can add requests to this list.\n-            self._flush_trigger: Event = Event()\n-            try:\n-                if not docarray_v2:\n-                    non_assigned_to_response_docs: DocumentArray = DocumentArray.empty()\n-                else:\n-                    non_assigned_to_response_docs = self._response_docarray_cls()\n+        big_doc_in_batch = copy.copy(self._big_doc)\n+        requests_idxs_in_batch = copy.copy(self._request_idxs)\n+        requests_lens_in_batch = copy.copy(self._request_lens)\n+        requests_in_batch = copy.copy(self._requests)\n+        requests_completed_in_batch = copy.copy(self._requests_completed)\n \n-                non_assigned_to_response_request_idxs = []\n-                sum_from_previous_first_req_idx = 0\n-                for docs_inner_batch, req_idxs in batch(\n-                    self._big_doc, self._request_idxs, self._preferred_batch_size if not self._flush_all else None\n-                ):\n-                    involved_requests_min_indx = req_idxs[0]\n-                    involved_requests_max_indx = req_idxs[-1]\n-                    input_len_before_call: int = len(docs_inner_batch)\n-                    batch_res_docs = None\n-                    try:\n-                        batch_res_docs = await self.func(\n-                            docs=docs_inner_batch,\n-                            parameters=self.params,\n-                            docs_matrix=None,  # joining manually with batch queue is not supported right now\n-                            tracing_context=None,\n-                        )\n-                        # Output validation\n-                        if (docarray_v2 and isinstance(batch_res_docs, DocList)) or (\n-                            not docarray_v2\n-                            and isinstance(batch_res_docs, DocumentArray)\n-                        ):\n-                            if not len(batch_res_docs) == input_len_before_call:\n-                                raise ValueError(\n-                                    f'Dynamic Batching requires input size to equal output size. Expected output size {input_len_before_call}, but got {len(batch_res_docs)}'\n-                                )\n-                        elif batch_res_docs is None:\n-                            if not len(docs_inner_batch) == input_len_before_call:\n-                                raise ValueError(\n-                                    f'Dynamic Batching requires input size to equal output size. Expected output size {input_len_before_call}, but got {len(docs_inner_batch)}'\n-                                )\n-                        else:\n-                            array_name = (\n-                                'DocumentArray' if not docarray_v2 else 'DocList'\n-                            )\n-                            raise TypeError(\n-                                f'The return type must be {array_name} / `None` when using dynamic batching, '\n-                                f'but getting {batch_res_docs!r}'\n-                            )\n-                    except Exception as exc:\n-                        # All the requests containing docs in this Exception should be raising it\n-                        for request_full in self._requests_completed[\n-                            involved_requests_min_indx : involved_requests_max_indx + 1\n-                        ]:\n-                            await request_full.put(exc)\n-                    else:\n-                        # We need to attribute the docs to their requests\n-                        non_assigned_to_response_docs.extend(\n-                            batch_res_docs or docs_inner_batch\n-                        )\n-                        non_assigned_to_response_request_idxs.extend(req_idxs)\n-                        num_assigned_docs = await _assign_results(\n-                            non_assigned_to_response_docs,\n-                            non_assigned_to_response_request_idxs,\n-                            sum_from_previous_first_req_idx,\n-                        )\n+        self._reset()\n+\n+        # At this moment, we have documents concatenated in big_doc_in_batch corresponding to requests in\n+        # requests_idxs_in_batch with its lengths stored in requests_lens_in_batch. For each requests, there is a queue to\n+        # communicate that the request has been processed properly.\n+\n+        if not docarray_v2:\n+            non_assigned_to_response_docs: DocumentArray = DocumentArray.empty()\n+        else:\n+            non_assigned_to_response_docs = self._response_docarray_cls()\n \n-                        sum_from_previous_first_req_idx = (\n-                            len(non_assigned_to_response_docs) - num_assigned_docs\n+        non_assigned_to_response_request_idxs = []\n+        sum_from_previous_first_req_idx = 0\n+        for docs_inner_batch, req_idxs in batch(\n+            big_doc_in_batch, requests_idxs_in_batch, self._preferred_batch_size if not self._flush_all else None\n+        ):\n+            involved_requests_min_indx = req_idxs[0]\n+            involved_requests_max_indx = req_idxs[-1]\n+            input_len_before_call: int = len(docs_inner_batch)\n+            batch_res_docs = None\n+            try:\n+                batch_res_docs = await self.func(\n+                    docs=docs_inner_batch,\n+                    parameters=self.params,\n+                    docs_matrix=None,  # joining manually with batch queue is not supported right now\n+                    tracing_context=None,\n+                )\n+                # Output validation\n+                if (docarray_v2 and isinstance(batch_res_docs, DocList)) or (\n+                    not docarray_v2\n+                    and isinstance(batch_res_docs, DocumentArray)\n+                ):\n+                    if not len(batch_res_docs) == input_len_before_call:\n+                        raise ValueError(\n+                            f'Dynamic Batching requires input size to equal output size. Expected output size {input_len_before_call}, but got {len(batch_res_docs)}'\n                         )\n-                        non_assigned_to_response_docs = non_assigned_to_response_docs[\n-                            num_assigned_docs:\n-                        ]\n-                        non_assigned_to_response_request_idxs = (\n-                            non_assigned_to_response_request_idxs[num_assigned_docs:]\n+                elif batch_res_docs is None:\n+                    if not len(docs_inner_batch) == input_len_before_call:\n+                        raise ValueError(\n+                            f'Dynamic Batching requires input size to equal output size. Expected output size {input_len_before_call}, but got {len(docs_inner_batch)}'\n                         )\n-                if len(non_assigned_to_response_request_idxs) > 0:\n-                    _ = await _assign_results(\n-                        non_assigned_to_response_docs,\n-                        non_assigned_to_response_request_idxs,\n-                        sum_from_previous_first_req_idx,\n+                else:\n+                    array_name = (\n+                        'DocumentArray' if not docarray_v2 else 'DocList'\n+                    )\n+                    raise TypeError(\n+                        f'The return type must be {array_name} / `None` when using dynamic batching, '\n+                        f'but getting {batch_res_docs!r}'\n                     )\n-            finally:\n-                self._reset()\n+            except Exception as exc:\n+                # All the requests containing docs in this Exception should be raising it\n+                for request_full in requests_completed_in_batch[\n+                    involved_requests_min_indx : involved_requests_max_indx + 1\n+                ]:\n+                    await request_full.put(exc)\n+            else:\n+                # We need to attribute the docs to their requests\n+                non_assigned_to_response_docs.extend(\n+                    batch_res_docs or docs_inner_batch\n+                )\n+                non_assigned_to_response_request_idxs.extend(req_idxs)\n+                num_assigned_docs = await _assign_results(\n+                    non_assigned_to_response_docs,\n+                    non_assigned_to_response_request_idxs,\n+                    sum_from_previous_first_req_idx,\n+                    requests_lens_in_batch,\n+                    requests_in_batch,\n+                    requests_completed_in_batch,\n+                )\n+\n+                sum_from_previous_first_req_idx = (\n+                    len(non_assigned_to_response_docs) - num_assigned_docs\n+                )\n+                non_assigned_to_response_docs = non_assigned_to_response_docs[\n+                    num_assigned_docs:\n+                ]\n+                non_assigned_to_response_request_idxs = (\n+                    non_assigned_to_response_request_idxs[num_assigned_docs:]\n+                )\n+        if len(non_assigned_to_response_request_idxs) > 0:\n+            _ = await _assign_results(\n+                non_assigned_to_response_docs,\n+                non_assigned_to_response_request_idxs,\n+                sum_from_previous_first_req_idx,\n+                requests_lens_in_batch,\n+                requests_in_batch,\n+                requests_completed_in_batch,\n+            )\n \n     async def close(self):\n         \"\"\"Closes the batch queue by flushing pending requests.\"\"\"\ndiff --git a/tests/integration/dynamic_batching/test_dynamic_batching.py b/tests/integration/dynamic_batching/test_dynamic_batching.py\nindex 0a9bf57847e8c..483f247db7892 100644\n--- a/tests/integration/dynamic_batching/test_dynamic_batching.py\n+++ b/tests/integration/dynamic_batching/test_dynamic_batching.py\n@@ -636,7 +636,14 @@ def test_failure_propagation():\n         True\n     ],\n )\n-def test_exception_handling_in_dynamic_batch(flush_all):\n+@pytest.mark.parametrize(\n+    'allow_concurrent',\n+    [\n+        False,\n+        True\n+    ],\n+)\n+def test_exception_handling_in_dynamic_batch(flush_all, allow_concurrent):\n     class SlowExecutorWithException(Executor):\n \n         @dynamic_batching(preferred_batch_size=3, timeout=5000, flush_all=flush_all)\n@@ -646,7 +653,7 @@ def foo(self, docs, **kwargs):\n                 if doc.text == 'fail':\n                     raise Exception('Fail is in the Batch')\n \n-    depl = Deployment(uses=SlowExecutorWithException)\n+    depl = Deployment(uses=SlowExecutorWithException, allow_concurrent=allow_concurrent)\n \n     with depl:\n         da = DocumentArray([Document(text='good') for _ in range(50)])\n@@ -670,6 +677,7 @@ def foo(self, docs, **kwargs):\n         else:\n             assert 1 <= num_failed_requests <= len(da)  # 3 requests in the dynamic batch failing\n \n+\n @pytest.mark.asyncio\n @pytest.mark.parametrize(\n     'flush_all',\n@@ -694,11 +702,11 @@ def foo(self, docs, **kwargs):\n         cl = Client(protocol=depl.protocol, port=depl.port, asyncio=True)\n         res = []\n         async for r in cl.post(\n-            on='/foo',\n-            inputs=da,\n-            request_size=7,\n-            continue_on_error=True,\n-            results_in_order=True,\n+                on='/foo',\n+                inputs=da,\n+                request_size=7,\n+                continue_on_error=True,\n+                results_in_order=True,\n         ):\n             res.extend(r)\n         assert len(res) == 50  # 1 request per input\n@@ -707,8 +715,11 @@ def foo(self, docs, **kwargs):\n                 assert int(d.text) <= 5\n         else:\n             larger_than_5 = 0\n+            smaller_than_5 = 0\n             for d in res:\n                 if int(d.text) > 5:\n                     larger_than_5 += 1\n-                assert int(d.text) >= 5\n+                if int(d.text) < 5:\n+                    smaller_than_5 += 1\n+            assert smaller_than_5 == 1\n             assert larger_than_5 > 0\ndiff --git a/tests/unit/serve/dynamic_batching/test_batch_queue.py b/tests/unit/serve/dynamic_batching/test_batch_queue.py\nindex bb922ed60d970..9db1958b86e05 100644\n--- a/tests/unit/serve/dynamic_batching/test_batch_queue.py\n+++ b/tests/unit/serve/dynamic_batching/test_batch_queue.py\n@@ -64,11 +64,13 @@ async def process_request(req):\n @pytest.mark.parametrize('flush_all', [False, True])\n async def test_batch_queue_timeout_does_not_wait_previous_batch(flush_all):\n     batches_lengths_computed = []\n+    lock = asyncio.Lock()\n \n     async def foo(docs, **kwargs):\n-        await asyncio.sleep(4)\n-        batches_lengths_computed.append(len(docs))\n-        return DocumentArray([Document(text='Done') for _ in docs])\n+        async with lock:\n+            await asyncio.sleep(4)\n+            batches_lengths_computed.append(len(docs))\n+            return DocumentArray([Document(text='Done') for _ in docs])\n \n     bq: BatchQueue = BatchQueue(\n         foo,\n@@ -109,7 +111,7 @@ async def process_request(req, sleep=0):\n         assert time_spent >= 8000\n         assert time_spent <= 8500\n     if flush_all is False:\n-        assert batches_lengths_computed == [5, 1, 2]\n+        assert batches_lengths_computed == [5, 2, 1]\n     else:\n         assert batches_lengths_computed == [6, 2]\n \n"},"summary":"## Summary of Merge Request\n\nДанный merge request направлен на оптимизацию работы очереди пакетов в Jina, в частности, на повышение производительности и стабильности. Основные изменения включают удаление блокировки `_data_lock` в методе `push` и добавление `self._flush_trigger: Event = Event()`. Экспертная оценка относит сложность изменений к уровню \"Medium\". Код соответствует принятым стандартам, с оценкой 8 по Code Style, и улучшает обработку пакетов, устраняя потенциальные проблемы с блокировками данных (оценка 9 по Design Patterns и 10 по Anti-Patterns). Рекомендуется проверить влияние изменений на производительность и убедиться в успешном прохождении всех тестов.\n","antiPatterns":{"detailed_analysis":"Внесенные изменения направлены на устранение блокировок данных в очереди пакетов, что является улучшением.  В частности, удаление `async with self._data_lock:` и замена его на копирование данных перед обработкой. Это снижает вероятность возникновения проблем с блокировками и улучшает производительность.  Изменения также включают в себя рефакторинг для повышения читаемости и упрощения логики.  Анти-паттерны не обнаружены, изменения направлены на улучшение существующего кода.","recommendations":[],"confidence":"High","score":10,"summary":"Изменения улучшают обработку пакетов, устраняя потенциальные проблемы с блокировками данных и повышая производительность."},"complexity":{"justification":"Это изменение направлено на оптимизацию работы очереди пакетов в Jina. Основные изменения включают в себя: удаление `async with self._data_lock` из метода `push`, что, вероятно, направлено на повышение производительности, и добавление `self._flush_trigger: Event = Event()` для управления потоком выполнения. Также были внесены изменения в логику обработки пакетов в методе `_assign_results` и в функции `batch`. Эти изменения затрагивают критические части системы, но не вводят сложную логику или новые зависимости. Объем изменений умеренный, и они требуют понимания взаимодействия между компонентами. Риски умеренные, так как изменения направлены на оптимизацию, а не на реализацию новых функций. Когнитивная нагрузка умеренная, так как изменения требуют понимания логики работы очереди пакетов, но не требуют глубоких знаний архитектуры системы. В целом, изменения соответствуют уровню сложности \"Medium\".","classification":"Medium"},"designPatterns":{"detailed_analysis":"Внесенные изменения направлены на устранение блокировок данных в очереди пакетов, что является улучшением.  В частности, изменения в `batch_queue.py` направлены на копирование данных перед обработкой, чтобы избежать проблем с блокировками. Это снижает риск возникновения состояний гонки и улучшает общую производительность.  В коде также были внесены изменения в логику обработки исключений и управления задачами, что повышает надежность.  В целом, эти изменения улучшают структуру и надежность кода, устраняя потенциальные проблемы с блокировками.  В `test_dynamic_batching.py` и `test_batch_queue.py` были внесены изменения в тесты для поддержки изменений в `batch_queue.py`.","recommendations":["Продолжать следовать принципам избежания блокировок при разработке многопоточных приложений.","Убедиться, что все тесты проходят успешно после внесения изменений."],"confidence":"High","score":9,"summary":"Изменения улучшают обработку пакетов, устраняя потенциальные проблемы с блокировками данных."},"codeStyle":{"detailed_analysis":"Внесенные изменения в основном направлены на оптимизацию работы `BatchQueue` и устранение потенциальных проблем с блокировками данных.  В частности, убрана блокировка `_data_lock` в методе `push`, что должно улучшить производительность.  Также внесены изменения в логику обработки батчей, включая копирование данных перед обработкой, что повышает надежность.  В коде присутствует незначительное изменение в порядке вызова функций в тесте `test_batch_queue_timeout_does_not_wait_previous_batch`, что может быть связано с изменением логики работы `BatchQueue`.  В целом, изменения направлены на улучшение производительности и стабильности, что соответствует хорошему стилю кодирования.","recommendations":["Проверить влияние изменений на производительность в реальных условиях.","Убедиться, что все тесты проходят успешно после внесения изменений."],"confidence":"High","score":8,"summary":"Изменения вносят улучшения в `BatchQueue`, направленные на повышение производительности и стабильности. Код соответствует принятым стандартам, но требуется дополнительная проверка производительности."}},{"pull":{"id":6189,"html_url":"https://github.com/jina-ai/serve/pull/6189","title":"feat: add custom_metric for dynamic batching","body":"Goals:\n\n\n\nresolves #ISSUE-NUMBER\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n check and update documentation. See guide and ask the team.","is_merged":true,"diff":"diff --git a/jina/serve/executors/__init__.py b/jina/serve/executors/__init__.py\nindex c821c5c1d0936..9e00c8e77a98f 100644\n--- a/jina/serve/executors/__init__.py\n+++ b/jina/serve/executors/__init__.py\n@@ -655,9 +655,22 @@ def _validate_sagemaker(self):\n             return\n \n     def _add_dynamic_batching(self, _dynamic_batching: Optional[Dict]):\n+        import collections\n+\n+        def deep_update(source, overrides):\n+            for key, value in overrides.items():\n+                if isinstance(value, collections.Mapping) and value:\n+                    returned = deep_update(source.get(key, {}), value)\n+                    source[key] = returned\n+                else:\n+                    source[key] = overrides[key]\n+            return source\n+\n         if _dynamic_batching:\n             self.dynamic_batching = getattr(self, 'dynamic_batching', {})\n-            self.dynamic_batching.update(_dynamic_batching)\n+            self.dynamic_batching = deep_update(\n+                self.dynamic_batching, _dynamic_batching\n+            )\n \n     def _add_metas(self, _metas: Optional[Dict]):\n         from jina.serve.executors.metas import get_default_metas\ndiff --git a/jina/serve/executors/decorators.py b/jina/serve/executors/decorators.py\nindex 7c7a6e4031bcf..b9072929cbed7 100644\n--- a/jina/serve/executors/decorators.py\n+++ b/jina/serve/executors/decorators.py\n@@ -416,7 +416,9 @@ def dynamic_batching(\n     *,\n     preferred_batch_size: Optional[int] = None,\n     timeout: Optional[float] = 10_000,\n-    flush_all: bool = False\n+    flush_all: bool = False,\n+    custom_metric: Optional[Callable[['DocumentArray'], Union[float, int]]] = None,\n+    use_custom_metric: bool = False,\n ):\n     \"\"\"\n     `@dynamic_batching` defines the dynamic batching behavior of an Executor.\n@@ -434,6 +436,8 @@ def dynamic_batching(\n         Default is 10_000ms (10 seconds).\n     :param flush_all: Determines if once the batches is triggered by timeout or preferred_batch_size, the function will receive everything that the batcher has accumulated or not.\n         If this is true, `preferred_batch_size` is used as a trigger mechanism.\n+    :param custom_metric: Potential lambda function to measure the \"weight\" of each request.\n+    :param use_custom_metric: Determines if we need to use the `custom_metric` to determine preferred_batch_size.\n     :return: decorated function\n     \"\"\"\n \n@@ -480,6 +484,8 @@ def _inject_owner_attrs(self, owner, name):\n             ] = preferred_batch_size\n             owner.dynamic_batching[fn_name]['timeout'] = timeout\n             owner.dynamic_batching[fn_name]['flush_all'] = flush_all\n+            owner.dynamic_batching[fn_name]['use_custom_metric'] = use_custom_metric\n+            owner.dynamic_batching[fn_name]['custom_metric'] = custom_metric\n             setattr(owner, name, self.fn)\n \n         def __set_name__(self, owner, name):\ndiff --git a/jina/serve/runtimes/worker/batch_queue.py b/jina/serve/runtimes/worker/batch_queue.py\nindex 0419e35414a46..31bac588d5efd 100644\n--- a/jina/serve/runtimes/worker/batch_queue.py\n+++ b/jina/serve/runtimes/worker/batch_queue.py\n@@ -1,9 +1,10 @@\n import asyncio\n import copy\n from asyncio import Event, Task\n-from typing import Callable, Dict, List, Optional, TYPE_CHECKING\n+from typing import Callable, Dict, List, Optional, TYPE_CHECKING, Union\n from jina._docarray import docarray_v2\n import contextlib\n+\n if not docarray_v2:\n     from docarray import DocumentArray\n else:\n@@ -18,16 +19,18 @@ class BatchQueue:\n     \"\"\"A batch queue that holds the data request and the callable to batch requests to.\"\"\"\n \n     def __init__(\n-        self,\n-        func: Callable,\n-        request_docarray_cls,\n-        response_docarray_cls,\n-        output_array_type: Optional[str] = None,\n-        params: Optional[Dict] = None,\n-        allow_concurrent: bool = False,\n-        flush_all: bool = False,\n-        preferred_batch_size: int = 4,\n-        timeout: int = 10_000,\n+            self,\n+            func: Callable,\n+            request_docarray_cls,\n+            response_docarray_cls,\n+            output_array_type: Optional[str] = None,\n+            params: Optional[Dict] = None,\n+            allow_concurrent: bool = False,\n+            flush_all: bool = False,\n+            preferred_batch_size: int = 4,\n+            timeout: int = 10_000,\n+            custom_metric: Optional[Callable[['DocumentArray'], Union[int, float]]] = None,\n+            use_custom_metric: bool = False,\n     ) -> None:\n         # To keep old user behavior, we use data lock when flush_all is true and no allow_concurrent\n         if allow_concurrent and flush_all:\n@@ -44,6 +47,8 @@ def __init__(\n         self._response_docarray_cls = response_docarray_cls\n         self._flush_all = flush_all\n         self._preferred_batch_size: int = preferred_batch_size\n+        self._custom_metric = None if not use_custom_metric else custom_metric\n+        self._metric_value = 0\n         self._timeout: int = timeout\n         self._reset()\n         self._flush_trigger: Event = Event()\n@@ -62,20 +67,22 @@ def _reset(self) -> None:\n         # a list of every request ID\n         self._request_idxs: List[int] = []\n         self._request_lens: List[int] = []\n+        self._docs_metrics: List[int] = []\n         self._requests_completed: List[asyncio.Queue] = []\n         if not docarray_v2:\n             self._big_doc: DocumentArray = DocumentArray.empty()\n         else:\n             self._big_doc = self._request_docarray_cls()\n+        self._metric_value = 0\n \n         self._flush_task: Optional[Task] = None\n         self._flush_trigger: Event = Event()\n \n     def _cancel_timer_if_pending(self):\n         if (\n-            self._timer_task\n-            and not self._timer_task.done()\n-            and not self._timer_task.cancelled()\n+                self._timer_task\n+                and not self._timer_task.done()\n+                and not self._timer_task.cancelled()\n         ):\n             self._timer_finished = False\n             self._timer_task.cancel()\n@@ -91,7 +98,7 @@ async def _sleep_then_set(self):\n         self._flush_trigger.set()\n         self._timer_finished = True\n \n-    async def push(self, request: DataRequest, http = False) -> asyncio.Queue:\n+    async def push(self, request: DataRequest, http=False) -> asyncio.Queue:\n         \"\"\"Append request to the the list of requests to be processed.\n \n         This method creates an asyncio Queue for that request and keeps track of it. It returns\n@@ -116,12 +123,18 @@ async def push(self, request: DataRequest, http = False) -> asyncio.Queue:\n             self._big_doc.extend(docs)\n             next_req_idx = len(self._requests)\n             num_docs = len(docs)\n+            metric_value = num_docs\n+            if self._custom_metric is not None:\n+                metrics = [self._custom_metric(doc) for doc in docs]\n+                metric_value += sum(metrics)\n+                self._docs_metrics.extend(metrics)\n+            self._metric_value += metric_value\n             self._request_idxs.extend([next_req_idx] * num_docs)\n-            self._request_lens.append(len(docs))\n+            self._request_lens.append(num_docs)\n             self._requests.append(request)\n             queue = asyncio.Queue()\n             self._requests_completed.append(queue)\n-            if len(self._big_doc) >= self._preferred_batch_size:\n+            if self._metric_value >= self._preferred_batch_size:\n                 self._flush_trigger.set()\n \n         return queue\n@@ -132,10 +145,10 @@ async def _await_then_flush(self, http=False) -> None:\n         \"\"\"\n \n         def _get_docs_groups_completed_request_indexes(\n-            non_assigned_docs,\n-            non_assigned_docs_reqs_idx,\n-            sum_from_previous_mini_batch_in_first_req_idx,\n-            requests_lens_in_batch,\n+                non_assigned_docs,\n+                non_assigned_docs_reqs_idx,\n+                sum_from_previous_mini_batch_in_first_req_idx,\n+                requests_lens_in_batch,\n         ):\n             \"\"\"\n             This method groups all the `non_assigned_docs` into groups of docs according to the `req_idx` they belong to.\n@@ -160,9 +173,9 @@ def _get_docs_groups_completed_request_indexes(\n                 )\n                 if req_idx > min_involved_req_idx:\n                     request_bucket = non_assigned_docs[\n-                        num_distributed_docs : num_distributed_docs\n-                        + num_docs_in_req_idx\n-                    ]\n+                                     num_distributed_docs: num_distributed_docs\n+                                                           + num_docs_in_req_idx\n+                                     ]\n                     num_distributed_docs += num_docs_in_req_idx\n                     completed_req_idx.append(min_involved_req_idx)\n                     min_involved_req_idx = req_idx\n@@ -171,25 +184,25 @@ def _get_docs_groups_completed_request_indexes(\n                 num_docs_in_req_idx += 1\n \n             if (\n-                req_idx not in completed_req_idx\n-                and num_docs_in_req_idx + sum_from_previous_mini_batch_in_first_req_idx\n-                == requests_lens_in_batch[req_idx]\n+                    req_idx not in completed_req_idx\n+                    and num_docs_in_req_idx + sum_from_previous_mini_batch_in_first_req_idx\n+                    == requests_lens_in_batch[req_idx]\n             ):\n                 completed_req_idx.append(req_idx)\n                 request_bucket = non_assigned_docs[\n-                    num_distributed_docs : num_distributed_docs + num_docs_in_req_idx\n-                ]\n+                                 num_distributed_docs: num_distributed_docs + num_docs_in_req_idx\n+                                 ]\n                 distributed_requests.append(request_bucket)\n \n             return distributed_requests, completed_req_idx\n \n         async def _assign_results(\n-            non_assigned_docs,\n-            non_assigned_docs_reqs_idx,\n-            sum_from_previous_mini_batch_in_first_req_idx,\n-            requests_lens_in_batch,\n-            requests_in_batch,\n-            requests_completed_in_batch,\n+                non_assigned_docs,\n+                non_assigned_docs_reqs_idx,\n+                sum_from_previous_mini_batch_in_first_req_idx,\n+                requests_lens_in_batch,\n+                requests_in_batch,\n+                requests_completed_in_batch,\n         ):\n             \"\"\"\n             This method aims to assign to the corresponding request objects the resulting documents from the mini batches.\n@@ -220,7 +233,7 @@ async def _assign_results(\n                 request = requests_in_batch[request_idx]\n                 request_completed = requests_completed_in_batch[request_idx]\n                 if http is False or self._output_array_type is not None:\n-                    request.direct_docs = None # batch queue will work in place, therefore result will need to read from data.\n+                    request.direct_docs = None  # batch queue will work in place, therefore result will need to read from data.\n                     request.data.set_docs_convert_arrays(\n                         docs_group, ndarray_type=self._output_array_type\n                     )\n@@ -230,15 +243,31 @@ async def _assign_results(\n \n             return num_assigned_docs\n \n-        def batch(iterable_1, iterable_2, n:Optional[int] = 1):\n+        def batch(iterable_1, iterable_2, n: Optional[int] = 1, iterable_metrics: Optional = None):\n             if n is None:\n                 yield iterable_1, iterable_2\n                 return\n-            items = len(iterable_1)\n-            for ndx in range(0, items, n):\n-                yield iterable_1[ndx : min(ndx + n, items)], iterable_2[\n-                    ndx : min(ndx + n, items)\n-                ]\n+            elif iterable_metrics is None:\n+                items = len(iterable_1)\n+                for ndx in range(0, items, n):\n+                    yield iterable_1[ndx: min(ndx + n, items)], iterable_2[\n+                                                                ndx: min(ndx + n, items)\n+                                                                ]\n+            else:\n+                batch_idx = 0\n+                batch_weight = 0\n+\n+                for i, (item, weight) in enumerate(zip(iterable_1, iterable_metrics)):\n+                    batch_weight += weight\n+\n+                    if batch_weight >= n:\n+                        yield iterable_1[batch_idx: i + 1], iterable_2[batch_idx: i + 1]\n+                        batch_idx = i + 1\n+                        batch_weight = 0\n+\n+                # Yield any remaining items\n+                if batch_weight > 0:\n+                    yield iterable_1[batch_idx: len(iterable_1)], iterable_2[batch_idx: len(iterable_1)]\n \n         await self._flush_trigger.wait()\n         # writes to shared data between tasks need to be mutually exclusive\n@@ -246,6 +275,7 @@ def batch(iterable_1, iterable_2, n:Optional[int] = 1):\n             big_doc_in_batch = copy.copy(self._big_doc)\n             requests_idxs_in_batch = copy.copy(self._request_idxs)\n             requests_lens_in_batch = copy.copy(self._request_lens)\n+            docs_metrics_in_batch = copy.copy(self._docs_metrics)\n             requests_in_batch = copy.copy(self._requests)\n             requests_completed_in_batch = copy.copy(self._requests_completed)\n \n@@ -263,7 +293,8 @@ def batch(iterable_1, iterable_2, n:Optional[int] = 1):\n             non_assigned_to_response_request_idxs = []\n             sum_from_previous_first_req_idx = 0\n             for docs_inner_batch, req_idxs in batch(\n-                big_doc_in_batch, requests_idxs_in_batch, self._preferred_batch_size if not self._flush_all else None\n+                    big_doc_in_batch, requests_idxs_in_batch,\n+                    self._preferred_batch_size if not self._flush_all else None, docs_metrics_in_batch if self._custom_metric is not None else None\n             ):\n                 involved_requests_min_indx = req_idxs[0]\n                 involved_requests_max_indx = req_idxs[-1]\n@@ -278,8 +309,8 @@ def batch(iterable_1, iterable_2, n:Optional[int] = 1):\n                     )\n                     # Output validation\n                     if (docarray_v2 and isinstance(batch_res_docs, DocList)) or (\n-                        not docarray_v2\n-                        and isinstance(batch_res_docs, DocumentArray)\n+                            not docarray_v2\n+                            and isinstance(batch_res_docs, DocumentArray)\n                     ):\n                         if not len(batch_res_docs) == input_len_before_call:\n                             raise ValueError(\n@@ -301,8 +332,8 @@ def batch(iterable_1, iterable_2, n:Optional[int] = 1):\n                 except Exception as exc:\n                     # All the requests containing docs in this Exception should be raising it\n                     for request_full in requests_completed_in_batch[\n-                        involved_requests_min_indx : involved_requests_max_indx + 1\n-                    ]:\n+                                        involved_requests_min_indx: involved_requests_max_indx + 1\n+                                        ]:\n                         await request_full.put(exc)\n                 else:\n                     # We need to attribute the docs to their requests\n@@ -320,11 +351,11 @@ def batch(iterable_1, iterable_2, n:Optional[int] = 1):\n                     )\n \n                     sum_from_previous_first_req_idx = (\n-                        len(non_assigned_to_response_docs) - num_assigned_docs\n+                            len(non_assigned_to_response_docs) - num_assigned_docs\n                     )\n                     non_assigned_to_response_docs = non_assigned_to_response_docs[\n-                        num_assigned_docs:\n-                    ]\n+                                                    num_assigned_docs:\n+                                                    ]\n                     non_assigned_to_response_request_idxs = (\n                         non_assigned_to_response_request_idxs[num_assigned_docs:]\n                     )\ndiff --git a/tests/integration/dynamic_batching/test_dynamic_batching.py b/tests/integration/dynamic_batching/test_dynamic_batching.py\nindex 87e98455317bb..b55e8415c0aae 100644\n--- a/tests/integration/dynamic_batching/test_dynamic_batching.py\n+++ b/tests/integration/dynamic_batching/test_dynamic_batching.py\n@@ -736,3 +736,67 @@ def foo(self, docs, **kwargs):\n \n             assert smaller_than_5 == (1 if allow_concurrent else 0)\n             assert larger_than_5 > 0\n+\n+\n+@pytest.mark.asyncio\n+@pytest.mark.parametrize('use_custom_metric', [True, False])\n+@pytest.mark.parametrize('flush_all', [False, True])\n+async def test_dynamic_batching_custom_metric(use_custom_metric, flush_all):\n+    class DynCustomBatchProcessor(Executor):\n+\n+        @dynamic_batching(preferred_batch_size=10, custom_metric=lambda x: len(x.text))\n+        @requests(on='/foo')\n+        def foo(self, docs, **kwargs):\n+            time.sleep(0.5)\n+            total_len = sum([len(doc.text) for doc in docs])\n+            for doc in docs:\n+                doc.text = f\"{total_len}\"\n+\n+    depl = Deployment(uses=DynCustomBatchProcessor, uses_dynamic_batching={'foo': {\"preferred_batch_size\": 10, \"timeout\": 2000, \"use_custom_metric\": use_custom_metric, \"flush_all\": flush_all}})\n+    da = DocumentArray([Document(text='aaaaa') for i in range(50)])\n+    with depl:\n+        cl = Client(protocol=depl.protocol, port=depl.port, asyncio=True)\n+        res = []\n+        async for r in cl.post(\n+                on='/foo',\n+                inputs=da,\n+                request_size=1,\n+                continue_on_error=True,\n+                results_in_order=True,\n+        ):\n+            res.extend(r)\n+        assert len(res) == 50  # 1 request per input\n+\n+    # If custom_metric and flush all\n+    if use_custom_metric and not flush_all:\n+        for doc in res:\n+            assert doc.text == \"10\"\n+\n+    elif not use_custom_metric and not flush_all:\n+        for doc in res:\n+            assert doc.text == \"50\"\n+\n+    elif use_custom_metric and flush_all:\n+        # There will be 2 \"10\" and the rest will be \"240\"\n+        num_10 = 0\n+        num_240 = 0\n+        for doc in res:\n+            if doc.text == \"10\":\n+                num_10 += 1\n+            elif doc.text == \"240\":\n+                num_240 += 1\n+\n+        assert num_10 == 2\n+        assert num_240 == 48\n+    elif not use_custom_metric and flush_all:\n+        # There will be 10 \"50\" and the rest will be \"200\"\n+        num_50 = 0\n+        num_200 = 0\n+        for doc in res:\n+            if doc.text == \"50\":\n+                num_50 += 1\n+            elif doc.text == \"200\":\n+                num_200 += 1\n+\n+        assert num_50 == 10\n+        assert num_200 == 40\ndiff --git a/tests/unit/serve/executors/test_executor.py b/tests/unit/serve/executors/test_executor.py\nindex a6d902421ae83..344ebcaab7254 100644\n--- a/tests/unit/serve/executors/test_executor.py\n+++ b/tests/unit/serve/executors/test_executor.py\n@@ -614,15 +614,15 @@ class C(B):\n     [\n         (\n             dict(preferred_batch_size=4, timeout=5_000),\n-            dict(preferred_batch_size=4, timeout=5_000, flush_all=False),\n+            dict(preferred_batch_size=4, timeout=5_000, flush_all=False, use_custom_metric=False, custom_metric=None),\n         ),\n         (\n             dict(preferred_batch_size=4, timeout=5_000, flush_all=True),\n-            dict(preferred_batch_size=4, timeout=5_000, flush_all=True),\n+            dict(preferred_batch_size=4, timeout=5_000, flush_all=True, use_custom_metric=False, custom_metric=None),\n         ),\n         (\n             dict(preferred_batch_size=4),\n-            dict(preferred_batch_size=4, timeout=10_000, flush_all=False),\n+            dict(preferred_batch_size=4, timeout=10_000, flush_all=False, use_custom_metric=False, custom_metric=None),\n         ),\n     ],\n )\n@@ -641,15 +641,15 @@ def foo(self, docs, **kwargs):\n     [\n         (\n             dict(preferred_batch_size=4, timeout=5_000),\n-            dict(preferred_batch_size=4, timeout=5_000, flush_all=False),\n+            dict(preferred_batch_size=4, timeout=5_000, flush_all=False, use_custom_metric=False, custom_metric=None),\n         ),\n         (\n             dict(preferred_batch_size=4, timeout=5_000, flush_all=True),\n-            dict(preferred_batch_size=4, timeout=5_000, flush_all=True),\n+            dict(preferred_batch_size=4, timeout=5_000, flush_all=True, use_custom_metric=False, custom_metric=None),\n         ),\n         (\n             dict(preferred_batch_size=4),\n-            dict(preferred_batch_size=4, timeout=10_000, flush_all=False),\n+            dict(preferred_batch_size=4, timeout=10_000, flush_all=False, use_custom_metric=False, custom_metric=None),\n         ),\n     ],\n )\n"},"summary":"## Summary of Merge Request\n\nДанный MR направлен на добавление функциональности динамической пакетной обработки с использованием пользовательских метрик в Jina. Основные изменения включают добавление параметров `custom_metric` и `use_custom_metric` в декоратор `@dynamic_batching` и реализацию логики их использования в `BatchQueue`. Экспертная оценка относит сложность изменений к уровню \"Medium\". Код хорошо отформатирован и соответствует стандартам, с небольшими рекомендациями по улучшению комментариев и тестирования (Code Style: 8). Внедренные изменения не содержат анти-паттернов (Anti-Patterns: 10) и улучшают существующую систему, расширяя ее функциональность (Design Patterns: 9).\n","antiPatterns":{"detailed_analysis":"Внесенные изменения добавляют функциональность для динамической пакетной обработки с использованием пользовательских метрик. В `jina/serve/executors/decorators.py` добавлен параметр `custom_metric` в декоратор `@dynamic_batching`, позволяющий задать функцию для вычисления \"веса\" каждого запроса. В `jina/serve/runtimes/worker/batch_queue.py` реализована логика использования `custom_metric` для определения размера пакета. В целом, изменения направлены на улучшение производительности и гибкости динамической пакетной обработки. Анти-паттерны не обнаружены.","recommendations":[],"confidence":"High","score":10,"summary":"Внесенные изменения не содержат анти-паттернов и улучшают функциональность динамической пакетной обработки."},"complexity":{"justification":"Данный MR добавляет функциональность для динамической пакетной обработки в Jina. Он включает в себя изменения в нескольких файлах, включая `jina/serve/executors/__init__.py`, `jina/serve/executors/decorators.py`, `jina/serve/runtimes/worker/batch_queue.py`, и тесты. Основные изменения включают в себя добавление возможности использовать пользовательскую метрику для определения размера пакета, что может повлиять на производительность и поведение пакетной обработки. Объем изменений умеренный, затрагивает логику работы исполнителей и очереди пакетов. Влияние на систему умеренное, так как затрагивает механизм пакетной обработки, но не затрагивает критические компоненты напрямую. Когнитивная нагрузка умеренная, так как требуется понимание логики динамической пакетной обработки и добавленных опций. Риски умеренные, так как изменения в основном касаются конфигурации и логики пакетной обработки, но могут потребовать тщательного тестирования для обеспечения корректной работы.  Примеры изменений включают добавление параметров `custom_metric` и `use_custom_metric` в декоратор `@dynamic_batching`, а также изменения в `BatchQueue` для поддержки пользовательской метрики.  В целом, изменения соответствуют уровню сложности \"Medium\".","classification":"Medium"},"designPatterns":{"detailed_analysis":"Внесенные изменения добавляют функциональность для динамической пакетной обработки с использованием пользовательских метрик. В частности, изменения включают в себя добавление параметров `custom_metric` и `use_custom_metric` в декоратор `@dynamic_batching` и соответствующие изменения в `BatchQueue`. Это позволяет пользователям определять функцию для вычисления \"веса\" каждого запроса, что влияет на размер пакета. Это улучшение, хотя и добавляет сложность, не вводит анти-паттернов, а скорее расширяет функциональность существующей системы. Код хорошо структурирован и соответствует лучшим практикам. Добавлены тесты для проверки новой функциональности.","recommendations":[],"confidence":"High","score":9,"summary":"Внесенные изменения добавляют функциональность для динамической пакетной обработки с использованием пользовательских метрик, что является улучшением, не вводящим анти-паттернов."},"codeStyle":{"detailed_analysis":"Внесенные изменения включают в себя добавление функциональности для динамической пакетной обработки с использованием пользовательских метрик.  В частности, были добавлены параметры `custom_metric` и `use_custom_metric` в декоратор `dynamic_batching` и класс `BatchQueue`.  Это позволяет пользователям определять функцию для вычисления \"веса\" каждого запроса, что влияет на размер пакета.  Изменения затрагивают файлы `jina/serve/executors/decorators.py`, `jina/serve/runtimes/worker/batch_queue.py`, и тесты в `tests/integration/dynamic_batching/test_dynamic_batching.py` и `tests/unit/serve/executors/test_executor.py`.  Форматирование в целом соответствует стандартам, за исключением, возможно, незначительных отклонений в пробелах.  Имена переменных и функций, как правило, понятны и соответствуют соглашениям.  Изменения последовательны и соответствуют существующему стилю кодовой базы.  Читаемость улучшена за счет добавления комментариев и пояснений.  Соответствие руководству по стилю хорошее, с небольшими отклонениями.  В целом, изменения хорошо структурированы и легко понимаются.","recommendations":["Убедитесь, что добавленные комментарии достаточно информативны и объясняют логику работы с пользовательскими метриками.","Проверьте использование `custom_metric` в различных сценариях, чтобы убедиться в его корректной работе и отсутствии потенциальных проблем с производительностью."],"confidence":"High","score":8,"summary":"Добавлены функции для динамической пакетной обработки с использованием пользовательских метрик. Код хорошо отформатирован и соответствует стандартам. Небольшие улучшения в комментариях и тестировании могут улучшить качество кода."}},{"pull":{"id":6188,"html_url":"https://github.com/jina-ai/serve/pull/6188","title":"fix: pass allow_concurrent to runtime_args","body":"Goals:\n\n\n\nresolves #ISSUE-NUMBER\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n check and update documentation. See guide and ask the team.","is_merged":true,"diff":"diff --git a/jina/orchestrate/deployments/__init__.py b/jina/orchestrate/deployments/__init__.py\nindex 1d76601a68009..3eecfd3606aab 100644\n--- a/jina/orchestrate/deployments/__init__.py\n+++ b/jina/orchestrate/deployments/__init__.py\n@@ -1883,9 +1883,9 @@ def to_docker_compose_yaml(\n             yaml.dump(docker_compose_dict, fp, sort_keys=False)\n \n         command = (\n-            'docker-compose up'\n+            'docker compose up'\n             if output_path is None\n-            else f'docker-compose -f {output_path} up'\n+            else f'docker compose -f {output_path} up'\n         )\n \n         self.logger.info(\ndiff --git a/jina/orchestrate/flow/base.py b/jina/orchestrate/flow/base.py\nindex 4e3abe955bf11..9aec82444a280 100644\n--- a/jina/orchestrate/flow/base.py\n+++ b/jina/orchestrate/flow/base.py\n@@ -2851,9 +2851,9 @@ def to_docker_compose_yaml(\n             yaml.dump(docker_compose_dict, fp, sort_keys=False)\n \n         command = (\n-            'docker-compose up'\n+            'docker compose up'\n             if output_path is None\n-            else f'docker-compose -f {output_path} up'\n+            else f'docker compose -f {output_path} up'\n         )\n \n         self.logger.info(\ndiff --git a/jina/serve/runtimes/worker/request_handling.py b/jina/serve/runtimes/worker/request_handling.py\nindex 6d4b3fb31ffc9..456c94a7bdf41 100644\n--- a/jina/serve/runtimes/worker/request_handling.py\n+++ b/jina/serve/runtimes/worker/request_handling.py\n@@ -399,6 +399,7 @@ def _load_executor(\n                     'metrics_registry': metrics_registry,\n                     'tracer_provider': tracer_provider,\n                     'meter_provider': meter_provider,\n+                    'allow_concurrent': self.args.allow_concurrent,\n                 },\n                 py_modules=self.args.py_modules,\n                 extra_search_paths=self.args.extra_search_paths,\ndiff --git a/tests/conftest.py b/tests/conftest.py\nindex 6f400bf936c37..993a3f4794c00 100644\n--- a/tests/conftest.py\n+++ b/tests/conftest.py\n@@ -31,12 +31,12 @@ def test_metas(tmpdir, random_workspace_name):\n @pytest.fixture()\n def docker_compose(request):\n     os.system(\n-        f\"docker-compose -f {request.param} --project-directory . up  --build -d --remove-orphans\"\n+        f\"docker compose -f {request.param} --project-directory . up  --build -d --remove-orphans\"\n     )\n     time.sleep(10)\n     yield\n     os.system(\n-        f\"docker-compose -f {request.param} --project-directory . down --remove-orphans\"\n+        f\"docker compose -f {request.param} --project-directory . down --remove-orphans\"\n     )\n \n \ndiff --git a/tests/docker_compose/conftest.py b/tests/docker_compose/conftest.py\nindex 63f0681db50d8..aa5fb844c3f5f 100644\n--- a/tests/docker_compose/conftest.py\n+++ b/tests/docker_compose/conftest.py\n@@ -81,14 +81,14 @@ def __init__(self, dump_path, timeout_second=30):\n \n     def __enter__(self):\n         subprocess.run(\n-            f'docker-compose -f {self.dump_path} up --build -d --remove-orphans'.split(\n+            f'docker compose -f {self.dump_path} up --build -d --remove-orphans'.split(\n                 ' '\n             )\n         )\n \n         container_ids = (\n             subprocess.run(\n-                f'docker-compose -f {self.dump_path} ps -q'.split(' '),\n+                f'docker compose -f {self.dump_path} ps -q'.split(' '),\n                 capture_output=True,\n             )\n             .stdout.decode(\"utf-8\")\n@@ -127,5 +127,5 @@ def _are_all_container_healthy(\n \n     def __exit__(self, exc_type, exc_val, exc_tb):\n         subprocess.run(\n-            f'docker-compose -f {self.dump_path} down --remove-orphans'.split(' ')\n+            f'docker compose -f {self.dump_path} down --remove-orphans'.split(' ')\n         )\ndiff --git a/tests/integration/instrumentation/conftest.py b/tests/integration/instrumentation/conftest.py\nindex c25a7edf145bc..173e8421ee928 100644\n--- a/tests/integration/instrumentation/conftest.py\n+++ b/tests/integration/instrumentation/conftest.py\n@@ -35,12 +35,12 @@ def otlp_receiver_port():\n def otlp_collector(jaeger_port, prometheus_backend_port, otlp_receiver_port):\n     file_dir = os.path.dirname(__file__)\n     os.system(\n-        f\"docker-compose -f {os.path.join(file_dir, 'docker-compose.yml')} up -d --remove-orphans\"\n+        f\"docker compose -f {os.path.join(file_dir, 'docker-compose.yml')} up -d --remove-orphans\"\n     )\n     time.sleep(1)\n     yield\n     os.system(\n-        f\"docker-compose -f {os.path.join(file_dir, 'docker-compose.yml')} down --remove-orphans\"\n+        f\"docker compose -f {os.path.join(file_dir, 'docker-compose.yml')} down --remove-orphans\"\n     )\n \n \n"},"summary":"## Summary of Merge Request\n\nДанный MR направлен на обновление синтаксиса `docker-compose` на `docker compose` в различных файлах, а также добавление параметра `allow_concurrent` при загрузке executor. Основные изменения включают замену команд в файлах, таких как `jina/orchestrate/deployments/__init__.py`, `jina/orchestrate/flow/base.py`, и добавление параметра в `jina/serve/runtimes/worker/request_handling.py`. Оценка сложности низкая, так как изменения небольшие и не затрагивают критические компоненты. Код соответствует стандартам, оценка Code Style - 9 баллов. Изменения не вводят анти-паттерны, оценка - 10 баллов.\n","antiPatterns":{"detailed_analysis":"Внесенные изменения в основном заменяют `docker-compose` на `docker compose`. Это не является анти-паттерном, а скорее обновлением синтаксиса. Также добавлено `allow_concurrent` в `request_handling.py`, что не вносит анти-паттернов. Обновления в тестах также соответствуют замене синтаксиса и не содержат анти-паттернов.","recommendations":[],"confidence":"High","score":10,"summary":"Изменения в основном касаются обновления синтаксиса `docker-compose` и добавления параметра, не вводящих анти-паттернов."},"complexity":{"justification":"Данный MR содержит небольшие изменения, затрагивающие несколько файлов. Основные изменения включают замену `docker-compose` на `docker compose` в нескольких местах, а также добавление `allow_concurrent` в аргументы при загрузке executor. Эти изменения не затрагивают критические компоненты, не вводят сложную логику и не несут значительных рисков. Объем изменений невелик, и понимание изменений не требует глубоких знаний системы. Следовательно, сложность оценивается как низкая.","classification":"Low"},"designPatterns":{"detailed_analysis":"Внесенные изменения в основном затрагивают замену `docker-compose` на `docker compose` в командах. Это не вводит новых анти-паттернов и не устраняет существующие. Изменения в `request_handling.py` добавляют параметр `allow_concurrent`, что может повлиять на производительность, но не является анти-паттерном само по себе. Изменения в `tests/conftest.py` и других файлах тестов также касаются замены команд, что не влияет на анти-паттерны.","recommendations":[],"confidence":"High","score":9,"summary":"Изменения в основном касаются замены команд docker-compose, что не вводит анти-паттерны."},"codeStyle":{"detailed_analysis":"Изменения в основном касаются замены `docker-compose` на `docker compose` в командах. Это изменение затрагивает несколько файлов, включая `jina/orchestrate/deployments/__init__.py`, `jina/orchestrate/flow/base.py`, `tests/conftest.py`, `tests/docker_compose/conftest.py` и `tests/integration/instrumentation/conftest.py`. Также добавлено `allow_concurrent` в аргументы при загрузке executor в `jina/serve/runtimes/worker/request_handling.py`. Изменения в целом соответствуют принятому стилю кодирования, форматирование сохранено, имена переменных и функций понятны. Соответствие гайдлайнам в основном соблюдено, за исключением небольших изменений в командах docker compose, которые не влияют на читаемость или структуру кода.","recommendations":["Нет существенных рекомендаций по стилю кода."],"confidence":"High","score":9,"summary":"Внесенные изменения в основном касаются замены `docker-compose` на `docker compose` и добавления параметра `allow_concurrent`. Код соответствует стандартам."}},{"pull":{"id":6184,"html_url":"https://github.com/jina-ai/serve/pull/6184","title":"fix: fix optim issue with optimization","body":"Goals:\n\n\n\nresolves #ISSUE-NUMBER\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n check and update documentation. See guide and ask the team.","is_merged":true,"diff":"diff --git a/jina/serve/runtimes/worker/batch_queue.py b/jina/serve/runtimes/worker/batch_queue.py\nindex 8f7e0d283b413..572fcf6fe2743 100644\n--- a/jina/serve/runtimes/worker/batch_queue.py\n+++ b/jina/serve/runtimes/worker/batch_queue.py\n@@ -84,13 +84,14 @@ async def _sleep_then_set(self):\n         self._flush_trigger.set()\n         self._timer_finished = True\n \n-    async def push(self, request: DataRequest) -> asyncio.Queue:\n+    async def push(self, request: DataRequest, http = False) -> asyncio.Queue:\n         \"\"\"Append request to the the list of requests to be processed.\n \n         This method creates an asyncio Queue for that request and keeps track of it. It returns\n         this queue to the caller so that the caller can now when this request has been processed\n \n         :param request: The request to append to the queue.\n+        :param http: Flag to determine if the request is served via HTTP for some optims\n \n         :return: The queue that will receive when the request is processed.\n         \"\"\"\n@@ -103,7 +104,7 @@ async def push(self, request: DataRequest) -> asyncio.Queue:\n             self._start_timer()\n         async with self._data_lock:\n             if not self._flush_task:\n-                self._flush_task = asyncio.create_task(self._await_then_flush())\n+                self._flush_task = asyncio.create_task(self._await_then_flush(http))\n \n             self._big_doc.extend(docs)\n             next_req_idx = len(self._requests)\n@@ -118,8 +119,10 @@ async def push(self, request: DataRequest) -> asyncio.Queue:\n \n         return queue\n \n-    async def _await_then_flush(self) -> None:\n-        \"\"\"Process all requests in the queue once flush_trigger event is set.\"\"\"\n+    async def _await_then_flush(self, http=False) -> None:\n+        \"\"\"Process all requests in the queue once flush_trigger event is set.\n+        :param http: Flag to determine if the request is served via HTTP for some optims\n+        \"\"\"\n \n         def _get_docs_groups_completed_request_indexes(\n             non_assigned_docs,\n@@ -200,9 +203,13 @@ async def _assign_results(\n             for docs_group, request_idx in zip(docs_grouped, completed_req_idxs):\n                 request = self._requests[request_idx]\n                 request_completed = self._requests_completed[request_idx]\n-                request.data.set_docs_convert_arrays(\n-                    docs_group, ndarray_type=self._output_array_type\n-                )\n+                if http is False or self._output_array_type is not None:\n+                    request.direct_docs = None # batch queue will work in place, therefore result will need to read from data.\n+                    request.data.set_docs_convert_arrays(\n+                        docs_group, ndarray_type=self._output_array_type\n+                    )\n+                else:\n+                    request.direct_docs = docs_group\n                 await request_completed.put(None)\n \n             return num_assigned_docs\ndiff --git a/jina/serve/runtimes/worker/request_handling.py b/jina/serve/runtimes/worker/request_handling.py\nindex 7d9958c35c049..6d4b3fb31ffc9 100644\n--- a/jina/serve/runtimes/worker/request_handling.py\n+++ b/jina/serve/runtimes/worker/request_handling.py\n@@ -704,8 +704,9 @@ async def handle(\n                     **self._batchqueue_config[exec_endpoint],\n                 )\n             # This is necessary because push might need to await for the queue to be emptied\n+            # the batch queue will change the request in-place\n             queue = await self._batchqueue_instances[exec_endpoint][param_key].push(\n-                requests[0]\n+                requests[0], http=http\n             )\n             item = await queue.get()\n             queue.task_done()\ndiff --git a/tests/integration/docarray_v2/test_v2.py b/tests/integration/docarray_v2/test_v2.py\nindex eebbafd1a572f..f03fa4ddb9caf 100644\n--- a/tests/integration/docarray_v2/test_v2.py\n+++ b/tests/integration/docarray_v2/test_v2.py\n@@ -35,7 +35,7 @@ class Image(BaseDoc):\n         lll: List[List[str]] = [[]]\n         texts: DocList[TextDoc]\n \n-    class MyExec(Executor):\n+    class MyExecDifSchema(Executor):\n         @requests(on='/foo')\n         def foo(self, docs: DocList[Image], **kwargs) -> DocList[Image]:\n             for doc in docs:\n@@ -45,7 +45,7 @@ def foo(self, docs: DocList[Image], **kwargs) -> DocList[Image]:\n             return docs\n \n     ports = [random_port() for _ in protocols]\n-    with Flow(port=ports, protocol=protocols, replicas=replicas).add(uses=MyExec) as f:\n+    with Flow(port=ports, protocol=protocols, replicas=replicas).add(uses=MyExecDifSchema) as f:\n         for port, protocol in zip(ports, protocols):\n             c = Client(port=port, protocol=protocol)\n             docs = c.post(\n@@ -76,14 +76,14 @@ def test_send_custom_doc(protocols, replicas):\n     class MyDoc(BaseDoc):\n         my_text: str\n \n-    class MyExec(Executor):\n+    class MyExecCustomDoc(Executor):\n         @requests(on='/foo')\n         def foo(self, docs: DocList[MyDoc], **kwargs) -> DocList[MyDoc]:\n             docs[0].my_text = 'hello world'\n             return docs\n \n     ports = [random_port() for _ in protocols]\n-    with Flow(port=ports, protocol=protocols, replicas=replicas).add(uses=MyExec):\n+    with Flow(port=ports, protocol=protocols, replicas=replicas).add(uses=MyExecCustomDoc):\n         for port, protocol in zip(ports, protocols):\n             c = Client(port=port, protocol=protocol)\n             docs = c.post(\n@@ -100,7 +100,7 @@ def test_input_response_schema(protocols, replicas):\n     class MyDoc(BaseDoc):\n         text: str\n \n-    class MyExec(Executor):\n+    class MyExecRespSchema(Executor):\n         @requests(\n             on='/foo',\n             request_schema=DocList[MyDoc],\n@@ -112,7 +112,7 @@ def foo(self, docs, **kwargs):\n             return docs\n \n     ports = [random_port() for _ in protocols]\n-    with Flow(port=ports, protocol=protocols, replicas=replicas).add(uses=MyExec):\n+    with Flow(port=ports, protocol=protocols, replicas=replicas).add(uses=MyExecRespSchema):\n         for port, protocol in zip(ports, protocols):\n             c = Client(port=port, protocol=protocol)\n             docs = c.post(\n@@ -130,7 +130,7 @@ def test_input_response_schema_annotation(protocols, replicas):\n     class MyDoc(BaseDoc):\n         text: str\n \n-    class MyExec(Executor):\n+    class MyExecAnnotation(Executor):\n         @requests(on='/bar')\n         def bar(self, docs: DocList[MyDoc], **kwargs) -> DocList[MyDoc]:\n             assert docs.__class__.doc_type == MyDoc\n@@ -138,7 +138,7 @@ def bar(self, docs: DocList[MyDoc], **kwargs) -> DocList[MyDoc]:\n             return docs\n \n     ports = [random_port() for _ in protocols]\n-    with Flow(port=ports, protocol=protocols, replicas=replicas).add(uses=MyExec):\n+    with Flow(port=ports, protocol=protocols, replicas=replicas).add(uses=MyExecAnnotation):\n         for port, protocol in zip(ports, protocols):\n             c = Client(port=port, protocol=protocol)\n             docs = c.post(\n@@ -148,7 +148,7 @@ def bar(self, docs: DocList[MyDoc], **kwargs) -> DocList[MyDoc]:\n             assert docs.__class__.doc_type == MyDoc\n \n \n-@pytest.mark.parametrize('endpoint', [f'task{i+1}' for i in range(6)])\n+@pytest.mark.parametrize('endpoint', [f'task{i + 1}' for i in range(6)])\n def test_generator_endpoints_type_annotations(endpoint):\n     class InputDocument(BaseDoc):\n         input: str\n@@ -168,13 +168,13 @@ async def task2(self, doc: InputDocument, **kwargs) -> OutputDocument:\n \n         @requests(on='/task3')\n         async def task3(\n-            self, doc: InputDocument, **kwargs\n+                self, doc: InputDocument, **kwargs\n         ) -> Generator[OutputDocument, None, None]:\n             yield OutputDocument(text='hello world')\n \n         @requests(on='/task4')\n         async def task4(\n-            self, doc: InputDocument, **kwargs\n+                self, doc: InputDocument, **kwargs\n         ) -> AsyncGenerator[OutputDocument, None]:\n             yield OutputDocument(text='hello world')\n \n@@ -184,21 +184,21 @@ async def task5(self, doc: InputDocument, **kwargs) -> Iterator[OutputDocument]:\n \n         @requests(on='/task6')\n         async def task6(\n-            self, doc: InputDocument, **kwargs\n+                self, doc: InputDocument, **kwargs\n         ) -> AsyncIterator[OutputDocument]:\n             yield OutputDocument(text='hello world')\n \n     assert (\n-        GeneratorExecutor.requests_by_class['GeneratorExecutor'][\n-            f'/{endpoint}'\n-        ].request_schema\n-        == InputDocument\n+            GeneratorExecutor.requests_by_class['GeneratorExecutor'][\n+                f'/{endpoint}'\n+            ].request_schema\n+            == InputDocument\n     )\n     assert (\n-        GeneratorExecutor.requests_by_class['GeneratorExecutor'][\n-            f'/{endpoint}'\n-        ].response_schema\n-        == OutputDocument\n+            GeneratorExecutor.requests_by_class['GeneratorExecutor'][\n+                f'/{endpoint}'\n+            ].response_schema\n+            == OutputDocument\n     )\n \n \n@@ -212,27 +212,77 @@ class InputDoc(BaseDoc):\n \n     class OutputDoc(BaseDoc):\n         embedding: AnyTensor\n+        t: str\n \n-    class MyExec(Executor):\n+    class MyExecForFlow(Executor):\n         @requests(on='/bar')\n         def bar(self, docs: DocList[InputDoc], **kwargs) -> DocList[OutputDoc]:\n             docs_return = DocList[OutputDoc](\n-                [OutputDoc(embedding=np.zeros((100, 1))) for _ in range(len(docs))]\n+                [OutputDoc(embedding=np.zeros((100, 1)), t='hey') for _ in range(len(docs))]\n             )\n             return docs_return\n \n         @requests(on='/bar_with_dbatch')\n         @dynamic_batching(preferred_batch_size=4)\n         def bar_with_dbatch(\n-            self, docs: DocList[InputDoc], **kwargs\n+                self, docs: DocList[InputDoc], **kwargs\n         ) -> DocList[OutputDoc]:\n             docs_return = DocList[OutputDoc](\n-                [OutputDoc(embedding=np.zeros((100, 1))) for _ in range(len(docs))]\n+                [OutputDoc(embedding=np.zeros((100, 1)), t='hey') for _ in range(len(docs))]\n             )\n             return docs_return\n \n     ports = [random_port() for _ in protocols]\n-    with Flow(port=ports, protocol=protocols, replicas=replicas).add(uses=MyExec):\n+    with Flow(port=ports, protocol=protocols, replicas=replicas).add(uses=MyExecForFlow):\n+        for port, protocol in zip(ports, protocols):\n+            c = Client(port=port, protocol=protocol)\n+            docs = c.post(\n+                on='/bar',\n+                inputs=InputDoc(img=ImageDoc(tensor=np.zeros((3, 224, 224)))),\n+                return_type=DocList[OutputDoc],\n+            )\n+            assert docs[0].embedding.shape == (100, 1)\n+            assert docs.__class__.doc_type == OutputDoc\n+            docs = c.post(\n+                on='/bar_with_dbatch',\n+                inputs=InputDoc(img=ImageDoc(tensor=np.zeros((3, 224, 224)))),\n+                return_type=DocList[OutputDoc],\n+            )\n+            assert docs[0].embedding.shape == (100, 1)\n+            assert docs.__class__.doc_type == OutputDoc\n+\n+\n+@pytest.mark.parametrize(\n+    'protocols', [['grpc'], ['http'], ['grpc', 'http']]\n+)\n+def test_different_output_input_deployment(protocols):\n+    class InputDoc(BaseDoc):\n+        img: ImageDoc\n+\n+    class OutputDoc(BaseDoc):\n+        embedding: AnyTensor\n+        t: str\n+\n+    class MyExecForDepl(Executor):\n+        @requests(on='/bar')\n+        def bar(self, docs: DocList[InputDoc], **kwargs) -> DocList[OutputDoc]:\n+            docs_return = DocList[OutputDoc](\n+                [OutputDoc(embedding=np.zeros((100, 1)), t='hey') for _ in range(len(docs))]\n+            )\n+            return docs_return\n+\n+        @requests(on='/bar_with_dbatch')\n+        @dynamic_batching(preferred_batch_size=4)\n+        def bar_with_dbatch(\n+                self, docs: DocList[InputDoc], **kwargs\n+        ) -> DocList[OutputDoc]:\n+            docs_return = DocList[OutputDoc](\n+                [OutputDoc(embedding=np.zeros((100, 1)), t='hey') for _ in range(len(docs))]\n+            )\n+            return docs_return\n+\n+    ports = [random_port() for _ in protocols]\n+    with Deployment(port=ports, protocol=protocols, uses=MyExecForDepl, include_gateway=False):\n         for port, protocol in zip(ports, protocols):\n             c = Client(port=port, protocol=protocol)\n             docs = c.post(\n@@ -319,20 +369,20 @@ def bar(self, docs: DocList[Output1], **kwargs) -> DocList[Output2]:\n                 assert v['output'] == LegacyDocument.schema()\n                 v = schema_map['/bar']\n                 assert (\n-                    v['input']\n-                    == _create_pydantic_model_from_schema(\n-                        _create_aux_model_doc_list_to_list(Input1).schema(),\n-                        'Input1',\n-                        {},\n-                    ).schema()\n+                        v['input']\n+                        == _create_pydantic_model_from_schema(\n+                    _create_aux_model_doc_list_to_list(Input1).schema(),\n+                    'Input1',\n+                    {},\n+                ).schema()\n                 )\n                 assert (\n-                    v['output']\n-                    == _create_pydantic_model_from_schema(\n-                        _create_aux_model_doc_list_to_list(Output2).schema(),\n-                        'Output2',\n-                        {},\n-                    ).schema()\n+                        v['output']\n+                        == _create_pydantic_model_from_schema(\n+                    _create_aux_model_doc_list_to_list(Output2).schema(),\n+                    'Output2',\n+                    {},\n+                ).schema()\n                 )\n \n \n@@ -370,7 +420,7 @@ def bar(self, docs: DocList[Output1], **kwargs) -> DocList[Output2]:\n \n     ports = [random_port() for _ in protocols]\n     with Flow(port=ports, protocol=protocols).add(uses=Exec1Default).add(\n-        uses=Exec2Default\n+            uses=Exec2Default\n     ):\n         for port, protocol in zip(ports, protocols):\n             c = Client(port=port, protocol=protocol)\n@@ -410,16 +460,16 @@ def bar(self, docs: DocList[Output1], **kwargs) -> DocList[Output2]:\n             assert v['output'] == LegacyDocument.schema()\n             v = schema_map[__default_endpoint__]\n             assert (\n-                v['input']\n-                == _create_pydantic_model_from_schema(\n-                    _create_aux_model_doc_list_to_list(Input1).schema(), 'Input1', {}\n-                ).schema()\n+                    v['input']\n+                    == _create_pydantic_model_from_schema(\n+                _create_aux_model_doc_list_to_list(Input1).schema(), 'Input1', {}\n+            ).schema()\n             )\n             assert (\n-                v['output']\n-                == _create_pydantic_model_from_schema(\n-                    _create_aux_model_doc_list_to_list(Output2).schema(), 'Output2', {}\n-                ).schema()\n+                    v['output']\n+                    == _create_pydantic_model_from_schema(\n+                _create_aux_model_doc_list_to_list(Output2).schema(), 'Output2', {}\n+            ).schema()\n             )\n \n \n@@ -449,14 +499,14 @@ def endpoint(self, docs: DocList[DocTest], **kwargs) -> DocList[DocTest]:\n     ports = [random_port() for _ in protocols]\n     flow = (\n         Flow(protocol=protocols, port=ports)\n-        .add(uses=ExecutorTest, uses_with={'text': 'exec1'}, name='pod0')\n-        .add(\n+            .add(uses=ExecutorTest, uses_with={'text': 'exec1'}, name='pod0')\n+            .add(\n             uses=ExecutorTest, uses_with={'text': 'exec2'}, needs='gateway', name='pod1'\n         )\n-        .add(\n+            .add(\n             uses=ExecutorTest, uses_with={'text': 'exec3'}, needs='gateway', name='pod2'\n         )\n-        .add(\n+            .add(\n             needs=['pod0', 'pod1', 'pod2'],\n             uses=ReduceExecutorTest,\n             no_reduce=not reduce,\n@@ -495,12 +545,12 @@ class ProcessingTestDocConditions(BaseDoc):\n     class ConditionDumpExecutor(Executor):\n         @requests\n         def foo(\n-            self, docs: DocList[ProcessingTestDocConditions], **kwargs\n+                self, docs: DocList[ProcessingTestDocConditions], **kwargs\n         ) -> DocList[ProcessingTestDocConditions]:\n             with open(\n-                os.path.join(str(self.workspace), f'{self.metas.name}.txt'),\n-                'w',\n-                encoding='utf-8',\n+                    os.path.join(str(self.workspace), f'{self.metas.name}.txt'),\n+                    'w',\n+                    encoding='utf-8',\n             ) as fp:\n                 for doc in docs:\n                     fp.write(doc.text)\n@@ -509,7 +559,7 @@ def foo(\n     class FirstExec(Executor):\n         @requests\n         def foo(\n-            self, docs: DocList[LegacyDocument], **kwargs\n+                self, docs: DocList[LegacyDocument], **kwargs\n         ) -> DocList[ProcessingTestDocConditions]:\n             output_da = DocList[ProcessingTestDocConditions](\n                 [\n@@ -522,14 +572,14 @@ def foo(\n     class JoinerExec(Executor):\n         @requests\n         def foo(\n-            self, docs: DocList[ProcessingTestDocConditions], **kwargs\n+                self, docs: DocList[ProcessingTestDocConditions], **kwargs\n         ) -> DocList[ProcessingTestDocConditions]:\n             pass\n \n     f = (\n         Flow(protocol=protocol)\n-        .add(uses=FirstExec, name='first')\n-        .add(\n+            .add(uses=FirstExec, name='first')\n+            .add(\n             uses=ConditionDumpExecutor,\n             uses_metas={'name': 'exec1'},\n             workspace=os.environ['TEMP_WORKSPACE'],\n@@ -537,7 +587,7 @@ def foo(\n             needs=['first'],\n             when={'tags__type': {'$eq': 1}},\n         )\n-        .add(\n+            .add(\n             uses=ConditionDumpExecutor,\n             workspace=os.environ['TEMP_WORKSPACE'],\n             uses_metas={'name': 'exec2'},\n@@ -545,7 +595,7 @@ def foo(\n             needs='first',\n             when={'tags__type': {'$gt': 1}},\n         )\n-        .needs_all('joiner', uses=JoinerExec)\n+            .needs_all('joiner', uses=JoinerExec)\n     )\n \n     with f:\n@@ -569,12 +619,12 @@ def foo(\n         assert types_set == {1, 2}\n \n         with open(\n-            os.path.join(str(tmpdir), 'exec1', '0', f'exec1.txt'), 'r', encoding='utf-8'\n+                os.path.join(str(tmpdir), 'exec1', '0', f'exec1.txt'), 'r', encoding='utf-8'\n         ) as fp:\n             assert fp.read() == 'type1'\n \n         with open(\n-            os.path.join(str(tmpdir), 'exec2', '0', f'exec2.txt'), 'r', encoding='utf-8'\n+                os.path.join(str(tmpdir), 'exec2', '0', f'exec2.txt'), 'r', encoding='utf-8'\n         ) as fp:\n             assert fp.read() == 'type2'\n \n@@ -626,7 +676,7 @@ def __init__(self, file_name, *args, **kwargs):\n \n         @requests\n         def foo(\n-            self, docs: DocList[LegacyDocument], **kwargs\n+                self, docs: DocList[LegacyDocument], **kwargs\n         ) -> DocList[LegacyDocument]:\n             time.sleep(TIME_SLEEP_FLOATING)\n             with open(self.file_name, 'a+', encoding='utf-8') as f:\n@@ -641,8 +691,8 @@ def foo(\n \n     f = (\n         Flow(protocol=protocol)\n-        .add(name='first')\n-        .add(\n+            .add(name='first')\n+            .add(\n             name='second',\n             floating=True,\n             uses=FloatingTestExecutor,\n@@ -658,8 +708,8 @@ def foo(\n             )\n             end_time = time.time()\n             assert (\n-                end_time - start_time\n-            ) < TIME_SLEEP_FLOATING  # check that the response arrives before the\n+                           end_time - start_time\n+                   ) < TIME_SLEEP_FLOATING  # check that the response arrives before the\n             # Floating Executor finishes\n             assert len(ret) == 1\n             assert ret[0].text == ''\n@@ -727,16 +777,16 @@ def test_send_parameters(protocol, ctxt_manager):\n     if ctxt_manager == 'deployment' and protocol == 'websocket':\n         return\n \n-    class Foo(Executor):\n+    class FooSendExecutor(Executor):\n         @requests(on='/hello')\n         def foo(self, docs: DocList[TextDoc], parameters, **kwargs) -> DocList[TextDoc]:\n             for doc in docs:\n                 doc.text += f'Processed by foo with {parameters[\"param\"]}'\n \n     if ctxt_manager == 'flow':\n-        ctxt_mgr = Flow(protocol=protocol).add(uses=Foo)\n+        ctxt_mgr = Flow(protocol=protocol).add(uses=FooSendExecutor)\n     else:\n-        ctxt_mgr = Deployment(protocol=protocol, uses=Foo)\n+        ctxt_mgr = Deployment(protocol=protocol, uses=FooSendExecutor)\n \n     with ctxt_mgr:\n         ret = ctxt_mgr.post(\n@@ -754,15 +804,15 @@ def test_get_parameters_back(protocol, ctxt_manager):\n     if ctxt_manager == 'deployment' and protocol == 'websocket':\n         return\n \n-    class Foo(Executor):\n+    class FooParams(Executor):\n         @requests(on='/hello')\n         def foo(self, parameters, **kwargs):\n             return {'back': parameters}\n \n     if ctxt_manager == 'flow':\n-        ctxt_mgr = Flow(protocol=protocol).add(uses=Foo, name='foo')\n+        ctxt_mgr = Flow(protocol=protocol).add(uses=FooParams, name='foo')\n     else:\n-        ctxt_mgr = Deployment(protocol=protocol, uses=Foo, name='foo')\n+        ctxt_mgr = Deployment(protocol=protocol, uses=FooParams, name='foo')\n \n     with ctxt_mgr:\n         ret = ctxt_mgr.post(\n@@ -783,15 +833,15 @@ def test_raise_exception(protocol, ctxt_manager):\n     if ctxt_manager == 'deployment' and protocol == 'websocket':\n         return\n \n-    class Foo(Executor):\n+    class FooExcep(Executor):\n         @requests(on='/hello')\n         def foo(self, **kwargs):\n             raise Exception('Raising some exception from Executor')\n \n     if ctxt_manager == 'flow':\n-        ctxt_mgr = Flow(protocol=protocol).add(uses=Foo, name='foo')\n+        ctxt_mgr = Flow(protocol=protocol).add(uses=FooExcep, name='foo')\n     else:\n-        ctxt_mgr = Deployment(protocol=protocol, uses=Foo, name='foo')\n+        ctxt_mgr = Deployment(protocol=protocol, uses=FooExcep, name='foo')\n \n     with ctxt_mgr:\n         if protocol == 'http':\n@@ -850,10 +900,10 @@ async def get_endpoint_stream_docs(text: str):\n                     ]\n                 )\n                 async for resp in self.streamer.stream_docs(\n-                    docs,\n-                    parameters=PARAMETERS,\n-                    target_executor='executor1',\n-                    return_type=DocList[TextDoc],\n+                        docs,\n+                        parameters=PARAMETERS,\n+                        target_executor='executor1',\n+                        return_type=DocList[TextDoc],\n                 ):\n                     assert resp.doc_type is TextDoc\n                     return {'result': [doc.text for doc in resp]}\n@@ -867,10 +917,10 @@ async def get_endpoint_stream(text: str):\n                     ]\n                 )\n                 async for resp, _ in self.streamer.stream(\n-                    docs,\n-                    parameters=PARAMETERS,\n-                    target_executor='executor1',\n-                    return_type=DocList[TextDoc],\n+                        docs,\n+                        parameters=PARAMETERS,\n+                        target_executor='executor1',\n+                        return_type=DocList[TextDoc],\n                 ):\n                     assert resp.doc_type is TextDoc\n                     return {'result': [doc.text for doc in resp]}\n@@ -886,13 +936,13 @@ def func(self, docs: DocList[TextDoc], **kwargs) -> DocList[TextDoc]:\n     class SecondExec(Executor):\n         @requests\n         def func(\n-            self, docs: DocList[TextDoc], parameters, **kwargs\n+                self, docs: DocList[TextDoc], parameters, **kwargs\n         ) -> DocList[TextDoc]:\n             for doc in docs:\n                 doc.text += f' Second(parameters={str(parameters)})'\n \n     with Flow().config_gateway(uses=MyGateway, protocol='http').add(\n-        uses=FirstExec, name='executor0'\n+            uses=FirstExec, name='executor0'\n     ).add(uses=SecondExec, name='executor1') as flow:\n         import requests\n \n@@ -921,16 +971,16 @@ def test_any_endpoint(protocol, ctxt_manager):\n     if ctxt_manager == 'deployment' and protocol == 'websocket':\n         return\n \n-    class Foo(Executor):\n+    class FooAny(Executor):\n         @requests\n         def foo(self, docs: DocList[TextDoc], parameters, **kwargs) -> DocList[TextDoc]:\n             for doc in docs:\n                 doc.text = 'Foo'\n \n     if ctxt_manager == 'flow':\n-        ctxt_mgr = Flow(protocol=protocol).add(uses=Foo, name='foo')\n+        ctxt_mgr = Flow(protocol=protocol).add(uses=FooAny, name='foo')\n     else:\n-        ctxt_mgr = Deployment(protocol=protocol, uses=Foo, name='foo')\n+        ctxt_mgr = Deployment(protocol=protocol, uses=FooAny, name='foo')\n \n     with ctxt_mgr:\n         ret = ctxt_mgr.post(on='/index', inputs=DocList[TextDoc]([TextDoc(text='')]))\n@@ -1046,10 +1096,10 @@ def foo(self, docs: DocList[TextDoc], **kwargs) -> DocList[TextDoc]:\n \n     f = (\n         Flow(protocol=protocol)\n-        .add(uses=Previous, name='previous')\n-        .add(uses=First, name='first', needs='previous')\n-        .add(uses=Second, name='second', needs='previous')\n-        .needs_all()\n+            .add(uses=Previous, name='previous')\n+            .add(uses=First, name='first', needs='previous')\n+            .add(uses=Second, name='second', needs='previous')\n+            .needs_all()\n     )\n \n     with pytest.raises(RuntimeFailToStart):\n@@ -1119,7 +1169,7 @@ def foo(self, docs, *args, **kwargs):\n @pytest.mark.parametrize('num_shards', [1, 2], indirect=True)\n @pytest.mark.parametrize('protocol', ['grpc', 'http', 'websocket'])\n def test_flow_with_external_deployment(\n-    external_deployment, external_deployment_args, input_docs, num_shards, protocol\n+        external_deployment, external_deployment_args, input_docs, num_shards, protocol\n ):\n     with external_deployment:\n         external_args = vars(external_deployment_args)\n@@ -1149,7 +1199,7 @@ class InputDoc(BaseDoc):\n     class OutputDoc(BaseDoc):\n         embedding: AnyTensor\n \n-    class MyExec(Executor):\n+    class MyExecD(Executor):\n         @requests(on='/bar')\n         def bar(self, docs: DocList[InputDoc], **kwargs) -> DocList[OutputDoc]:\n             docs_return = DocList[OutputDoc](\n@@ -1158,7 +1208,7 @@ def bar(self, docs: DocList[InputDoc], **kwargs) -> DocList[OutputDoc]:\n             return docs_return\n \n     ports = [random_port() for _ in protocols]\n-    with Deployment(port=ports, protocol=protocols, replicas=replicas, uses=MyExec):\n+    with Deployment(port=ports, protocol=protocols, replicas=replicas, uses=MyExecD):\n         for port, protocol in zip(ports, protocols):\n             c = Client(port=port, protocol=protocol)\n             docs = c.post(\n@@ -1191,7 +1241,7 @@ class OutputComplexDoc(BaseDoc):\n     class MyComplexServeExec(Executor):\n         @requests(on='/bar')\n         def bar(\n-            self, docs: DocList[InputComplexDoc], **kwargs\n+                self, docs: DocList[InputComplexDoc], **kwargs\n         ) -> DocList[OutputComplexDoc]:\n             docs_return = DocList[OutputComplexDoc](\n                 [\n@@ -1261,14 +1311,14 @@ def __init__(self, *args, **kwargs):\n \n         @requests(on=['/index'])\n         def index(\n-            self, docs: DocList[TextDocWithId], **kwargs\n+                self, docs: DocList[TextDocWithId], **kwargs\n         ) -> DocList[TextDocWithId]:\n             for doc in docs:\n                 self._docs_dict[doc.id] = doc\n \n         @requests(on=['/search'])\n         def search(\n-            self, docs: DocList[TextDocWithId], **kwargs\n+                self, docs: DocList[TextDocWithId], **kwargs\n         ) -> DocList[TextDocWithId]:\n             for doc in docs:\n                 doc.text = self._docs_dict[doc.id].text\n@@ -1312,14 +1362,14 @@ def __init__(self, sleep_time=0.1, *args, **kwargs):\n \n         @requests(on=['/index'])\n         def index(\n-            self, docs: DocList[TextDocWithId], **kwargs\n+                self, docs: DocList[TextDocWithId], **kwargs\n         ) -> DocList[TextDocWithId]:\n             for doc in docs:\n                 self._docs.append(doc)\n \n         @requests(on=['/search'])\n         def search(\n-            self, docs: DocList[TextDocWithId], **kwargs\n+                self, docs: DocList[TextDocWithId], **kwargs\n         ) -> DocList[ResultTestDoc]:\n             resp = DocList[ResultTestDoc]()\n             for q in docs:\n@@ -1328,10 +1378,10 @@ def search(\n             return resp\n \n     with Deployment(\n-        uses=SimilarityTestIndexer,\n-        uses_with={'sleep_time': sleep_time},\n-        shards=2,\n-        reduce=reduce,\n+            uses=SimilarityTestIndexer,\n+            uses_with={'sleep_time': sleep_time},\n+            shards=2,\n+            reduce=reduce,\n     ) as dep:\n         index_da = DocList[TextDocWithId](\n             [TextDocWithId(id=f'{i}', text=f'ID {i}') for i in range(10)]\n@@ -1378,14 +1428,14 @@ def __init__(self, sleep_time=0.1, *args, **kwargs):\n \n         @requests(on=['/index'])\n         def index(\n-            self, docs: DocList[TextDocWithId], **kwargs\n+                self, docs: DocList[TextDocWithId], **kwargs\n         ) -> DocList[TextDocWithId]:\n             for doc in docs:\n                 self._docs.append(doc)\n \n         @requests(on=['/search'])\n         def search(\n-            self, docs: DocList[TextDocWithId], **kwargs\n+                self, docs: DocList[TextDocWithId], **kwargs\n         ) -> DocList[ResultTestDoc]:\n             resp = DocList[ResultTestDoc]()\n             for q in docs:\n@@ -1395,10 +1445,10 @@ def search(\n \n     ports = [random_port() for _ in protocols]\n     with Flow(protocol=protocols, port=ports).add(\n-        uses=SimilarityTestIndexer,\n-        uses_with={'sleep_time': sleep_time},\n-        shards=2,\n-        reduce=reduce,\n+            uses=SimilarityTestIndexer,\n+            uses_with={'sleep_time': sleep_time},\n+            shards=2,\n+            reduce=reduce,\n     ):\n         for port, protocol in zip(ports, protocols):\n             c = Client(port=port, protocol=protocol)\n@@ -1426,10 +1476,10 @@ class MyDocWithMatchesAndScores(MyDoc):\n         matches: DocList[MyDoc]\n         scores: List[float]\n \n-    class MyExec(Executor):\n+    class MyExecIssueShards(Executor):\n         @requests(on='/search')\n         def foo(\n-            self, docs: DocList[MyDoc], **kwargs\n+                self, docs: DocList[MyDoc], **kwargs\n         ) -> DocList[MyDocWithMatchesAndScores]:\n             res = DocList[MyDocWithMatchesAndScores]()\n             for doc in docs:\n@@ -1443,7 +1493,7 @@ def foo(\n                 res.append(new_doc)\n             return res\n \n-    d = Deployment(uses=MyExec, shards=2)\n+    d = Deployment(uses=MyExecIssueShards, shards=2)\n     with d:\n         res = d.post(\n             on='/search',\n@@ -1521,7 +1571,7 @@ class OutputDocMonitor(BaseDoc):\n     class MonitorExecTest(Executor):\n         @requests\n         def foo(\n-            self, docs: DocList[InputDocMonitor], **kwargs\n+                self, docs: DocList[InputDocMonitor], **kwargs\n         ) -> DocList[OutputDocMonitor]:\n             ret = DocList[OutputDocMonitor]()\n             for doc in docs:\n@@ -1563,7 +1613,7 @@ class Config:\n     class MyExecDocWithExample(Executor):\n         @requests\n         def foo(\n-            self, docs: DocList[MyDocWithExample], **kwargs\n+                self, docs: DocList[MyDocWithExample], **kwargs\n         ) -> DocList[MyDocWithExample]:\n             pass\n \n@@ -1601,7 +1651,7 @@ class MyInputModel(BaseDoc):\n     class MyFailingExecutor(Executor):\n         @requests(on='/generate')\n         def generate(\n-            self, docs: DocList[MyInputModel], **kwargs\n+                self, docs: DocList[MyInputModel], **kwargs\n         ) -> DocList[MyRandomModel]:\n             return DocList[MyRandomModel]([doc.b for doc in docs])\n \n"},"summary":"## Summary of Merge Request\n\nДанный merge request направлен на оптимизацию обработки HTTP запросов в системе. Основные изменения включают добавление параметра `http` в функцию `push` в `batch_queue.py` и его передачу в `request_handling.py`, а также изменения в тестах, связанные с использованием новых функций. Общая сложность изменений оценена как средняя. Код хорошо отформатирован и соответствует стандартам, однако рекомендуется улучшить именование классов в тестах для повышения читаемости. Анти-паттерны не обнаружены, а изменения в целом направлены на улучшение производительности.\n","antiPatterns":{"detailed_analysis":"Внесенные изменения затрагивают несколько файлов, в основном добавляя новые тесты и незначительно изменяя существующий код. В `jina/serve/runtimes/worker/batch_queue.py` добавлена опция `http` в метод `push` и `_await_then_flush`, что может быть оптимизацией для HTTP запросов. В тестах происходит переименование классов и добавление новых тестов, что не вносит анти-паттернов. Общее качество кода не ухудшилось.","recommendations":[],"confidence":"High","score":9,"summary":"Изменения в основном касаются добавления тестов и незначительных изменений в существующем коде, анти-паттерны не обнаружены."},"complexity":{"justification":"Данный diff содержит изменения в нескольких файлах, затрагивая логику обработки запросов в batch_queue.py и request_handling.py, а также изменения в тестах. Объем изменений умеренный. В batch_queue.py добавлена опция http для оптимизации, что указывает на изменение логики обработки запросов. В request_handling.py изменена логика вызова push. В тестах происходит изменение названий классов и добавление новых тестов, что указывает на расширение функциональности. Эти изменения требуют понимания взаимодействия между компонентами и могут потребовать тщательного анализа, но не являются критическими или архитектурными. Риски умеренные. Сложность классифицируется как средняя (Medium).","classification":"Medium"},"designPatterns":{"detailed_analysis":"Внесенные изменения добавляют параметр `http` в функцию `push` класса `BatchQueue` и передают его в функцию `_await_then_flush`. Это сделано для оптимизации обработки запросов, поступающих через HTTP.  В коде также изменяется логика обработки результатов в зависимости от значения параметра `http`.  В целом, изменения направлены на оптимизацию работы с HTTP запросами, что не является анти-паттерном, а скорее улучшением.  Однако, изменения затрагивают логику работы с данными, что требует внимательного анализа и тестирования, чтобы избежать потенциальных проблем.  В коде тестов происходит замена названий классов, что не является анти-паттерном.","recommendations":[],"confidence":"Medium","score":7,"summary":"Изменения вносят улучшения в обработку HTTP запросов, но требуют тщательного тестирования. Анти-паттерны не обнаружены."},"codeStyle":{"detailed_analysis":"Изменения включают в себя добавление параметра `http` в функцию `push` в `batch_queue.py` и его передачу в `handle` в `request_handling.py`. Также были внесены изменения в тесты, связанные с использованием новых функций и классов. \n\n**Форматирование:** В целом, форматирование кода соответствует стандартам. Отступы и пробелы соблюдены. \n\n**Именование:** Имена переменных и функций, в основном, понятны и соответствуют их назначению. Однако, в некоторых случаях, имена классов в тестах (`MyExecDifSchema`, `MyExecCustomDoc`, `MyExecRespSchema`, `MyExecAnnotation`, `MyExecForFlow`, `MyExecForDepl`, `FooSendExecutor`, `FooParams`, `FooExcep`, `FooAny`, `MyExecD`, `MyExecIssueShards`) могли бы быть более описательными, чтобы лучше отражать их функциональность.\n\n**Консистентность:** Изменения в основном консистентны с существующим кодом. \n\n**Читаемость:** Код легко читается и понимается. Добавлены комментарии для пояснения изменений, что улучшает читаемость. \n\n**Соответствие гайдлайнам:** Код соответствует PEP 8 и другим стандартам, принятым в проекте. \n\nВ целом, изменения хорошо оформлены и соответствуют стандартам кодирования.","recommendations":["Переименовать классы в тестах, чтобы их имена были более описательными и отражали их функциональность (например, `MyExecDifSchema` -> `MyExecutorWithDifferentSchema`)."],"confidence":"High","score":8,"summary":"Внесены изменения в `batch_queue.py` и `request_handling.py`, а также в тесты. Код хорошо отформатирован, читаемый и соответствует стандартам. Рекомендовано улучшить именование классов в тестах."}},{"pull":{"id":6183,"html_url":"https://github.com/jina-ai/serve/pull/6183","title":"fix: small optimization in HTTP server and client","body":"Goals:\n\n\n\nresolves #ISSUE-NUMBER\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n check and update documentation. See guide and ask the team.","is_merged":true,"diff":"diff --git a/jina/clients/base/http.py b/jina/clients/base/http.py\nindex 653a98f051629..c55156bf69365 100644\n--- a/jina/clients/base/http.py\n+++ b/jina/clients/base/http.py\n@@ -219,7 +219,7 @@ def _result_handler(result):\n \n                 resp = DataRequest(r_str)\n                 if da is not None:\n-                    resp.data.docs = da\n+                    resp.direct_docs = da\n \n                 callback_exec(\n                     response=resp,\ndiff --git a/jina/clients/mixin.py b/jina/clients/mixin.py\nindex ec0c52049d200..a6960fa355f63 100644\n--- a/jina/clients/mixin.py\n+++ b/jina/clients/mixin.py\n@@ -414,7 +414,7 @@ async def _get_results(*args, **kwargs):\n                     if return_responses:\n                         result.append(resp)\n                     else:\n-                        result.extend(resp.data.docs)\n+                        result.extend(resp.docs)\n             if return_results:\n                 if not return_responses and is_singleton and len(result) == 1:\n                     return result[0]\n@@ -438,6 +438,7 @@ async def _get_results(*args, **kwargs):\n             results_in_order=results_in_order,\n             stream=stream,\n             prefetch=prefetch,\n+            return_type=return_type,\n             on=on,\n             **kwargs,\n         )\n@@ -507,7 +508,6 @@ async def post(\n         c.continue_on_error = continue_on_error\n \n         parameters = _include_results_field_in_param(parameters)\n-\n         async for result in c._get_results(\n             on=on,\n             inputs=inputs,\n@@ -538,7 +538,7 @@ async def post(\n                     is_singleton = True\n                     result.document_array_cls = DocList[return_type]\n             if not return_responses:\n-                ret_docs = result.data.docs\n+                ret_docs = result.docs\n                 if is_singleton and len(ret_docs) == 1:\n                     yield ret_docs[0]\n                 else:\ndiff --git a/jina/serve/runtimes/worker/http_fastapi_app.py b/jina/serve/runtimes/worker/http_fastapi_app.py\nindex b45b94f7c62cf..889166d8aeb63 100644\n--- a/jina/serve/runtimes/worker/http_fastapi_app.py\n+++ b/jina/serve/runtimes/worker/http_fastapi_app.py\n@@ -99,16 +99,16 @@ async def post(body: input_model, response: Response):\n             data = body.data\n             if isinstance(data, list):\n                 if not docarray_v2:\n-                    req.data.docs = DocumentArray.from_pydantic_model(data)\n+                    req.direct_docs = DocumentArray.from_pydantic_model(data)\n                 else:\n                     req.document_array_cls = DocList[input_doc_model]\n-                    req.data.docs = DocList[input_doc_list_model](data)\n+                    req.direct_docs = DocList[input_doc_list_model](data)\n             else:\n                 if not docarray_v2:\n-                    req.data.docs = DocumentArray([Document.from_pydantic_model(data)])\n+                    req.direct_docs = DocumentArray([Document.from_pydantic_model(data)])\n                 else:\n                     req.document_array_cls = DocList[input_doc_model]\n-                    req.data.docs = DocList[input_doc_list_model]([data])\n+                    req.direct_docs = DocList[input_doc_list_model]([data])\n                 if body.header is None:\n                     req.header.request_id = req.docs[0].id\n \n@@ -122,7 +122,6 @@ async def post(body: input_model, response: Response):\n                     docs_response = resp.docs.to_dict()\n                 else:\n                     docs_response = resp.docs\n-\n                 ret = output_model(data=docs_response, parameters=resp.parameters)\n \n                 return ret\n@@ -152,10 +151,10 @@ async def streaming_get(request: Request = None, body: input_doc_model = None):\n             req = DataRequest()\n             req.header.exec_endpoint = endpoint_path\n             if not docarray_v2:\n-                req.data.docs = DocumentArray([body])\n+                req.direct_docs = DocumentArray([body])\n             else:\n                 req.document_array_cls = DocList[input_doc_model]\n-                req.data.docs = DocList[input_doc_model]([body])\n+                req.direct_docs = DocList[input_doc_model]([body])\n             event_generator = _gen_dict_documents(await caller(req))\n             return EventSourceResponse(event_generator)\n \ndiff --git a/jina/serve/runtimes/worker/request_handling.py b/jina/serve/runtimes/worker/request_handling.py\nindex af3786f2886d3..7d9958c35c049 100644\n--- a/jina/serve/runtimes/worker/request_handling.py\n+++ b/jina/serve/runtimes/worker/request_handling.py\n@@ -177,7 +177,7 @@ def call_handle(request):\n                 'is_generator'\n             ]\n \n-            return self.process_single_data(request, None, is_generator=is_generator)\n+            return self.process_single_data(request, None, http=True, is_generator=is_generator)\n \n         app = get_fastapi_app(\n             request_models_map=request_models_map, caller=call_handle, **kwargs\n@@ -201,7 +201,7 @@ def call_handle(request):\n                 'is_generator'\n             ]\n \n-            return self.process_single_data(request, None, is_generator=is_generator)\n+            return self.process_single_data(request, None, http=True, is_generator=is_generator)\n \n         app = get_fastapi_app(\n             request_models_map=request_models_map, caller=call_handle, **kwargs\n@@ -548,7 +548,7 @@ def _record_response_size_monitoring(self, requests):\n                 requests[0].nbytes, attributes=attributes\n             )\n \n-    def _set_result(self, requests, return_data, docs):\n+    def _set_result(self, requests, return_data, docs, http=False):\n         # assigning result back to request\n         if return_data is not None:\n             if isinstance(return_data, DocumentArray):\n@@ -568,10 +568,12 @@ def _set_result(self, requests, return_data, docs):\n                     f'The return type must be DocList / Dict / `None`, '\n                     f'but getting {return_data!r}'\n                 )\n-\n-        WorkerRequestHandler.replace_docs(\n-            requests[0], docs, self.args.output_array_type\n-        )\n+        if not http:\n+            WorkerRequestHandler.replace_docs(\n+                requests[0], docs, self.args.output_array_type\n+            )\n+        else:\n+            requests[0].direct_docs = docs\n         return docs\n \n     def _setup_req_doc_array_cls(self, requests, exec_endpoint, is_response=False):\n@@ -659,11 +661,12 @@ async def handle_generator(\n         )\n \n     async def handle(\n-        self, requests: List['DataRequest'], tracing_context: Optional['Context'] = None\n+        self, requests: List['DataRequest'], http=False, tracing_context: Optional['Context'] = None\n     ) -> DataRequest:\n         \"\"\"Initialize private parameters and execute private loading functions.\n \n         :param requests: The messages to handle containing a DataRequest\n+        :param http: Flag indicating if it is used by the HTTP server for some optims\n         :param tracing_context: Optional OpenTelemetry tracing context from the originating request.\n         :returns: the processed message\n         \"\"\"\n@@ -721,7 +724,7 @@ async def handle(\n                 docs_map=docs_map,\n                 tracing_context=tracing_context,\n             )\n-            _ = self._set_result(requests, return_data, docs)\n+            _ = self._set_result(requests, return_data, docs, http=http)\n \n         for req in requests:\n             req.add_executor(self.deployment_name)\n@@ -909,18 +912,19 @@ def reduce_requests(requests: List['DataRequest']) -> 'DataRequest':\n \n     # serving part\n     async def process_single_data(\n-        self, request: DataRequest, context, is_generator: bool = False\n+        self, request: DataRequest, context, http: bool = False, is_generator: bool = False\n     ) -> DataRequest:\n         \"\"\"\n         Process the received requests and return the result as a new request\n \n         :param request: the data request to process\n         :param context: grpc context\n+        :param http: Flag indicating if it is used by the HTTP server for some optims\n         :param is_generator: whether the request should be handled with streaming\n         :returns: the response request\n         \"\"\"\n         self.logger.debug('recv a process_single_data request')\n-        return await self.process_data([request], context, is_generator=is_generator)\n+        return await self.process_data([request], context, http=http, is_generator=is_generator)\n \n     async def stream_doc(\n         self, request: SingleDocumentRequest, context: 'grpc.aio.ServicerContext'\n@@ -1065,13 +1069,14 @@ def _extract_tracing_context(\n         return None\n \n     async def process_data(\n-        self, requests: List[DataRequest], context, is_generator: bool = False\n+        self, requests: List[DataRequest], context, http=False, is_generator: bool = False\n     ) -> DataRequest:\n         \"\"\"\n         Process the received requests and return the result as a new request\n \n         :param requests: the data requests to process\n         :param context: grpc context\n+        :param http: Flag indicating if it is used by the HTTP server for some optims\n         :param is_generator: whether the request should be handled with streaming\n         :returns: the response request\n         \"\"\"\n@@ -1094,11 +1099,11 @@ async def process_data(\n \n                 if is_generator:\n                     result = await self.handle_generator(\n-                        requests=requests, tracing_context=tracing_context\n+                        requests=requests,tracing_context=tracing_context\n                     )\n                 else:\n                     result = await self.handle(\n-                        requests=requests, tracing_context=tracing_context\n+                        requests=requests, http=http, tracing_context=tracing_context\n                     )\n \n                 if self._successful_requests_metrics:\ndiff --git a/jina/types/request/data.py b/jina/types/request/data.py\nindex c3fd12822e8c1..9c936833f376f 100644\n--- a/jina/types/request/data.py\n+++ b/jina/types/request/data.py\n@@ -114,6 +114,8 @@ def __init__(\n         self._pb_body = None\n         self._document_array_cls = DocumentArray\n         self._data = None\n+        # to be used to bypass proto extra transforms\n+        self.direct_docs = None\n \n         try:\n             if isinstance(request, jina_pb2.DataRequestProto):\n@@ -275,7 +277,10 @@ def docs(self) -> 'DocumentArray':\n         \"\"\"Get the :class: `DocumentArray` with sequence `data.docs` as content.\n \n         .. # noqa: DAR201\"\"\"\n-        return self.data.docs\n+        if self.direct_docs is not None:\n+            return self.direct_docs\n+        else:\n+            return self.data.docs\n \n     @property\n     def data(self) -> 'DataRequest._DataContent':\n@@ -441,6 +446,8 @@ def __init__(\n         self._document_cls = Document\n         self.buffer = None\n         self._data = None\n+        # to be used to bypass proto extra transforms\n+        self.direct_doc = None\n \n         try:\n             if isinstance(request, jina_pb2.SingleDocumentRequestProto):\n@@ -606,7 +613,10 @@ def doc(self) -> 'Document':\n         \"\"\"Get the :class: `DocumentArray` with sequence `data.docs` as content.\n \n         .. # noqa: DAR201\"\"\"\n-        return self.data.doc\n+        if self.direct_doc is not None:\n+            return self.direct_doc\n+        else:\n+            return self.data.doc\n \n     @property\n     def data(self) -> 'SingleDocumentRequest._DataContent':\ndiff --git a/tests/integration/dynamic_batching/test_dynamic_batching.py b/tests/integration/dynamic_batching/test_dynamic_batching.py\nindex 355e771c52fc7..0a9bf57847e8c 100644\n--- a/tests/integration/dynamic_batching/test_dynamic_batching.py\n+++ b/tests/integration/dynamic_batching/test_dynamic_batching.py\n@@ -528,7 +528,7 @@ def _assert_all_docs_processed(port, num_docs, endpoint):\n         target=f'0.0.0.0:{port}',\n         endpoint=endpoint,\n     )\n-    docs = resp.data.docs\n+    docs = resp.docs\n     assert docs.texts == ['long timeout' for _ in range(num_docs)]\n \n \ndiff --git a/tests/integration/inspect_deployments_flow/test_inspect_deployments_flow.py b/tests/integration/inspect_deployments_flow/test_inspect_deployments_flow.py\nindex 84d6443a7a5c7..d1e422b1f9a8d 100644\n--- a/tests/integration/inspect_deployments_flow/test_inspect_deployments_flow.py\n+++ b/tests/integration/inspect_deployments_flow/test_inspect_deployments_flow.py\n@@ -145,7 +145,7 @@ def test_flow_returned_collect(protocol, port_generator):\n     def validate_func(resp):\n         num_evaluations = 0\n         scores = set()\n-        for doc in resp.data.docs:\n+        for doc in resp.docs:\n             num_evaluations += len(doc.evaluations)\n             scores.add(doc.evaluations['evaluate'].value)\n         assert num_evaluations == 1\ndiff --git a/tests/unit/serve/dynamic_batching/test_batch_queue.py b/tests/unit/serve/dynamic_batching/test_batch_queue.py\nindex 2d0a172ca5a27..bb922ed60d970 100644\n--- a/tests/unit/serve/dynamic_batching/test_batch_queue.py\n+++ b/tests/unit/serve/dynamic_batching/test_batch_queue.py\n@@ -27,7 +27,7 @@ async def foo(docs, **kwargs):\n     three_data_requests = [DataRequest() for _ in range(3)]\n     for req in three_data_requests:\n         req.data.docs = DocumentArray.empty(1)\n-        assert req.data.docs[0].text == ''\n+        assert req.docs[0].text == ''\n \n     async def process_request(req):\n         q = await bq.push(req)\n@@ -42,12 +42,12 @@ async def process_request(req):\n     assert time_spent >= 2000\n     # Test that since no more docs arrived, the function was triggerred after timeout\n     for resp in responses:\n-        assert resp.data.docs[0].text == 'Done'\n+        assert resp.docs[0].text == 'Done'\n \n     four_data_requests = [DataRequest() for _ in range(4)]\n     for req in four_data_requests:\n         req.data.docs = DocumentArray.empty(1)\n-        assert req.data.docs[0].text == ''\n+        assert req.docs[0].text == ''\n     init_time = time.time()\n     tasks = [asyncio.create_task(process_request(req)) for req in four_data_requests]\n     responses = await asyncio.gather(*tasks)\n@@ -55,7 +55,7 @@ async def process_request(req):\n     assert time_spent < 2000\n     # Test that since no more docs arrived, the function was triggerred after timeout\n     for resp in responses:\n-        assert resp.data.docs[0].text == 'Done'\n+        assert resp.docs[0].text == 'Done'\n \n     await bq.close()\n \n@@ -135,7 +135,7 @@ async def foo(docs, **kwargs):\n     data_requests = [DataRequest() for _ in range(3)]\n     for req in data_requests:\n         req.data.docs = DocumentArray.empty(10)  # 30 docs in total\n-        assert req.data.docs[0].text == ''\n+        assert req.docs[0].text == ''\n \n     async def process_request(req):\n         q = await bq.push(req)\n@@ -150,7 +150,7 @@ async def process_request(req):\n     assert time_spent < 2000\n     # Test that since no more docs arrived, the function was triggerred after timeout\n     for resp in responses:\n-        assert resp.data.docs[0].text == 'Done'\n+        assert resp.docs[0].text == 'Done'\n \n     await bq.close()\n \n@@ -196,9 +196,9 @@ async def process_request(req):\n             assert isinstance(item, Exception)\n     for i, req in enumerate(data_requests):\n         if i not in BAD_REQUEST_IDX:\n-            assert req.data.docs[0].text == f'{i} Processed'\n+            assert req.docs[0].text == f'{i} Processed'\n         else:\n-            assert req.data.docs[0].text == 'Bad'\n+            assert req.docs[0].text == 'Bad'\n \n \n @pytest.mark.asyncio\n@@ -246,11 +246,11 @@ async def process_request(req):\n             assert isinstance(item, Exception)\n     for i, req in enumerate(data_requests):\n         if i not in EXPECTED_BAD_REQUESTS:\n-            assert req.data.docs[0].text == 'Processed'\n+            assert req.docs[0].text == 'Processed'\n         elif i in TRIGGER_BAD_REQUEST_IDX:\n-            assert req.data.docs[0].text == 'Bad'\n+            assert req.docs[0].text == 'Bad'\n         else:\n-            assert req.data.docs[0].text == ''\n+            assert req.docs[0].text == ''\n \n \n @pytest.mark.asyncio\n"},"summary":"## Summary of Merge Request\n\nДанный MR направлен на оптимизацию обработки данных в HTTP-запросах. Основные изменения включают замену `resp.data.docs` на `resp.direct_docs` и `req.data.docs` на `req.direct_docs` в нескольких файлах, а также добавление параметра `http` в функции обработки данных. Экспертная оценка указывает на низкую сложность изменений и соответствие стандартам кодирования, с оценкой 8 по Code Style и 9 по Design Patterns. В целом, изменения улучшают доступ к данным и не вводят анти-паттернов, однако рекомендуется провести тщательное тестирование, чтобы убедиться в отсутствии регрессий и корректности изменений в контексте HTTP-запросов.\n","antiPatterns":{"detailed_analysis":"Внесенные изменения затрагивают несколько мест в коде, где происходит работа с `DocumentArray` и `DataRequest`. Основные изменения заключаются в замене `resp.data.docs` на `resp.docs` и `req.data.docs` на `req.direct_docs`. Это, вероятно, сделано для оптимизации доступа к документам и обхода лишних преобразований. В целом, эти изменения не вводят новых анти-паттернов и, возможно, улучшают производительность. Однако, необходимо убедиться, что все места, где использовались `resp.data.docs` и `req.data.docs`, были корректно заменены, и что это не привело к регрессии в других частях системы. Также, в `jina/serve/runtimes/worker/request_handling.py` добавлены параметры `http=True` в вызовах `process_single_data` и `process_data`, что может указывать на оптимизации для HTTP-сервера. Это выглядит как хорошее улучшение, но требует дополнительной проверки, чтобы убедиться, что эти изменения не влияют на другие типы запросов или обработку данных. ","recommendations":["Провести тщательное тестирование всех затронутых участков кода, чтобы убедиться в отсутствии регрессий.","Убедиться, что изменения в `jina/serve/runtimes/worker/request_handling.py` не влияют на обработку других типов запросов, кроме HTTP.","Проверить документацию и комментарии, чтобы убедиться, что изменения отражены корректно."],"confidence":"High","score":8,"summary":"Внесенные изменения в основном касаются замены `data.docs` на `docs` и `direct_docs`, что потенциально улучшает производительность. Анти-паттерны не обнаружены, но требуется тщательное тестирование."},"complexity":{"justification":"Данный MR содержит небольшие изменения, затрагивающие несколько файлов. Основные изменения включают замену `resp.data.docs` на `resp.direct_docs` в нескольких местах, а также добавление параметра `http` в функцию `process_single_data`. Эти изменения направлены на оптимизацию работы с данными в HTTP-запросах. Объем изменений небольшой, логика проста и понятна. Риски минимальны, так как изменения локальны и не затрагивают критические компоненты системы. Когнитивная нагрузка низкая.  Примеры из определения сложности (Low): исправление опечаток, обновление документации, простые изменения конфигурации. Данный MR соответствует этим характеристикам.","classification":"Low"},"designPatterns":{"detailed_analysis":"Внесенные изменения в основном касаются замены `resp.data.docs` на `resp.docs` и `req.data.docs` на `req.direct_docs` в различных файлах. Это улучшает читаемость и, возможно, производительность, упрощая доступ к документам.  В некоторых местах также добавлены параметры `http=True` для оптимизации работы с HTTP-запросами.  Эти изменения не вводят новых анти-паттернов и, вероятно, улучшают кодовую базу, упрощая доступ к данным и повышая производительность. ","recommendations":[],"confidence":"High","score":9,"summary":"Изменения в основном направлены на улучшение доступа к данным и оптимизацию работы с HTTP-запросами, не вводя анти-паттернов."},"codeStyle":{"detailed_analysis":"Изменения в основном касаются замены `req.data.docs` на `req.direct_docs` в нескольких файлах, а также добавления параметра `http` в функцию `process_data` и его использования. Это указывает на оптимизацию для работы с HTTP-запросами, вероятно, для повышения производительности или улучшения обработки данных.  \n\n**Форматирование:** В целом, форматирование сохраняется, изменения минимальны и не влияют на общую читаемость.  \n\n**Именование:** Имена переменных и функций остаются понятными и соответствуют общепринятым соглашениям.  \n\n**Консистентность:** Изменения последовательно применяются в различных файлах, что указывает на соблюдение единого стиля.  \n\n**Читаемость:** Замена `req.data.docs` на `req.direct_docs` не ухудшает читаемость, а добавление параметра `http` в `process_data` делает код более понятным в контексте HTTP-запросов.  \n\n**Соответствие гайдлайнам:** Изменения не нарушают каких-либо явных правил стиля, предполагая, что существующий код соответствует гайдлайнам.  \n\nВ целом, изменения выглядят как улучшения, направленные на оптимизацию и улучшение обработки HTTP-запросов.","recommendations":["Нет существенных рекомендаций по стилю."],"confidence":"High","score":8,"summary":"Внесенные изменения улучшают обработку HTTP-запросов, заменяя `req.data.docs` на `req.direct_docs` и добавляя параметр `http` в функцию `process_data`. Код соответствует стандартам стиля."}},{"pull":{"id":6182,"html_url":"https://github.com/jina-ai/serve/pull/6182","title":"chore: print lines debug","body":"Goals:\n\n\n\nresolves #ISSUE-NUMBER\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n check and update documentation. See guide and ask the team.","is_merged":false,"diff":"diff --git a/jina/clients/base/helper.py b/jina/clients/base/helper.py\nindex 0a2d7481164a8..d512c09568ff3 100644\n--- a/jina/clients/base/helper.py\n+++ b/jina/clients/base/helper.py\n@@ -15,7 +15,7 @@\n from jina.types.request import Request\n from jina.types.request.data import DataRequest\n from jina.types.request.status import StatusMessage\n-\n+import timeit\n if TYPE_CHECKING:  # pragma: no cover\n     from opentelemetry import trace\n \n@@ -122,8 +122,11 @@ async def __aenter__(self):\n \n         :return: start self\n         \"\"\"\n-        return await self.start()\n-\n+        _start = timeit.default_timer()\n+        res = await self.start()\n+        _end = timeit.default_timer()\n+        print(f'ASYNC ENTER {_end - _start}s')\n+        return res\n     async def start(self):\n         \"\"\"Create ClientSession and enter context\n \n@@ -139,7 +142,11 @@ async def start(self):\n         return self\n \n     async def __aexit__(self, exc_type, exc_val, exc_tb):\n-        await self.close(exc_type, exc_val, exc_tb)\n+        _start = timeit.default_timer()\n+        res = await self.close(exc_type, exc_val, exc_tb)\n+        _end = timeit.default_timer()\n+        print(f'ASYNC EXIT {_end - _start}s')\n+        return res\n \n     async def close(self, *args, **kwargs):\n         \"\"\"Close ClientSession\n@@ -160,12 +167,15 @@ async def send_message(self, request: 'Request'):\n         :param request: request as dict\n         :return: send post message\n         \"\"\"\n+        _start = timeit.default_timer()\n+        print(f'{_start} => HTTPClient send message lets start')\n         req_dict = request.to_dict()\n         req_dict['exec_endpoint'] = req_dict['header']['exec_endpoint']\n         if 'target_executor' in req_dict['header']:\n             req_dict['target_executor'] = req_dict['header']['target_executor']\n         for attempt in range(1, self.max_attempts + 1):\n             try:\n+                _start_req = timeit.default_timer()\n                 request_kwargs = {'url': self.url}\n                 if not docarray_v2:\n                     request_kwargs['json'] = req_dict\n@@ -173,12 +183,16 @@ async def send_message(self, request: 'Request'):\n                     from docarray.base_doc.io.json import orjson_dumps\n \n                     request_kwargs['data'] = JinaJsonPayload(value=req_dict)\n+                _end_req = timeit.default_timer()\n+                print(f'{_end_req} => HTTPClient prepare request took {_end_req - _start_req}s')\n                 response = await self.session.post(**request_kwargs).__aenter__()\n                 try:\n                     r_str = await response.json()\n                 except aiohttp.ContentTypeError:\n                     r_str = await response.text()\n                 handle_response_status(response.status, r_str, self.url)\n+                _end = timeit.default_timer()\n+                print(f'{_end} => HTTPClient send_message total took {_end - _start}s')\n                 return response\n             except (ValueError, ConnectionError, BadClient, aiohttp.ClientError) as err:\n                 await retry.wait_or_raise_err(\ndiff --git a/jina/clients/base/http.py b/jina/clients/base/http.py\nindex c55156bf69365..2ad5ca0426028 100644\n--- a/jina/clients/base/http.py\n+++ b/jina/clients/base/http.py\n@@ -12,6 +12,7 @@\n from jina.serve.stream import RequestStreamer\n from jina.types.request import Request\n from jina.types.request.data import DataRequest\n+import timeit\n \n if TYPE_CHECKING:  # pragma: no cover\n     from jina.clients.base import CallbackFnType, InputType\n@@ -96,20 +97,20 @@ async def _is_flow_ready(self, **kwargs) -> bool:\n         return False\n \n     async def _get_results(\n-        self,\n-        inputs: 'InputType',\n-        on_done: 'CallbackFnType',\n-        on_error: Optional['CallbackFnType'] = None,\n-        on_always: Optional['CallbackFnType'] = None,\n-        max_attempts: int = 1,\n-        initial_backoff: float = 0.5,\n-        max_backoff: float = 0.1,\n-        backoff_multiplier: float = 1.5,\n-        results_in_order: bool = False,\n-        prefetch: Optional[int] = None,\n-        timeout: Optional[int] = None,\n-        return_type: Type[DocumentArray] = DocumentArray,\n-        **kwargs,\n+            self,\n+            inputs: 'InputType',\n+            on_done: 'CallbackFnType',\n+            on_error: Optional['CallbackFnType'] = None,\n+            on_always: Optional['CallbackFnType'] = None,\n+            max_attempts: int = 1,\n+            initial_backoff: float = 0.5,\n+            max_backoff: float = 0.1,\n+            backoff_multiplier: float = 1.5,\n+            results_in_order: bool = False,\n+            prefetch: Optional[int] = None,\n+            timeout: Optional[int] = None,\n+            return_type: Type[DocumentArray] = DocumentArray,\n+            **kwargs,\n     ):\n         \"\"\"\n         :param inputs: the callable\n@@ -130,17 +131,24 @@ async def _get_results(\n         with ImportExtensions(required=True):\n             pass\n \n+        _start_total = timeit.default_timer()\n+        print(f'## {_start_total} => I AM in _get_results')\n+\n         self.inputs = inputs\n+        _aada = timeit.default_timer()\n+        print(f'Setting inputs took {_aada - _start_total}s')\n         request_iterator = self._get_requests(**kwargs)\n+        _aada2 = timeit.default_timer()\n+        print(f'Getting req_it {_aada2 - _aada}s')\n         on = kwargs.get('on', '/post')\n         if len(self._endpoints) == 0:\n             await self._get_endpoints_from_openapi(**kwargs)\n \n         async with AsyncExitStack() as stack:\n-            cm1 = ProgressBar(\n-                total_length=self._inputs_length, disable=not self.show_progress\n-            )\n-            p_bar = stack.enter_context(cm1)\n+            # cm1 = ProgressBar(\n+            #     total_length=self._inputs_length, disable=not self.show_progress\n+            # )\n+            # p_bar = stack.enter_context(cm1)\n             proto = 'https' if self.args.tls else 'http'\n             endpoint = on.strip('/')\n             has_default_endpoint = 'default' in self._endpoints\n@@ -167,7 +175,7 @@ async def _get_results(\n             )\n \n             def _request_handler(\n-                request: 'Request', **kwargs\n+                    request: 'Request', **kwargs\n             ) -> 'Tuple[asyncio.Future, Optional[asyncio.Future]]':\n                 \"\"\"\n                 For HTTP Client, for each request in the iterator, we `send_message` using\n@@ -176,7 +184,8 @@ def _request_handler(\n                 :param kwargs: kwargs\n                 :return: asyncio Task for sending message\n                 \"\"\"\n-                return asyncio.ensure_future(iolet.send_message(request=request)), None\n+                res = asyncio.ensure_future(iolet.send_message(request=request)), None\n+                return res\n \n             def _result_handler(result):\n                 return result\n@@ -184,19 +193,31 @@ def _result_handler(result):\n             streamer_args = vars(self.args)\n             if prefetch:\n                 streamer_args['prefetch'] = prefetch\n+\n+            _start_streamer = timeit.default_timer()\n+            print(f'## {_start_streamer} => I AM creating streamer')\n             streamer = RequestStreamer(\n                 request_handler=_request_handler,\n                 result_handler=_result_handler,\n                 logger=self.logger,\n                 **streamer_args,\n             )\n+\n+            _start = timeit.default_timer()\n+            print(f'## Streamer created in {_start - _start_streamer}s')\n+\n             async for response in streamer.stream(\n-                request_iterator=request_iterator, results_in_order=results_in_order\n+                    request_iterator=request_iterator, results_in_order=results_in_order\n             ):\n+\n                 r_status = response.status\n \n                 r_str = await response.json()\n+                _end = timeit.default_timer()\n+                print(f'{_end} => GETTING RESPONSE from streamer took {_end - _start}s')\n+                _start = timeit.default_timer()\n                 handle_response_status(r_status, r_str, url)\n+                _st = timeit.default_timer()\n \n                 da = None\n                 if 'data' in r_str and r_str['data'] is not None:\n@@ -216,10 +237,15 @@ def _result_handler(result):\n                                 [return_type(**v) for v in r_str['data']]\n                             )\n                     del r_str['data']\n-\n+                _e = timeit.default_timer()\n+                print(f'Create DocList took {_e - _st}s')\n                 resp = DataRequest(r_str)\n+                _e2 = timeit.default_timer()\n+                print(f'Create DataRequest from r_str took {_e2 - _e}s')\n                 if da is not None:\n                     resp.direct_docs = da\n+                _e3 = timeit.default_timer()\n+                print(f'Setting direct_docs took {_e3 - _e2}s')\n \n                 callback_exec(\n                     response=resp,\n@@ -229,18 +255,25 @@ def _result_handler(result):\n                     on_always=on_always,\n                     continue_on_error=self.continue_on_error,\n                 )\n-                if self.show_progress:\n-                    p_bar.update()\n+                _e4 = timeit.default_timer()\n+                print(f'Calling callback took {_e4 - _e3}s')\n+                # if self.show_progress:\n+                #     p_bar.update()\n+                _end = timeit.default_timer()\n+                print(f'{_end} => YIELD RESPONSE TOOK {_end - _start}s')\n                 yield resp\n \n+        _end_total = timeit.default_timer()\n+        print(f'## {_end_total} => I AM in _get_results took {_end_total - _start_total}s')\n+\n     async def _get_streaming_results(\n-        self,\n-        on: str,\n-        inputs: 'Document',\n-        parameters: Optional[Dict] = None,\n-        return_type: Type[Document] = Document,\n-        timeout: Optional[int] = None,\n-        **kwargs,\n+            self,\n+            on: str,\n+            inputs: 'Document',\n+            parameters: Optional[Dict] = None,\n+            return_type: Type[Document] = Document,\n+            timeout: Optional[int] = None,\n+            **kwargs,\n     ):\n         proto = 'https' if self.args.tls else 'http'\n         endpoint = on.strip('/')\ndiff --git a/jina/clients/mixin.py b/jina/clients/mixin.py\nindex a6960fa355f63..8d643e75362e9 100644\n--- a/jina/clients/mixin.py\n+++ b/jina/clients/mixin.py\n@@ -10,7 +10,7 @@\n from jina.excepts import InternalNetworkError\n from jina.helper import deprecate_by, get_or_reuse_loop, run_async\n from jina.importer import ImportExtensions\n-\n+import timeit\n if TYPE_CHECKING:  # pragma: no cover\n     from pydantic import BaseModel\n     from jina.clients.base import CallbackFnType, InputType\n@@ -387,8 +387,10 @@ def post(\n         .. warning::\n             ``target_executor`` uses ``re.match`` for checking if the pattern is matched. ``target_executor=='foo'`` will match both deployments with the name ``foo`` and ``foo_what_ever_suffix``.\n         \"\"\"\n-\n+        print(f'##### I AM POSTING')\n+        _post_start = timeit.default_timer()\n         c = self.client\n+        _cl = timeit.default_timer()\n         c.show_progress = show_progress\n         c.continue_on_error = continue_on_error\n \n@@ -397,6 +399,9 @@ def post(\n         return_results = (on_always is None) and (on_done is None)\n \n         async def _get_results(*args, **kwargs):\n+            _start = timeit.default_timer()\n+            print(f'{_start} ######## I AM GETTING RESULTS')\n+\n             is_singleton = False\n             inferred_return_type = return_type\n             if docarray_v2:\n@@ -415,13 +420,16 @@ async def _get_results(*args, **kwargs):\n                         result.append(resp)\n                     else:\n                         result.extend(resp.docs)\n+\n+            _end = timeit.default_timer()\n+            print(f'######## {_end} => I AM GETTING RESULTS took {_end - _start}s')\n             if return_results:\n                 if not return_responses and is_singleton and len(result) == 1:\n                     return result[0]\n                 else:\n                     return result\n \n-        return self._with_retry(\n+        res = self._with_retry(\n             func=_get_results,\n             inputs=inputs,\n             on_done=on_done,\n@@ -442,6 +450,9 @@ async def _get_results(*args, **kwargs):\n             on=on,\n             **kwargs,\n         )\n+        _post_end = timeit.default_timer()\n+        print(f'##### I AM POSTING took {_post_end - _post_start}s')\n+        return res\n \n     # ONLY CRUD, for other request please use `.post`\n     index = partialmethod(post, '/index')\ndiff --git a/jina/helper.py b/jina/helper.py\nindex b5bcd9759b4b8..80bd8dd4b4d26 100644\n--- a/jina/helper.py\n+++ b/jina/helper.py\n@@ -38,7 +38,7 @@\n from rich.console import Console\n \n from jina.constants import __windows__\n-\n+import timeit\n __all__ = [\n     'batch_iterator',\n     'parse_arg',\n@@ -1316,6 +1316,8 @@ def run(self):\n                 'something wrong when running the eventloop, result can not be retrieved'\n             )\n     else:\n+\n+        print(f'{timeit.default_timer()} ==> HEY HERE ASYNCIO RUN {func.__name__}')\n         return asyncio.run(func(*args, **kwargs))\n \n \ndiff --git a/jina/serve/runtimes/worker/http_fastapi_app.py b/jina/serve/runtimes/worker/http_fastapi_app.py\nindex 889166d8aeb63..61ed8ad1a1fe3 100644\n--- a/jina/serve/runtimes/worker/http_fastapi_app.py\n+++ b/jina/serve/runtimes/worker/http_fastapi_app.py\n@@ -87,8 +87,11 @@ def add_post_route(\n \n             app_kwargs['response_class'] = DocArrayResponse\n \n+        from timeit import default_timer\n+\n         @app.api_route(**app_kwargs)\n         async def post(body: input_model, response: Response):\n+            _start = default_timer()\n             req = DataRequest()\n             if body.header is not None:\n                 req.header.request_id = body.header.request_id\n@@ -111,8 +114,19 @@ async def post(body: input_model, response: Response):\n                     req.direct_docs = DocList[input_doc_list_model]([data])\n                 if body.header is None:\n                     req.header.request_id = req.docs[0].id\n+            _end = default_timer()\n \n+            logger.info(\n+                f'Creating Request took {_end - _start}s'\n+            )\n+            _start = default_timer()\n             resp = await caller(req)\n+            _end = default_timer()\n+\n+            logger.info(\n+                f'Respon to Request took {_end - _start}s'\n+            )\n+            _start = default_timer()\n             status = resp.header.status\n \n             if status.code == jina_pb2.StatusProto.ERROR:\n@@ -123,7 +137,10 @@ async def post(body: input_model, response: Response):\n                 else:\n                     docs_response = resp.docs\n                 ret = output_model(data=docs_response, parameters=resp.parameters)\n-\n+                _end = default_timer()\n+                logger.info(\n+                    f'Extra time {_end - _start}s'\n+                )\n                 return ret\n \n     def add_streaming_routes(\ndiff --git a/jina/serve/runtimes/worker/request_handling.py b/jina/serve/runtimes/worker/request_handling.py\nindex 7d9958c35c049..bc62bf9f0d135 100644\n--- a/jina/serve/runtimes/worker/request_handling.py\n+++ b/jina/serve/runtimes/worker/request_handling.py\n@@ -30,6 +30,7 @@\n from jina.serve.instrumentation import MetricsTimer\n from jina.serve.runtimes.worker.batch_queue import BatchQueue\n from jina.types.request.data import DataRequest, SingleDocumentRequest\n+from timeit import default_timer\n \n if docarray_v2:\n     from docarray import DocList\n@@ -671,6 +672,7 @@ async def handle(\n         :returns: the processed message\n         \"\"\"\n         # skip executor if endpoints mismatch\n+        _start = default_timer()\n         exec_endpoint: str = requests[0].header.exec_endpoint\n         if exec_endpoint not in self._executor.requests:\n             if __default_endpoint__ in self._executor.requests:\n@@ -716,6 +718,8 @@ async def handle(\n             docs_matrix, docs_map = WorkerRequestHandler._get_docs_matrix_from_request(\n                 requests\n             )\n+            _end = default_timer()\n+            print(f'EXTRA BEFORE EXECUTOR TOOK {_end - _start}s')\n             return_data = await self._executor.__acall__(\n                 req_endpoint=exec_endpoint,\n                 docs=docs,\n@@ -724,6 +728,7 @@ async def handle(\n                 docs_map=docs_map,\n                 tracing_context=tracing_context,\n             )\n+            _start = default_timer()\n             _ = self._set_result(requests, return_data, docs, http=http)\n \n         for req in requests:\n@@ -735,7 +740,8 @@ async def handle(\n         except AttributeError:\n             pass\n         self._record_response_size_monitoring(requests)\n-\n+        _end = default_timer()\n+        print(f'EXTRA AFTER EXECUTOR TOOK {_end - _start}s')\n         return requests[0]\n \n     @staticmethod\ndiff --git a/jina/serve/stream/__init__.py b/jina/serve/stream/__init__.py\nindex 03c488d78f114..1ae5bf666d529 100644\n--- a/jina/serve/stream/__init__.py\n+++ b/jina/serve/stream/__init__.py\n@@ -20,7 +20,7 @@\n \n from jina._docarray import DocumentArray\n from jina.types.request.data import Response\n-\n+import timeit\n if TYPE_CHECKING:  # pragma: no cover\n     from jina.types.request import Request\n \n@@ -178,6 +178,8 @@ async def stream(\n         :param args: positional arguments\n         :yield: responses from Executors\n         \"\"\"\n+        _start_streaming = timeit.default_timer()\n+        print(f'## {_start_streaming} Start streaming')\n         prefetch = prefetch or self._prefetch\n         if context is not None:\n             for metadatum in context.invocation_metadata():\n@@ -197,6 +199,8 @@ async def stream(\n                 return_type=return_type,\n             )\n             async for response in async_iter:\n+                _first_resp_streaming = timeit.default_timer()\n+                print(f'## {_first_resp_streaming} Got first response in {_first_resp_streaming - _start_streaming}s')\n                 yield response\n         except InternalNetworkError as err:\n             if (\n"},"summary":"## Summary:\n\nДанный Merge Request (MR) направлен на добавление отладочной информации для измерения времени выполнения операций. Основные изменения включают добавление операторов `print` и использование `timeit` в нескольких файлах (`helper.py`, `http.py`, `mixin.py`, `http_fastapi_app.py`, `request_handling.py`, `__init__.py`) для отслеживания производительности. Экспертная оценка выявила умеренную сложность изменений. В то же время, MR содержит значительное количество отладочных принтов, что является анти-паттерном и снижает читаемость кода. Рекомендуется удалить все отладочные принты и рассмотреть возможность использования более структурированного логирования после завершения отладки.\n","antiPatterns":{"detailed_analysis":"Внесенные изменения содержат множество отладочных принтов, которые не должны оставаться в коде. Это анти-паттерн, который ухудшает читаемость и может привести к проблемам с производительностью. Также, добавление `timeit` для измерения времени выполнения в нескольких местах, хотя и полезно для отладки, не является лучшей практикой для продакшн-кода и может быть расценено как незначительный анти-паттерн. Общая оценка снижена из-за большого количества отладочных принтов.","recommendations":["Удалить все отладочные принты, добавленные в рамках этого MR.","Рассмотреть возможность использования более структурированного подхода к логированию (например, с использованием библиотеки `logging`) вместо `print` для отладки.","Удалить или закомментировать `timeit` после завершения отладки, если они не нужны в продакшн-коде."],"confidence":"High","score":4,"summary":"Внесенные изменения содержат значительное количество отладочных принтов, что является анти-паттерном."},"complexity":{"justification":"Изменения включают в себя добавление отладочной печати для измерения времени выполнения различных операций в нескольких файлах (helper.py, http.py, mixin.py, http_fastapi_app.py, request_handling.py, __init__.py). Объем изменений умеренный, затрагивает несколько файлов.  Изменения не затрагивают критические компоненты, но влияют на логику обработки запросов и ответа.  Когнитивная нагрузка умеренная, так как изменения простые, но требуют понимания структуры кода и логики обработки запросов.  Риски минимальны, так как изменения в основном касаются отладки и не должны влиять на функциональность.  Примеры: добавление `timeit` для измерения времени выполнения функций.  Это соответствует уровню сложности Medium, так как изменения требуют понимания существующего кода и влияют на несколько компонентов, но не являются сложными или рискованными.","classification":"Medium"},"designPatterns":{"detailed_analysis":"В данном Merge Request (MR) были добавлены отладочные сообщения с использованием `timeit` для измерения времени выполнения различных операций. Это само по себе не является анти-паттерном, но чрезмерное использование таких сообщений может привести к захламлению кода и усложнению его чтения. В частности, добавление `timeit` в `jina/clients/base/helper.py`, `jina/clients/base/http.py`, `jina/clients/mixin.py`, `jina/helper.py`, `jina/serve/runtimes/worker/http_fastapi_app.py`, `jina/serve/runtimes/worker/request_handling.py` и `jina/serve/stream/__init__.py` указывает на потенциальное избыточное использование. Также, в `jina/clients/base/helper.py` и `jina/clients/mixin.py` добавлены вызовы `print` для отладки, что может указывать на временное решение, которое следует удалить после завершения отладки. В целом, изменения не вводят серьезных анти-паттернов, но требуют осторожности в отношении количества отладочных сообщений.","recommendations":["Удалить или закомментировать отладочные сообщения `timeit` и `print` после завершения отладки.","Рассмотреть возможность использования более структурированного механизма логирования (например, `logging`) для отладочной информации, чтобы избежать захламления кода.","Убедиться, что отладочные сообщения не влияют на производительность в продакшене."],"confidence":"Medium","score":7,"summary":"Внесены отладочные сообщения, что потенциально может привести к захламлению кода. Рекомендуется удалить или закомментировать их после завершения отладки."},"codeStyle":{"detailed_analysis":"Изменения в основном касаются добавления операторов `print` для отладки времени выполнения различных операций в коде. Эти операторы добавлены в `jina/clients/base/helper.py`, `jina/clients/base/http.py`, `jina/clients/mixin.py`, `jina/helper.py`, `jina/serve/runtimes/worker/http_fastapi_app.py`, `jina/serve/runtimes/worker/request_handling.py` и `jina/serve/stream/__init__.py`.  В целом, изменения не влияют на форматирование, именование или соответствие гайдлайнам, но добавляют логирование времени выполнения, что может быть полезно для отладки.  Читаемость кода немного снижается из-за добавления операторов `print`, но это незначительно. Консистентность сохраняется, так как изменения в основном касаются добавления отладочной информации.","recommendations":["Удалить операторы print после завершения отладки.","Рассмотреть возможность использования более структурированного логирования (например, с использованием библиотеки logging) вместо print для production-ready кода."],"confidence":"Medium","score":6,"summary":"Внесены изменения, добавляющие операторы print для отладки. Код в целом соответствует стандартам, но рекомендуется удалить отладочные print-ы после завершения отладки и рассмотреть более структурированный подход к логированию."}},{"pull":{"id":6181,"html_url":"https://github.com/jina-ai/serve/pull/6181","title":"fix: avoid expensive setting","body":"Goals:\n\n\n\nresolves #ISSUE-NUMBER\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n check and update documentation. See guide and ask the team.","is_merged":false,"diff":"diff --git a/jina/clients/base/grpc.py b/jina/clients/base/grpc.py\nindex 204924a57f74d..6a4c0e9f6ae56 100644\n--- a/jina/clients/base/grpc.py\n+++ b/jina/clients/base/grpc.py\n@@ -145,7 +145,7 @@ async def _get_results(\n                                 async for (\n                                     response\n                                 ) in stream_rpc.stream_rpc_with_retry():\n-                                    yield response\n+                                    yield response, None\n                             else:\n                                 unary_rpc = UnaryRpc(\n                                     channel=channel,\n@@ -169,7 +169,7 @@ async def _get_results(\n                                     **kwargs,\n                                 )\n                                 async for response in unary_rpc.unary_rpc_with_retry():\n-                                    yield response\n+                                    yield response, None\n                         except (grpc.aio.AioRpcError, InternalNetworkError) as err:\n                             await self._handle_error_and_metadata(err)\n         except KeyboardInterrupt:\ndiff --git a/jina/clients/base/http.py b/jina/clients/base/http.py\nindex 653a98f051629..cc7a495cd3fdf 100644\n--- a/jina/clients/base/http.py\n+++ b/jina/clients/base/http.py\n@@ -218,12 +218,13 @@ def _result_handler(result):\n                     del r_str['data']\n \n                 resp = DataRequest(r_str)\n-                if da is not None:\n-                    resp.data.docs = da\n+                #if da is not None:\n+                #    resp.data.docs = da\n \n                 callback_exec(\n                     response=resp,\n                     logger=self.logger,\n+                    docs=da,\n                     on_error=on_error,\n                     on_done=on_done,\n                     on_always=on_always,\n@@ -231,7 +232,7 @@ def _result_handler(result):\n                 )\n                 if self.show_progress:\n                     p_bar.update()\n-                yield resp\n+                yield resp, da\n \n     async def _get_streaming_results(\n         self,\ndiff --git a/jina/clients/base/stream_rpc.py b/jina/clients/base/stream_rpc.py\nindex 6ea2b9805e27a..ebfef9fdfd71b 100644\n--- a/jina/clients/base/stream_rpc.py\n+++ b/jina/clients/base/stream_rpc.py\n@@ -58,6 +58,7 @@ async def stream_rpc_with_retry(self):\n             callback_exec(\n                 response=resp,\n                 logger=self.logger,\n+                docs=None,\n                 on_error=self.on_error,\n                 on_done=self.on_done,\n                 on_always=self.on_always,\ndiff --git a/jina/clients/base/unary_rpc.py b/jina/clients/base/unary_rpc.py\nindex 6cb219706738c..dc762bcee49ab 100644\n--- a/jina/clients/base/unary_rpc.py\n+++ b/jina/clients/base/unary_rpc.py\n@@ -101,6 +101,7 @@ def _result_handler(resp):\n             callback_exec(\n                 response=resp,\n                 logger=self.logger,\n+                docs=None,\n                 on_error=self.on_error,\n                 on_done=self.on_done,\n                 on_always=self.on_always,\ndiff --git a/jina/clients/base/websocket.py b/jina/clients/base/websocket.py\nindex a8b868704bac0..806e517182446 100644\n--- a/jina/clients/base/websocket.py\n+++ b/jina/clients/base/websocket.py\n@@ -209,6 +209,7 @@ def _request_handler(\n                     callback_exec(\n                         response=response,\n                         logger=self.logger,\n+                        docs=None,\n                         on_error=on_error,\n                         on_done=on_done,\n                         on_always=on_always,\n@@ -216,7 +217,7 @@ def _request_handler(\n                     )\n                     if self.show_progress:\n                         p_bar.update()\n-                    yield response\n+                    yield response, None\n             except Exception as ex:\n                 exception_raised = ex\n                 try:\ndiff --git a/jina/clients/helper.py b/jina/clients/helper.py\nindex 063837abc9240..5bdbacd17600f 100644\n--- a/jina/clients/helper.py\n+++ b/jina/clients/helper.py\n@@ -58,6 +58,7 @@ def _arg_wrapper(*args, **kwargs):\n def callback_exec(\n     response,\n     logger: JinaLogger,\n+    docs: Optional = None,\n     on_done: Optional[Callable] = None,\n     on_error: Optional[Callable] = None,\n     on_always: Optional[Callable] = None,\n@@ -66,20 +67,28 @@ def callback_exec(\n     \"\"\"Execute the callback with the response.\n \n     :param response: the response\n+    :param logger: a logger instance\n+    :param docs: the docs to attach lazily to response if needed\n     :param on_done: the on_done callback\n     :param on_error: the on_error callback\n     :param on_always: the on_always callback\n     :param continue_on_error: whether to continue on error\n-    :param logger: a logger instance\n     \"\"\"\n     if response.header.status.code >= jina_pb2.StatusProto.ERROR:\n         if on_error:\n+            if docs is not None:\n+                # response.data.docs is expensive and not always needed.\n+                response.data.docs = docs\n             _safe_callback(on_error, continue_on_error, logger)(response)\n         elif continue_on_error:\n             logger.error(f'Server error: {response.header}')\n         else:\n             raise BadServer(response.header)\n     elif on_done and response.header.status.code == jina_pb2.StatusProto.SUCCESS:\n+        if docs is not None:\n+            response.data.docs = docs\n         _safe_callback(on_done, continue_on_error, logger)(response)\n     if on_always:\n+        if docs is not None:\n+            response.data.docs = docs\n         _safe_callback(on_always, continue_on_error, logger)(response)\ndiff --git a/jina/clients/mixin.py b/jina/clients/mixin.py\nindex ec0c52049d200..024316df64e46 100644\n--- a/jina/clients/mixin.py\n+++ b/jina/clients/mixin.py\n@@ -407,14 +407,17 @@ async def _get_results(*args, **kwargs):\n                     inferred_return_type = DocList[return_type]\n             result = [] if return_responses else inferred_return_type([])\n \n-            async for resp in c._get_results(*args, **kwargs):\n+            async for resp, da in c._get_results(*args, **kwargs):\n \n                 if return_results:\n                     resp.document_array_cls = inferred_return_type\n                     if return_responses:\n+                        if da is not None:\n+                            resp.data.docs = da\n                         result.append(resp)\n                     else:\n-                        result.extend(resp.data.docs)\n+                        result.extend(da if da is not None else resp.data.docs)\n+\n             if return_results:\n                 if not return_responses and is_singleton and len(result) == 1:\n                     return result[0]\n@@ -508,7 +511,7 @@ async def post(\n \n         parameters = _include_results_field_in_param(parameters)\n \n-        async for result in c._get_results(\n+        async for result, da in c._get_results(\n             on=on,\n             inputs=inputs,\n             on_done=on_done,\n@@ -538,12 +541,14 @@ async def post(\n                     is_singleton = True\n                     result.document_array_cls = DocList[return_type]\n             if not return_responses:\n-                ret_docs = result.data.docs\n+                ret_docs = da if da is not None else result.data.docs\n                 if is_singleton and len(ret_docs) == 1:\n                     yield ret_docs[0]\n                 else:\n                     yield ret_docs\n             else:\n+                if da is not None:\n+                    result.data.docs = da\n                 yield result\n \n     async def stream_doc(\n"},"summary":"## Summary of Merge Request\n\nЦель данного MR - оптимизация обработки данных и улучшение производительности, в основном за счет отложенной загрузки данных. Ключевые изменения включают добавление `docs=None` в вызовы `callback_exec` и изменение возвращаемых значений в асинхронных функциях для передачи данных. Оценка сложности - средняя, так как изменения затрагивают несколько файлов и требуют понимания взаимодействия между компонентами. Код соответствует стандартам стиля, оценка 8. Изменения не вводят анти-паттерны, а направлены на оптимизацию, оценка 9. Дизайн паттерны не нарушены, оценка 10.\n","antiPatterns":{"detailed_analysis":"Внесенные изменения в основном касаются добавления `docs=da` в вызовы `callback_exec` и изменения возвращаемых значений в некоторых функциях для передачи `da`. Это сделано для оптимизации, чтобы избежать дорогостоящего доступа к `response.data.docs`, если он не нужен.  В коде не обнаружено новых анти-паттернов, и изменения направлены на улучшение производительности, что является положительным моментом.  Небольшое изменение в `mixin.py` для обработки `da` также не вносит анти-паттернов.","recommendations":[],"confidence":"High","score":9,"summary":"Изменения направлены на оптимизацию доступа к данным и не вводят анти-паттерны. Оценка: 9."},"complexity":{"justification":"Данный diff содержит изменения в нескольких файлах, затрагивая логику обработки результатов в различных клиентских классах (grpc, http, websocket и др.). Основные изменения включают добавление `docs=None` в вызовы `callback_exec` и изменение возвращаемых значений в некоторых асинхронных функциях для передачи данных. Эти изменения, вероятно, направлены на оптимизацию обработки данных и улучшение производительности, но требуют понимания взаимодействия между различными компонентами системы. Объем изменений умеренный, но затрагивает несколько файлов и требует понимания логики обработки результатов. Риски умеренные, так как изменения в основном касаются обработки данных и не затрагивают критические компоненты напрямую. Когнитивная нагрузка умеренная, так как требуется понимание логики обработки результатов и взаимодействия между компонентами.  Примеры из определения сложности (Medium) соответствуют характеру изменений: добавление нового функционала, требующего понимания взаимодействия между частями системы, и рефакторинг, затрагивающий API/структуры данных без существенных изменений архитектуры.","classification":"Medium"},"designPatterns":{"detailed_analysis":"Внесенные изменения в основном касаются добавления `docs=None` в вызовы `callback_exec` и изменения возвращаемых значений в некоторых функциях для передачи `docs`. Эти изменения направлены на оптимизацию и отложенную загрузку данных, что является хорошей практикой. Не обнаружено каких-либо анти-паттернов, введенных этими изменениями. ","recommendations":[],"confidence":"High","score":10,"summary":"Изменения направлены на оптимизацию и отложенную загрузку данных, анти-паттерны не обнаружены."},"codeStyle":{"detailed_analysis":"Изменения в основном касаются добавления `docs=None` в вызовы `callback_exec` и изменения возвращаемых значений в некоторых функциях для передачи данных. Это сделано для оптимизации, чтобы избежать дорогостоящего доступа к `response.data.docs`, если он не нужен.  \n\n**Форматирование:** В целом, форматирование соответствует стандартам. Изменения минимальны и не влияют на читаемость.\n\n**Именование:** Имена переменных и функций остаются понятными и соответствующими их назначению. Изменения не вносят изменений в именование.\n\n**Консистентность:** Изменения последовательно применяются во всех затронутых файлах, что обеспечивает консистентность стиля.\n\n**Читаемость:** Добавление `docs=None` и изменение возвращаемых значений улучшают читаемость, поскольку код становится более эффективным и избегает ненужных операций.  Комментарии не требуются, так как изменения понятны.\n\n**Соответствие гайдлайнам:** Код соответствует общим принципам стиля, таким как PEP 8.  Изменения не нарушают никаких гайдлайнов.","recommendations":["Нет существенных рекомендаций по стилю. Код хорошо структурирован и соответствует стандартам."],"confidence":"High","score":8,"summary":"Внесенные изменения направлены на оптимизацию производительности, избегая ненужных операций с данными. Код соответствует стандартам стиля."}},{"pull":{"id":6179,"html_url":"https://github.com/jina-ai/serve/pull/6179","title":"feat: add flush all option to dynamic batching configuration","body":"Allow flush-all option to dynamic batching","is_merged":true,"diff":"diff --git a/jina/serve/executors/decorators.py b/jina/serve/executors/decorators.py\nindex 4034439102478..7c7a6e4031bcf 100644\n--- a/jina/serve/executors/decorators.py\n+++ b/jina/serve/executors/decorators.py\n@@ -416,6 +416,7 @@ def dynamic_batching(\n     *,\n     preferred_batch_size: Optional[int] = None,\n     timeout: Optional[float] = 10_000,\n+    flush_all: bool = False\n ):\n     \"\"\"\n     `@dynamic_batching` defines the dynamic batching behavior of an Executor.\n@@ -426,11 +427,13 @@ def dynamic_batching(\n \n     :param func: the method to decorate\n     :param preferred_batch_size: target number of Documents in a batch. The batcher will collect requests until `preferred_batch_size` is reached,\n-        or until `timeout` is reached. Therefore, the actual batch size can be smaller or larger than `preferred_batch_size`.\n+        or until `timeout` is reached. Therefore, the actual batch size can be smaller or equal to `preferred_batch_size`, except if `flush_all` is set to True\n     :param timeout: maximum time in milliseconds to wait for a request to be assigned to a batch.\n         If the oldest request in the queue reaches a waiting time of `timeout`, the batch will be passed to the Executor,\n         even if it contains fewer than `preferred_batch_size` Documents.\n         Default is 10_000ms (10 seconds).\n+    :param flush_all: Determines if once the batches is triggered by timeout or preferred_batch_size, the function will receive everything that the batcher has accumulated or not.\n+        If this is true, `preferred_batch_size` is used as a trigger mechanism.\n     :return: decorated function\n     \"\"\"\n \n@@ -476,6 +479,7 @@ def _inject_owner_attrs(self, owner, name):\n                 'preferred_batch_size'\n             ] = preferred_batch_size\n             owner.dynamic_batching[fn_name]['timeout'] = timeout\n+            owner.dynamic_batching[fn_name]['flush_all'] = flush_all\n             setattr(owner, name, self.fn)\n \n         def __set_name__(self, owner, name):\ndiff --git a/jina/serve/runtimes/worker/batch_queue.py b/jina/serve/runtimes/worker/batch_queue.py\nindex 530f5f58d3a81..8f7e0d283b413 100644\n--- a/jina/serve/runtimes/worker/batch_queue.py\n+++ b/jina/serve/runtimes/worker/batch_queue.py\n@@ -23,6 +23,7 @@ def __init__(\n         response_docarray_cls,\n         output_array_type: Optional[str] = None,\n         params: Optional[Dict] = None,\n+        flush_all: bool = False,\n         preferred_batch_size: int = 4,\n         timeout: int = 10_000,\n     ) -> None:\n@@ -35,6 +36,7 @@ def __init__(\n         self.params = params\n         self._request_docarray_cls = request_docarray_cls\n         self._response_docarray_cls = response_docarray_cls\n+        self._flush_all = flush_all\n         self._preferred_batch_size: int = preferred_batch_size\n         self._timeout: int = timeout\n         self._reset()\n@@ -205,7 +207,10 @@ async def _assign_results(\n \n             return num_assigned_docs\n \n-        def batch(iterable_1, iterable_2, n=1):\n+        def batch(iterable_1, iterable_2, n:Optional[int] = 1):\n+            if n is None:\n+                yield iterable_1, iterable_2\n+                return\n             items = len(iterable_1)\n             for ndx in range(0, items, n):\n                 yield iterable_1[ndx : min(ndx + n, items)], iterable_2[\n@@ -229,7 +234,7 @@ def batch(iterable_1, iterable_2, n=1):\n                 non_assigned_to_response_request_idxs = []\n                 sum_from_previous_first_req_idx = 0\n                 for docs_inner_batch, req_idxs in batch(\n-                    self._big_doc, self._request_idxs, self._preferred_batch_size\n+                    self._big_doc, self._request_idxs, self._preferred_batch_size if not self._flush_all else None\n                 ):\n                     involved_requests_min_indx = req_idxs[0]\n                     involved_requests_max_indx = req_idxs[-1]\ndiff --git a/jina/serve/runtimes/worker/http_fastapi_app.py b/jina/serve/runtimes/worker/http_fastapi_app.py\nindex fd4aeabf8c79c..b45b94f7c62cf 100644\n--- a/jina/serve/runtimes/worker/http_fastapi_app.py\n+++ b/jina/serve/runtimes/worker/http_fastapi_app.py\n@@ -7,6 +7,7 @@\n from jina.serve.networking.sse import EventSourceResponse\n from jina.types.request.data import DataRequest\n \n+\n if TYPE_CHECKING:\n     from jina.logging.logger import JinaLogger\n \n@@ -88,7 +89,6 @@ def add_post_route(\n \n         @app.api_route(**app_kwargs)\n         async def post(body: input_model, response: Response):\n-\n             req = DataRequest()\n             if body.header is not None:\n                 req.header.request_id = body.header.request_id\n@@ -122,7 +122,9 @@ async def post(body: input_model, response: Response):\n                     docs_response = resp.docs.to_dict()\n                 else:\n                     docs_response = resp.docs\n+\n                 ret = output_model(data=docs_response, parameters=resp.parameters)\n+\n                 return ret\n \n     def add_streaming_routes(\ndiff --git a/tests/integration/dynamic_batching/test_dynamic_batching.py b/tests/integration/dynamic_batching/test_dynamic_batching.py\nindex 90126a82700f5..355e771c52fc7 100644\n--- a/tests/integration/dynamic_batching/test_dynamic_batching.py\n+++ b/tests/integration/dynamic_batching/test_dynamic_batching.py\n@@ -629,11 +629,17 @@ def test_failure_propagation():\n             )\n \n \n-@pytest.mark.repeat(10)\n-def test_exception_handling_in_dynamic_batch():\n+@pytest.mark.parametrize(\n+    'flush_all',\n+    [\n+        False,\n+        True\n+    ],\n+)\n+def test_exception_handling_in_dynamic_batch(flush_all):\n     class SlowExecutorWithException(Executor):\n \n-        @dynamic_batching(preferred_batch_size=3, timeout=1000)\n+        @dynamic_batching(preferred_batch_size=3, timeout=5000, flush_all=flush_all)\n         @requests(on='/foo')\n         def foo(self, docs, **kwargs):\n             for doc in docs:\n@@ -659,4 +665,50 @@ def foo(self, docs, **kwargs):\n             if r.header.status.code == jina_pb2.StatusProto.StatusCode.ERROR:\n                 num_failed_requests += 1\n \n-        assert 1 <= num_failed_requests <= 3  # 3 requests in the dynamic batch failing\n+        if not flush_all:\n+            assert 1 <= num_failed_requests <= 3  # 3 requests in the dynamic batch failing\n+        else:\n+            assert 1 <= num_failed_requests <= len(da)  # 3 requests in the dynamic batch failing\n+\n+@pytest.mark.asyncio\n+@pytest.mark.parametrize(\n+    'flush_all',\n+    [\n+        False,\n+        True\n+    ],\n+)\n+async def test_num_docs_processed_in_exec(flush_all):\n+    class DynBatchProcessor(Executor):\n+\n+        @dynamic_batching(preferred_batch_size=5, timeout=5000, flush_all=flush_all)\n+        @requests(on='/foo')\n+        def foo(self, docs, **kwargs):\n+            for doc in docs:\n+                doc.text = f\"{len(docs)}\"\n+\n+    depl = Deployment(uses=DynBatchProcessor, protocol='http')\n+\n+    with depl:\n+        da = DocumentArray([Document(text='good') for _ in range(50)])\n+        cl = Client(protocol=depl.protocol, port=depl.port, asyncio=True)\n+        res = []\n+        async for r in cl.post(\n+            on='/foo',\n+            inputs=da,\n+            request_size=7,\n+            continue_on_error=True,\n+            results_in_order=True,\n+        ):\n+            res.extend(r)\n+        assert len(res) == 50  # 1 request per input\n+        if not flush_all:\n+            for d in res:\n+                assert int(d.text) <= 5\n+        else:\n+            larger_than_5 = 0\n+            for d in res:\n+                if int(d.text) > 5:\n+                    larger_than_5 += 1\n+                assert int(d.text) >= 5\n+            assert larger_than_5 > 0\ndiff --git a/tests/unit/serve/dynamic_batching/test_batch_queue.py b/tests/unit/serve/dynamic_batching/test_batch_queue.py\nindex 22758995d7270..2d0a172ca5a27 100644\n--- a/tests/unit/serve/dynamic_batching/test_batch_queue.py\n+++ b/tests/unit/serve/dynamic_batching/test_batch_queue.py\n@@ -9,7 +9,8 @@\n \n \n @pytest.mark.asyncio\n-async def test_batch_queue_timeout():\n+@pytest.mark.parametrize('flush_all', [False, True])\n+async def test_batch_queue_timeout(flush_all):\n     async def foo(docs, **kwargs):\n         await asyncio.sleep(0.1)\n         return DocumentArray([Document(text='Done') for _ in docs])\n@@ -20,6 +21,7 @@ async def foo(docs, **kwargs):\n         response_docarray_cls=DocumentArray,\n         preferred_batch_size=4,\n         timeout=2000,\n+        flush_all=flush_all,\n     )\n \n     three_data_requests = [DataRequest() for _ in range(3)]\n@@ -59,7 +61,8 @@ async def process_request(req):\n \n \n @pytest.mark.asyncio\n-async def test_batch_queue_timeout_does_not_wait_previous_batch():\n+@pytest.mark.parametrize('flush_all', [False, True])\n+async def test_batch_queue_timeout_does_not_wait_previous_batch(flush_all):\n     batches_lengths_computed = []\n \n     async def foo(docs, **kwargs):\n@@ -73,6 +76,7 @@ async def foo(docs, **kwargs):\n         response_docarray_cls=DocumentArray,\n         preferred_batch_size=5,\n         timeout=3000,\n+        flush_all=flush_all\n     )\n \n     data_requests = [DataRequest() for _ in range(3)]\n@@ -93,19 +97,28 @@ async def process_request(req, sleep=0):\n     init_time = time.time()\n     tasks = [asyncio.create_task(process_request(req)) for req in data_requests]\n     tasks.append(asyncio.create_task(process_request(extra_data_request, sleep=2)))\n-    responses = await asyncio.gather(*tasks)\n+    _ = await asyncio.gather(*tasks)\n     time_spent = (time.time() - init_time) * 1000\n-    # TIME TAKEN: 8000 for first batch of requests, plus 4000 for second batch that is fired inmediately\n-    # BEFORE FIX in https://github.com/jina-ai/jina/pull/6071, this would take: 8000 + 3000 + 4000 (Timeout would start counting too late)\n-    assert time_spent >= 12000\n-    assert time_spent <= 12500\n-    assert batches_lengths_computed == [5, 1, 2]\n+\n+    if flush_all is False:\n+        # TIME TAKEN: 8000 for first batch of requests, plus 4000 for second batch that is fired inmediately\n+        # BEFORE FIX in https://github.com/jina-ai/jina/pull/6071, this would take: 8000 + 3000 + 4000 (Timeout would start counting too late)\n+        assert time_spent >= 12000\n+        assert time_spent <= 12500\n+    else:\n+        assert time_spent >= 8000\n+        assert time_spent <= 8500\n+    if flush_all is False:\n+        assert batches_lengths_computed == [5, 1, 2]\n+    else:\n+        assert batches_lengths_computed == [6, 2]\n \n     await bq.close()\n \n \n @pytest.mark.asyncio\n-async def test_batch_queue_req_length_larger_than_preferred():\n+@pytest.mark.parametrize('flush_all', [False, True])\n+async def test_batch_queue_req_length_larger_than_preferred(flush_all):\n     async def foo(docs, **kwargs):\n         await asyncio.sleep(0.1)\n         return DocumentArray([Document(text='Done') for _ in docs])\n@@ -116,6 +129,7 @@ async def foo(docs, **kwargs):\n         response_docarray_cls=DocumentArray,\n         preferred_batch_size=4,\n         timeout=2000,\n+        flush_all=flush_all,\n     )\n \n     data_requests = [DataRequest() for _ in range(3)]\n@@ -240,7 +254,8 @@ async def process_request(req):\n \n \n @pytest.mark.asyncio\n-async def test_exception_all():\n+@pytest.mark.parametrize('flush_all', [False, True])\n+async def test_exception_all(flush_all):\n     async def foo(docs, **kwargs):\n         raise AssertionError\n \n@@ -249,6 +264,7 @@ async def foo(docs, **kwargs):\n         request_docarray_cls=DocumentArray,\n         response_docarray_cls=DocumentArray,\n         preferred_batch_size=2,\n+        flush_all=flush_all,\n         timeout=500,\n     )\n \n@@ -284,14 +300,19 @@ async def foo(docs, **kwargs):\n     assert repr(bq) == str(bq)\n \n \n-@pytest.mark.parametrize('num_requests', [61, 127, 100])\n-@pytest.mark.parametrize('preferred_batch_size', [7, 27, 61, 73, 100])\n+@pytest.mark.parametrize('num_requests', [33, 127, 100])\n+@pytest.mark.parametrize('preferred_batch_size', [7, 61, 100])\n @pytest.mark.parametrize('timeout', [0.3, 500])\n+@pytest.mark.parametrize('flush_all', [False, True])\n @pytest.mark.asyncio\n-async def test_return_proper_assignment(num_requests, preferred_batch_size, timeout):\n+async def test_return_proper_assignment(num_requests, preferred_batch_size, timeout, flush_all):\n     import random\n \n     async def foo(docs, **kwargs):\n+        if not flush_all:\n+            assert len(docs) <= preferred_batch_size\n+        else:\n+            assert len(docs) >= preferred_batch_size\n         await asyncio.sleep(0.1)\n         for doc in docs:\n             doc.text += ' Processed'\n@@ -301,6 +322,7 @@ async def foo(docs, **kwargs):\n         request_docarray_cls=DocumentArray,\n         response_docarray_cls=DocumentArray,\n         preferred_batch_size=preferred_batch_size,\n+        flush_all=flush_all,\n         timeout=timeout,\n     )\n \ndiff --git a/tests/unit/serve/executors/test_executor.py b/tests/unit/serve/executors/test_executor.py\nindex 3bb6f1769ceff..a6d902421ae83 100644\n--- a/tests/unit/serve/executors/test_executor.py\n+++ b/tests/unit/serve/executors/test_executor.py\n@@ -614,15 +614,15 @@ class C(B):\n     [\n         (\n             dict(preferred_batch_size=4, timeout=5_000),\n-            dict(preferred_batch_size=4, timeout=5_000),\n+            dict(preferred_batch_size=4, timeout=5_000, flush_all=False),\n         ),\n         (\n-            dict(preferred_batch_size=4, timeout=5_000),\n-            dict(preferred_batch_size=4, timeout=5_000),\n+            dict(preferred_batch_size=4, timeout=5_000, flush_all=True),\n+            dict(preferred_batch_size=4, timeout=5_000, flush_all=True),\n         ),\n         (\n             dict(preferred_batch_size=4),\n-            dict(preferred_batch_size=4, timeout=10_000),\n+            dict(preferred_batch_size=4, timeout=10_000, flush_all=False),\n         ),\n     ],\n )\n@@ -641,15 +641,15 @@ def foo(self, docs, **kwargs):\n     [\n         (\n             dict(preferred_batch_size=4, timeout=5_000),\n-            dict(preferred_batch_size=4, timeout=5_000),\n+            dict(preferred_batch_size=4, timeout=5_000, flush_all=False),\n         ),\n         (\n-            dict(preferred_batch_size=4, timeout=5_000),\n-            dict(preferred_batch_size=4, timeout=5_000),\n+            dict(preferred_batch_size=4, timeout=5_000, flush_all=True),\n+            dict(preferred_batch_size=4, timeout=5_000, flush_all=True),\n         ),\n         (\n             dict(preferred_batch_size=4),\n-            dict(preferred_batch_size=4, timeout=10_000),\n+            dict(preferred_batch_size=4, timeout=10_000, flush_all=False),\n         ),\n     ],\n )\n"},"summary":"## Summary of Merge Request\n\nДанный MR направлен на расширение функциональности динамической пакетной обработки в Jina, добавляя новый параметр `flush_all` в декоратор `@dynamic_batching` и класс `BatchQueue`. Основное изменение позволяет управлять получением всех накопленных данных при срабатывании таймаута или достижении `preferred_batch_size`.\n\nС точки зрения качества, изменения хорошо соответствуют стандартам кодирования (оценка 9 по Code Style) и не содержат анти-паттернов (оценка 8). Сложность изменений оценена как \"Medium\". Рекомендуется убедиться в тщательном тестировании нового параметра `flush_all` и его документировании, чтобы избежать потенциальных проблем с производительностью и усложнения логики.\n","antiPatterns":{"detailed_analysis":"Внесенные изменения добавляют новый параметр `flush_all` в декоратор `@dynamic_batching` и класс `BatchQueue`. Этот параметр позволяет определить, будет ли функция получать все накопленные данные в пакете при срабатывании таймаута или достижения `preferred_batch_size`. Изменения затрагивают несколько файлов, включая `decorators.py`, `batch_queue.py`, и тесты. В целом, изменения направлены на расширение функциональности динамической пакетной обработки, что само по себе не является анти-паттерном. Однако, необходимо убедиться, что добавление `flush_all` не приводит к усложнению логики или появлению новых проблем. В коде тестов добавлены новые параметризованные тесты, что является хорошей практикой. ","recommendations":["Проверить, что добавление `flush_all` не приводит к нежелательным побочным эффектам или проблемам с производительностью в различных сценариях использования.","Убедиться, что документация и комментарии в коде четко объясняют поведение параметра `flush_all` и его влияние на работу динамической пакетной обработки."],"confidence":"High","score":8,"summary":"Внесенные изменения добавляют новый параметр `flush_all` в `@dynamic_batching`, что расширяет функциональность динамической пакетной обработки. Анти-паттерны не обнаружены."},"complexity":{"justification":"Данный MR вносит изменения в функциональность динамической пакетной обработки в Jina. Основное изменение заключается в добавлении параметра `flush_all` в декоратор `@dynamic_batching` и в класс `BatchQueue`. Этот параметр позволяет определить, будет ли функция получать все накопленные данные в пакетировщике при срабатывании таймаута или достижения `preferred_batch_size`. Это влияет на логику работы пакетной обработки, особенно в отношении размера пакетов и времени ожидания. Объем изменений умеренный, затрагивает несколько файлов, включая декоратор, класс очереди пакетов и тесты. Влияние на систему умеренное, поскольку затрагивает механизм пакетной обработки, который является важной частью производительности. Когнитивная нагрузка умеренная, так как необходимо понимать влияние нового параметра на существующую логику. Риски умеренные, так как изменения в основном касаются конфигурации и поведения, а не критических алгоритмов. Примеры тестов были добавлены для проверки нового функционала. В целом, изменения требуют некоторого понимания существующей логики пакетной обработки, но не являются сложными или критичными, что соответствует уровню сложности \"Medium\".","classification":"Medium"},"designPatterns":{"detailed_analysis":"Внесенные изменения добавляют новый параметр `flush_all` в декоратор `@dynamic_batching` и класс `BatchQueue`. Этот параметр позволяет определить, будет ли функция получать все накопленные данные при срабатывании таймаута или достижения `preferred_batch_size`. Изменения затрагивают несколько файлов, включая `decorators.py`, `batch_queue.py`, и тесты. В целом, изменения направлены на расширение функциональности динамической пакетной обработки, что само по себе не является анти-паттерном. Однако, введение нового параметра может усложнить логику, если не будет должным образом протестировано и документировано. В коде тестов добавлены новые параметризованные тесты, что является хорошей практикой. В целом, анти-паттерны не обнаружены, но необходимо убедиться в корректности работы нового параметра во всех сценариях.","recommendations":["Убедиться, что новый параметр `flush_all` полностью протестирован во всех сценариях использования. Документировать поведение параметра в документации к API. Проверить, не приводит ли добавление параметра к излишней сложности кода."],"confidence":"High","score":8,"summary":"Внесенные изменения добавляют новый параметр `flush_all` для управления поведением динамической пакетной обработки. Анти-паттерны не обнаружены, но требуется тщательное тестирование и документирование."},"codeStyle":{"detailed_analysis":"Изменения включают в себя добавление нового параметра `flush_all` в декоратор `@dynamic_batching` и класс `BatchQueue`. Этот параметр определяет, будет ли функция получать все накопленные данные при срабатывании таймаута или достижения `preferred_batch_size`. Изменения затрагивают несколько файлов, включая `decorators.py`, `batch_queue.py`, `http_fastapi_app.py`, и несколько тестовых файлов. В основном, изменения хорошо отформатированы и соответствуют существующему стилю кодирования. Имена переменных и функций понятны. Добавлены новые тесты для проверки функциональности `flush_all`.","recommendations":["Нет существенных рекомендаций по стилю кода. Код хорошо отформатирован и соответствует существующим стандартам."],"confidence":"High","score":9,"summary":"Внесенные изменения хорошо соответствуют стандартам кодирования. Добавлена новая функциональность с параметром `flush_all`, которая хорошо интегрирована в существующий код."}},{"pull":{"id":6177,"html_url":"https://github.com/jina-ai/serve/pull/6177","title":"fix: pass header kwargs to get openapi endpoints","body":"Goals:\n\n\n\nresolves #ISSUE-NUMBER\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n check and update documentation. See guide and ask the team.","is_merged":true,"diff":"diff --git a/jina/clients/base/http.py b/jina/clients/base/http.py\nindex 44715ce732d6a..653a98f051629 100644\n--- a/jina/clients/base/http.py\n+++ b/jina/clients/base/http.py\n@@ -24,7 +24,7 @@ def __init__(self, *args, **kwargs):\n         super().__init__(*args, **kwargs)\n         self._endpoints = []\n \n-    async def _get_endpoints_from_openapi(self):\n+    async def _get_endpoints_from_openapi(self, **kwargs):\n         def extract_paths_by_method(spec):\n             paths_by_method = {}\n             for path, methods in spec['paths'].items():\n@@ -39,10 +39,15 @@ def extract_paths_by_method(spec):\n \n         import aiohttp\n \n+        session_kwargs = {}\n+        if 'headers' in kwargs:\n+            session_kwargs = {'headers': kwargs['headers']}\n+\n         proto = 'https' if self.args.tls else 'http'\n         target_url = f'{proto}://{self.args.host}:{self.args.port}/openapi.json'\n         try:\n-            async with aiohttp.ClientSession() as session:\n+\n+            async with aiohttp.ClientSession(**session_kwargs) as session:\n                 async with session.get(target_url) as response:\n                     content = await response.read()\n                     openapi_response = json.loads(content.decode())\n@@ -129,7 +134,7 @@ async def _get_results(\n         request_iterator = self._get_requests(**kwargs)\n         on = kwargs.get('on', '/post')\n         if len(self._endpoints) == 0:\n-            await self._get_endpoints_from_openapi()\n+            await self._get_endpoints_from_openapi(**kwargs)\n \n         async with AsyncExitStack() as stack:\n             cm1 = ProgressBar(\n"},"summary":"## MR Summary\n\nДанный MR направлен на улучшение функциональности HTTP-клиента, добавляя возможность передачи заголовков в запросы к OpenAPI. Основное изменение заключается в добавлении передачи заголовков (headers) в `aiohttp.ClientSession`. Оценка сложности - низкая, так как изменения небольшие и затрагивают некритичные части кода. Анализ Code Style показал улучшение соответствия стилю, гибкости и читаемости кода. В области Design Patterns и Anti-Patterns не обнаружено проблем, что говорит о хорошем качестве внесенных изменений.\n","antiPatterns":{"detailed_analysis":"Внесенные изменения улучшают код, передавая параметры заголовков в функцию `_get_endpoints_from_openapi`. Это позволяет корректно обрабатывать запросы к OpenAPI endpoints. Анти-паттерны не обнаружены, код стал более гибким и функциональным.","recommendations":[],"confidence":"High","score":10,"summary":"Изменения улучшают обработку заголовков при запросах к OpenAPI endpoints, анти-паттерны не обнаружены."},"complexity":{"justification":"Изменения вносят небольшие правки в HTTP-клиент, добавляя возможность передачи заголовков в запросы к OpenAPI. Объем изменений небольшой, затрагивает один файл. Изменения не затрагивают критические компоненты или основные потоки данных. Когнитивная нагрузка низкая, логика проста и понятна. Риски минимальны, так как изменения не затрагивают основные функции. Это соответствует характеристикам \"Low\" сложности: небольшое количество измененных строк/файлов, изменения в некритических частях, простая логика, низкая когнитивная нагрузка, минимальный риск регрессии.","classification":"Low"},"designPatterns":{"detailed_analysis":"Внесенные изменения улучшают код, передавая заголовки в `aiohttp.ClientSession`. Это позволяет корректно обрабатывать запросы с аутентификацией и другими заголовками. Анти-паттерны не обнаружены, код стал более гибким и функциональным.","recommendations":[],"confidence":"High","score":10,"summary":"Изменения улучшают обработку заголовков HTTP-запросов, не вводя анти-паттерны."},"codeStyle":{"detailed_analysis":"Изменения в основном касаются передачи аргументов `kwargs` в функцию `_get_endpoints_from_openapi`.  В частности, добавлена передача заголовков (headers) в `aiohttp.ClientSession`. Это улучшает соответствие стилю, так как позволяет более гибко настраивать HTTP-запросы.  Форматирование сохранено, изменения минимальны и не влияют на читаемость. Именование переменных и функций соответствует общепринятым соглашениям.  Согласованность сохранена, так как изменения внесены в существующий код.  Читаемость не ухудшилась, а скорее улучшилась, так как добавлена возможность передачи заголовков. Соответствие гайдлайнам высокое, так как изменения соответствуют лучшим практикам.","recommendations":["Нет существенных рекомендаций по улучшению."],"confidence":"High","score":8,"summary":"Внесены незначительные изменения, улучшающие передачу параметров в HTTP-запросы, что повышает гибкость и соответствие стилю."}},{"pull":{"id":6176,"html_url":"https://github.com/jina-ai/serve/pull/6176","title":"test: test CSP parameters","body":"Goals:\n\n\n\nresolves #ISSUE-NUMBER\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n check and update documentation. See guide and ask the team.","is_merged":true,"diff":"diff --git a/jina/serve/executors/__init__.py b/jina/serve/executors/__init__.py\nindex 06416159bf3fa..c821c5c1d0936 100644\n--- a/jina/serve/executors/__init__.py\n+++ b/jina/serve/executors/__init__.py\n@@ -634,25 +634,26 @@ def _validate_sagemaker(self):\n             and self.runtime_args.provider_endpoint\n         ):\n             endpoint_to_use = ('/' + self.runtime_args.provider_endpoint).lower()\n-            if endpoint_to_use in list(self.requests.keys()):\n-                self.logger.warning(\n-                    f'Using \"{endpoint_to_use}\" as \"/invocations\" route'\n-                )\n-                self.requests['/invocations'] = self.requests[endpoint_to_use]\n-                for k in remove_keys:\n-                    self.requests.pop(k)\n-                return\n-\n-        if len(self.requests) == 1:\n-            route = list(self.requests.keys())[0]\n-            self.logger.warning(f'Using \"{route}\" as \"/invocations\" route')\n-            self.requests['/invocations'] = self.requests[route]\n+        elif len(self.requests) == 1:\n+            endpoint_to_use = list(self.requests.keys())[0]\n+        else:\n+            raise ValueError('Cannot identify the endpoint to use for \"/invocations\"')\n+\n+        if endpoint_to_use in list(self.requests.keys()):\n+            self.logger.warning(f'Using \"{endpoint_to_use}\" as \"/invocations\" route')\n+            self.requests['/invocations'] = self.requests[endpoint_to_use]\n+            if (\n+                getattr(self, 'dynamic_batching', {}).get(endpoint_to_use, None)\n+                is not None\n+            ):\n+                self.dynamic_batching['/invocations'] = self.dynamic_batching[\n+                    endpoint_to_use\n+                ]\n+                self.dynamic_batching.pop(endpoint_to_use)\n             for k in remove_keys:\n                 self.requests.pop(k)\n             return\n \n-        raise ValueError('Cannot identify the endpoint to use for \"/invocations\"')\n-\n     def _add_dynamic_batching(self, _dynamic_batching: Optional[Dict]):\n         if _dynamic_batching:\n             self.dynamic_batching = getattr(self, 'dynamic_batching', {})\ndiff --git a/jina/serve/runtimes/worker/request_handling.py b/jina/serve/runtimes/worker/request_handling.py\nindex 08d404fb686d1..af3786f2886d3 100644\n--- a/jina/serve/runtimes/worker/request_handling.py\n+++ b/jina/serve/runtimes/worker/request_handling.py\n@@ -265,7 +265,16 @@ def _init_batchqueue_dict(self):\n             # Endpoints allow specific configurations while functions allow configs to be applied to all endpoints of the function\n             dbatch_endpoints = []\n             dbatch_functions = []\n+            request_models_map = self._executor._get_endpoint_models_dict()\n+\n             for key, dbatch_config in self._executor.dynamic_batching.items():\n+                if request_models_map.get(key, {}).get('parameters', {}).get('model', None) is not None:\n+                    error_msg = f'Executor Dynamic Batching cannot be used for endpoint {key} because it depends on parameters.'\n+                    self.logger.error(\n+                        error_msg\n+                    )\n+                    raise Exception(error_msg)\n+\n                 if key.startswith('/'):\n                     dbatch_endpoints.append((key, dbatch_config))\n                 else:\ndiff --git a/tests/integration/docarray_v2/csp/SampleExecutor/executor.py b/tests/integration/docarray_v2/csp/SampleExecutor/executor.py\nindex 1e0b4afc129c2..e9a45c6757cc5 100644\n--- a/tests/integration/docarray_v2/csp/SampleExecutor/executor.py\n+++ b/tests/integration/docarray_v2/csp/SampleExecutor/executor.py\n@@ -1,7 +1,7 @@\n import numpy as np\n from docarray import BaseDoc, DocList\n from docarray.typing import NdArray\n-from pydantic import Field\n+from pydantic import Field, BaseModel\n \n from jina import Executor, requests\n \n@@ -19,6 +19,11 @@ class Config(BaseDoc.Config):\n         json_encoders = {NdArray: lambda v: v.tolist()}\n \n \n+class Parameters(BaseModel):\n+    emb_dim: int\n+\n+\n+\n class SampleExecutor(Executor):\n     @requests(on=\"/encode\")\n     def foo(self, docs: DocList[TextDoc], **kwargs) -> DocList[EmbeddingResponseModel]:\n@@ -32,3 +37,16 @@ def foo(self, docs: DocList[TextDoc], **kwargs) -> DocList[EmbeddingResponseMode\n                 )\n             )\n         return DocList[EmbeddingResponseModel](ret)\n+\n+    @requests(on=\"/encode_parameter\")\n+    def bar(self, docs: DocList[TextDoc], parameters: Parameters, **kwargs) -> DocList[EmbeddingResponseModel]:\n+        ret = []\n+        for doc in docs:\n+            ret.append(\n+                EmbeddingResponseModel(\n+                    id=doc.id,\n+                    text=doc.text,\n+                    embeddings=np.random.random((1, parameters.emb_dim)),\n+                )\n+            )\n+        return DocList[EmbeddingResponseModel](ret)\ndiff --git a/tests/integration/docarray_v2/csp/test_sagemaker_embedding.py b/tests/integration/docarray_v2/csp/test_sagemaker_embedding.py\nindex a2233f0789dbe..8ad4ad3861586 100644\n--- a/tests/integration/docarray_v2/csp/test_sagemaker_embedding.py\n+++ b/tests/integration/docarray_v2/csp/test_sagemaker_embedding.py\n@@ -35,6 +35,8 @@ def test_provider_sagemaker_pod_inference():\n             os.path.join(os.path.dirname(__file__), \"SampleExecutor\", \"config.yml\"),\n             '--provider',\n             'sagemaker',\n+            \"--provider-endpoint\",\n+            \"encode\",\n             'serve',  # This is added by sagemaker\n         ]\n     )\n@@ -60,6 +62,43 @@ def test_provider_sagemaker_pod_inference():\n         assert len(resp_json['data'][0]['embeddings'][0]) == 64\n \n \n+def test_provider_sagemaker_pod_inference_parameters():\n+    args, _ = set_pod_parser().parse_known_args(\n+        [\n+            '--uses',\n+            os.path.join(os.path.dirname(__file__), \"SampleExecutor\", \"config.yml\"),\n+            '--provider',\n+            'sagemaker',\n+            \"--provider-endpoint\",\n+            \"encode_parameter\",\n+            'serve',  # This is added by sagemaker\n+        ]\n+    )\n+    with Pod(args):\n+        # Test the `GET /ping` endpoint (added by jina for sagemaker)\n+        resp = requests.get(f'http://localhost:{sagemaker_port}/ping')\n+        assert resp.status_code == 200\n+        assert resp.json() == {}\n+        for emb_dim in {32, 64, 128}:\n+\n+            # Test the `POST /invocations` endpoint for inference\n+            # Note: this endpoint is not implemented in the sample executor\n+            resp = requests.post(\n+                f'http://localhost:{sagemaker_port}/invocations',\n+                json={\n+                    'data': [\n+                        {'text': 'hello world'},\n+                    ],\n+                    'parameters': {'emb_dim': emb_dim}\n+                },\n+            )\n+            assert resp.status_code == 200\n+            resp_json = resp.json()\n+            assert len(resp_json['data']) == 1\n+            assert len(resp_json['data'][0]['embeddings'][0]) == emb_dim\n+\n+\n+\n @pytest.mark.parametrize(\n     \"filename\",\n     [\n@@ -74,6 +113,8 @@ def test_provider_sagemaker_pod_batch_transform_valid(filename):\n             os.path.join(os.path.dirname(__file__), \"SampleExecutor\", \"config.yml\"),\n             '--provider',\n             'sagemaker',\n+            \"--provider-endpoint\",\n+            \"encode\",\n             'serve',  # This is added by sagemaker\n         ]\n     )\n@@ -114,6 +155,8 @@ def test_provider_sagemaker_pod_batch_transform_invalid():\n             os.path.join(os.path.dirname(__file__), \"SampleExecutor\", \"config.yml\"),\n             '--provider',\n             'sagemaker',\n+            \"--provider-endpoint\",\n+            \"encode\",\n             'serve',  # This is added by sagemaker\n         ]\n     )\n@@ -145,6 +188,7 @@ def test_provider_sagemaker_deployment_inference():\n     with Deployment(\n         uses=os.path.join(os.path.dirname(__file__), \"SampleExecutor\", \"config.yml\"),\n         provider='sagemaker',\n+        provider_endpoint='encode',\n         port=dep_port,\n     ):\n         # Test the `GET /ping` endpoint (added by jina for sagemaker)\n@@ -171,7 +215,7 @@ def test_provider_sagemaker_deployment_inference():\n def test_provider_sagemaker_deployment_inference_docker(replica_docker_image_built):\n     dep_port = random_port()\n     with Deployment(\n-        uses='docker://sampler-executor', provider='sagemaker', port=dep_port\n+        uses='docker://sampler-executor', provider='sagemaker', provider_endpoint='encode', port=dep_port\n     ):\n         # Test the `GET /ping` endpoint (added by jina for sagemaker)\n         rsp = requests.get(f'http://localhost:{dep_port}/ping')\n@@ -200,6 +244,7 @@ def test_provider_sagemaker_deployment_batch():\n     with Deployment(\n         uses=os.path.join(os.path.dirname(__file__), \"SampleExecutor\", \"config.yml\"),\n         provider='sagemaker',\n+        provider_endpoint='encode',\n         port=dep_port,\n     ):\n         # Test the `POST /invocations` endpoint for batch-transform\n@@ -230,6 +275,24 @@ def test_provider_sagemaker_deployment_wrong_port():\n                 os.path.dirname(__file__), \"SampleExecutor\", \"config.yml\"\n             ),\n             provider='sagemaker',\n+            provider_endpoint='encode',\n             port=8080,\n         ):\n             pass\n+\n+\n+def test_provider_sagemaker_deployment_wrong_dynamic_batching():\n+    # Sagemaker executor would start on 8080.\n+    # If we use the same port for deployment, it should raise an error.\n+    from jina.excepts import RuntimeFailToStart\n+\n+    with pytest.raises(RuntimeFailToStart) as exc:\n+        with Deployment(\n+            uses=os.path.join(\n+                os.path.dirname(__file__), \"SampleExecutor\", \"config.yml\"\n+            ),\n+            provider='sagemaker',\n+            provider_endpoint='encode_parameter',\n+            uses_dynamic_batching={'/encode_parameter': {'preferred_batch_size': 20, 'timeout': 50}},\n+        ):\n+            pass\n"},"summary":"## Summary of Merge Request\n\nДанный MR направлен на улучшение обработки запросов к Sagemaker и добавление поддержки динамической пакетной обработки с параметрами. Основные изменения включают в себя улучшение логики выбора эндпоинта `/invocations`, добавление нового параметризованного эндпоинта и тестов для него, а также исправление логики обработки динамической пакетной обработки. Оценка сложности изменений – \"Medium\", так как затрагивается логика работы с сервисами. Код в целом соответствует стандартам, но требует незначительной доработки по стилю (длина строк, пробелы, комментарии). В части Design Patterns и Anti-Patterns оценка высокая, изменения улучшают архитектуру и не вводят анти-паттернов.\n","antiPatterns":{"detailed_analysis":"Внесенные изменения затрагивают логику выбора эндпоинта для запросов к Sagemaker и добавляют поддержку динамической пакетной обработки для эндпоинтов с параметрами. В `jina/serve/executors/__init__.py` улучшена логика выбора эндпоинта `/invocations`, а также добавлена проверка на использование динамической пакетной обработки с параметризованными эндпоинтами, что является хорошей практикой. В `jina/serve/runtimes/worker/request_handling.py` добавлена проверка, которая предотвращает использование динамической пакетной обработки для эндпоинтов, зависящих от параметров, что предотвращает потенциальные ошибки. В `tests/integration/docarray_v2/csp/SampleExecutor/executor.py` добавлен новый эндпоинт `/encode_parameter` для тестирования. В `tests/integration/docarray_v2/csp/test_sagemaker_embedding.py` добавлены тесты для нового эндпоинта с параметрами и для проверки динамической пакетной обработки. Изменения направлены на улучшение функциональности и стабильности, анти-паттерны не обнаружены.","recommendations":["Рекомендуется продолжить следовать лучшим практикам при разработке."],"confidence":"High","score":10,"summary":"Изменения вносят улучшения в логику выбора эндпоинтов и поддержку динамической пакетной обработки, анти-паттерны не обнаружены."},"complexity":{"justification":"Данный diff содержит изменения в нескольких файлах, затрагивающие логику работы с Sagemaker и динамической пакетной обработкой. В частности, изменения в `jina/serve/executors/__init__.py` и `jina/serve/runtimes/worker/request_handling.py` касаются выбора конечной точки для вызова и обработки динамической пакетной обработки, что требует понимания взаимодействия между компонентами. Добавлены новые тесты в `tests/integration/docarray_v2/csp/test_sagemaker_embedding.py`, которые проверяют работу с параметрами. Объем изменений умеренный, но затрагивает логику работы с сервисами, что требует внимательного анализа. Риски умеренные, так как изменения в основном касаются конфигурации и обработки запросов, а не критических частей системы. Когнитивная нагрузка средняя, так как требуется понимание работы с Sagemaker и динамической пакетной обработкой.  В целом, изменения соответствуют уровню сложности \"Medium\".","classification":"Medium"},"designPatterns":{"detailed_analysis":"Внесенные изменения затрагивают логику выбора эндпоинта для запросов к Sagemaker, а также добавляют поддержку динамической пакетной обработки с параметрами. В `jina/serve/executors/__init__.py` улучшена логика выбора эндпоинта `/invocations`, что упрощает конфигурацию. В `jina/serve/runtimes/worker/request_handling.py` добавлена проверка, которая предотвращает использование динамической пакетной обработки для эндпоинтов, зависящих от параметров, что является хорошей практикой. Добавлены новые тесты в `tests/integration/docarray_v2/csp/test_sagemaker_embedding.py` для проверки работы с параметрами. Анти-паттерны не обнаружены.","recommendations":[],"confidence":"High","score":10,"summary":"Изменения улучшают логику выбора эндпоинтов и добавляют поддержку динамической пакетной обработки с параметрами, не вводя анти-паттернов."},"codeStyle":{"detailed_analysis":"Изменения включают в себя улучшения в обработке запросов к Sagemaker, добавление нового теста для проверки работы с параметрами, а также исправление логики выбора маршрута \"/invocations\".\n\n**Форматирование:** В целом, форматирование соответствует стандартам, но в некоторых местах наблюдается незначительное отклонение от PEP 8 (например, длина строк). \n\n**Именование:** Имена переменных и функций в основном понятны и соответствуют своему назначению.  \n\n**Консистентность:** Изменения вносят улучшения в консистентность, особенно в части обработки маршрутов. \n\n**Читаемость:** Код в целом читаемый, но добавление нового функционала (параметризованный endpoint) немного усложняет понимание.  Необходимо убедиться, что комментарии объясняют логику работы с параметрами.\n\n**Соответствие гайдлайнам:** В целом, код соответствует гайдлайнам, но необходимо обратить внимание на длину строк и использование пробелов.\n\nВ целом, изменения улучшают функциональность и стабильность, но требуют небольшой доработки по стилю.","recommendations":["Проверить длину строк и при необходимости сократить их.","Убедиться, что добавлены комментарии, объясняющие логику работы с параметрами в новом endpoint.","Проверить использование пробелов в соответствии с PEP 8."],"confidence":"Medium","score":7,"summary":"Внесены улучшения в обработку запросов к Sagemaker, добавлены тесты и исправлена логика выбора маршрутов. Код в целом соответствует стандартам, но требует незначительной доработки по стилю."}},{"pull":{"id":6173,"html_url":"https://github.com/jina-ai/serve/pull/6173","title":"ci: update force-release.yml","body":"Goals:\n\n\n\nresolves #ISSUE-NUMBER\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n check and update documentation. See guide and ask the team.","is_merged":true,"diff":"diff --git a/.github/workflows/force-release.yml b/.github/workflows/force-release.yml\nindex f8ec19969cbfb..52c0a25f724c6 100644\n--- a/.github/workflows/force-release.yml\n+++ b/.github/workflows/force-release.yml\n@@ -1,4 +1,4 @@\n-pname: Manual Release\n+name: Manual Release\n \n on:\n   workflow_dispatch:\n"},"summary":"## MR Summary\n\nДанный merge request направлен на обновление конфигурации CI/CD, а именно изменение имени workflow в файле `.github/workflows/force-release.yml`. Основное изменение заключается в переименовании workflow с `pname` на `name`. Оценка сложности изменений – низкая, так как изменения локальные и понятные. Код соответствует стандартам стиля, улучшая читаемость. Анти-паттерны и нарушения паттернов проектирования не обнаружены.\n","antiPatterns":{"detailed_analysis":"Внесенные изменения в файл `.github/workflows/force-release.yml` незначительны и не содержат каких-либо анти-паттернов. Изменено только имя workflow.","recommendations":[],"confidence":"High","score":10,"summary":"Изменения в файле конфигурации workflow не содержат анти-паттернов."},"complexity":{"justification":"Данный diff представляет собой незначительное изменение в файле конфигурации CI/CD (.github/workflows/force-release.yml). Изменения включают в себя обновление имени workflow. Объем изменений мал (менее 10 строк). Характер изменений - конфигурационный. Влияние на систему минимально. Когнитивная нагрузка низкая. Риски минимальны. Соответствует характеристикам уровня сложности 'Low', так как изменения простые, локализованные и легко понятные. Не требует глубоких знаний системы и не несет значительных рисков. ","classification":"Low"},"designPatterns":{"detailed_analysis":"Внесенные изменения касаются обновления файла конфигурации для CI/CD. Изменения минимальны и не затрагивают логику работы приложения. Анти-паттерны не обнаружены.","recommendations":[],"confidence":"High","score":10,"summary":"Изменения в файле конфигурации CI/CD не содержат анти-паттернов."},"codeStyle":{"detailed_analysis":"Изменения в файле .github/workflows/force-release.yml минимальны и касаются только изменения имени workflow. Форматирование сохранено, отступы и пробелы соответствуют стандартам. Именование workflow изменено с `pname` на `name`, что соответствует общепринятой практике именования в YAML файлах GitHub Actions. Читаемость не ухудшилась, изменения понятны. Соответствие гайдлайнам GitHub Actions соблюдено. В целом, изменения незначительны и не вызывают вопросов с точки зрения стиля.","recommendations":[],"confidence":"High","score":9,"summary":"Изменения в файле .github/workflows/force-release.yml соответствуют стандартам стиля и улучшают читаемость."}},{"pull":{"id":6172,"html_url":"https://github.com/jina-ai/serve/pull/6172","title":"fix: update force-release.yml","body":"Goals:\n\n\n\nresolves #ISSUE-NUMBER\n\n\n...\n\n\n...\n\n\n...\n\n\n...\n\n\n check and update documentation. See guide and ask the team.","is_merged":true,"diff":"diff --git a/.github/workflows/force-release.yml b/.github/workflows/force-release.yml\nindex 3dfbac4eff644..f8ec19969cbfb 100644\n--- a/.github/workflows/force-release.yml\n+++ b/.github/workflows/force-release.yml\n@@ -1,4 +1,4 @@\n-name: Manual Release\n+pname: Manual Release\n \n on:\n   workflow_dispatch:\n@@ -140,13 +140,7 @@ jobs:\n         if: ${{ matrix.os == 'macos-latest' }}\n         run: |\n           python -m cibuildwheel --output-dir dist\n-      - name: Test wheels\n-        run: |\n-          WHEEL_FILE=$(ls dist/*.whl)\n-          python -m pip install $WHEEL_FILE\n-          python -c \"import jraft\"\n-        if: ${{ matrix.os != 'macos-latest' || matrix.platform_id != 'macosx_arm64' }} # runners do not necessarily have macos ARM, so cannot run this test for it\n-\n+          \n       - name: Upload wheels as artifacts\n         uses: actions/upload-artifact@v2\n         with:\n"},"summary":"## MR Summary\n\nДанный MR направлен на обновление конфигурационного файла `force-release.yml` для автоматизации процесса релиза. Основные изменения включают в себя модификации в workflow сборки и публикации пакетов.\n\nС точки зрения сложности, изменения оценены как \"Low\", так как затрагивают один файл и не влияют на критическую логику. Code Style в целом соответствует стандартам, однако рекомендуется заменить `pname` обратно на `name` для улучшения читаемости и рассмотреть добавление проверки колес для macos ARM. Паттерны проектирования и анти-паттерны не обнаружены, что указывает на хорошее качество изменений.\n","antiPatterns":{"detailed_analysis":"Внесенные изменения в файл force-release.yml не содержат явных анти-паттернов. Изменения в основном касаются обновления конфигурации workflow, что не приводит к появлению проблем с архитектурой или дизайном. Отсутствуют признаки дублирования кода, нарушения принципов SOLID или других распространенных анти-паттернов.","recommendations":[],"confidence":"High","score":10,"summary":"Изменения в файле force-release.yml не содержат анти-паттернов."},"complexity":{"justification":"Изменения в основном касаются обновления конфигурационного файла для автоматизации процесса релиза. Объем изменений небольшой, затрагивает один файл. Изменения не влияют на критические компоненты или логику работы системы. Когнитивная нагрузка низкая, изменения легко понять. Риски минимальны, так как изменения в основном касаются процесса сборки и публикации, а не основной функциональности. Пример соответствует \"Low\" - обновление конфигурации.","classification":"Low"},"designPatterns":{"detailed_analysis":"Внесенные изменения в файл force-release.yml, в основном, касаются обновления конфигурации workflow. Не обнаружено явных анти-паттернов. Изменения направлены на улучшение процесса сборки и публикации пакетов. ","recommendations":[],"confidence":"High","score":9,"summary":"Изменения в файле force-release.yml не содержат анти-паттернов."},"codeStyle":{"detailed_analysis":"Изменения в основном касаются файла force-release.yml. Форматирование в целом соответствует стандартам, отступы и пробелы соблюдены. Именование `pname` вместо `name` в начале файла выглядит странно и может ввести в заблуждение. Читаемость кода не сильно пострадала, но замена `name` на `pname` снижает ее. Соответствие гайдлайнам в целом хорошее, за исключением вышеупомянутого `pname`. Отсутствует проверка колес для macos ARM, что может быть упущением.","recommendations":["Заменить `pname` обратно на `name`.","Рассмотреть возможность добавления проверки колес для macos ARM."],"confidence":"High","score":7,"summary":"В целом код соответствует стандартам, но есть небольшие проблемы с именованием и отсутствием проверки для macos ARM."}}],"metricSummary":{"metricsSummary":{"complexity":{"classification":"Low","justification":"В большинстве pull request сложность изменений была оценена как низкая. Изменения в основном касались обновления конфигурации, рефакторинга кода и улучшения логики работы. В нескольких случаях были отмечены изменения, требующие понимания взаимодействия между компонентами, но в целом изменения были локальными и понятными. Когнитивная нагрузка была оценена как низкая, а риски минимальны."},"antiPatterns":{"confidence":"High","detailed_analysis":"Анализ показал, что в целом, в представленных pull request, анти-паттерны не были обнаружены. В основном, изменения касались обновления версий зависимостей, рефакторинга кода и улучшения логики работы. В некоторых случаях были отмечены улучшения в обработке ошибок и упрощение структуры кода. В нескольких случаях были внесены изменения, направленные на оптимизацию производительности и улучшение читаемости кода. В целом, код соответствует лучшим практикам, и анти-паттерны не были выявлены.","summary":"В целом, в представленных pull request анти-паттерны не обнаружены. Изменения в основном касались улучшения кода и оптимизации производительности.","recommendations":[],"score":9.1},"codeStyle":{"confidence":"High","detailed_analysis":"Анализ стиля кода показал, что в большинстве pull request код соответствует стандартам кодирования. Были отмечены улучшения в читаемости, форматировании и именовании переменных. В некоторых случаях были внесены незначительные корректировки, но в целом код хорошо структурирован и легко читается. В нескольких случаях были отмечены улучшения в обработке ошибок и упрощение структуры кода. В целом, код соответствует лучшим практикам, и нарушения стиля кодирования были минимальны.","summary":"В целом, код соответствует стандартам кодирования, с улучшениями в читаемости и форматировании.","recommendations":[],"score":8.22},"designPatterns":{"confidence":"High","detailed_analysis":"Анализ показал, что в большинстве pull request дизайн кода соответствует лучшим практикам. Были отмечены улучшения в структуре кода, упрощении логики и оптимизации производительности. В нескольких случаях были внесены изменения, направленные на улучшение гибкости и управляемости кода. В целом, код хорошо структурирован и соответствует принципам проектирования.","summary":"В целом, дизайн кода соответствует лучшим практикам, с улучшениями в структуре и производительности.","recommendations":[],"score":9.19}},"totalSummary":"Общая оценка производительности сотрудника положительная. В большинстве pull request были отмечены улучшения в коде, оптимизация производительности и соответствие стандартам кодирования. Анти-паттерны не обнаружены, а дизайн кода соответствует лучшим практикам. Рекомендации в основном касаются улучшения читаемости и тестирования. В целом, сотрудник демонстрирует хорошее понимание принципов разработки и умение писать качественный код."},"totalSummary":{"overall_assessment":"Общая оценка производительности сотрудника положительная. Анализ метрик показывает хорошее понимание принципов разработки, соответствие стандартам кодирования и стремление к улучшению качества кода. Отсутствие анти-паттернов и соответствие дизайна кода лучшим практикам свидетельствуют о высоком уровне профессионализма.","positives":["Соответствие стандартам кодирования","Отсутствие анти-паттернов","Соответствие дизайна кода лучшим практикам","Улучшения в коде и оптимизация производительности"],"areas_for_improvement":[]},"totalSummaryData":{"metricsSummary":{"complexity":{"classification":"Low","justification":"В большинстве pull request сложность изменений была оценена как низкая. Изменения в основном касались обновления конфигурации, рефакторинга кода и улучшения логики работы. В нескольких случаях были отмечены изменения, требующие понимания взаимодействия между компонентами, но в целом изменения были локальными и понятными. Когнитивная нагрузка была оценена как низкая, а риски минимальны."},"antiPatterns":{"confidence":"High","detailed_analysis":"Анализ показал, что в целом, в представленных pull request, анти-паттерны не были обнаружены. В основном, изменения касались обновления версий зависимостей, рефакторинга кода и улучшения логики работы. В некоторых случаях были отмечены улучшения в обработке ошибок и упрощение структуры кода. В нескольких случаях были внесены изменения, направленные на оптимизацию производительности и улучшение читаемости кода. В целом, код соответствует лучшим практикам, и анти-паттерны не были выявлены.","summary":"В целом, в представленных pull request анти-паттерны не обнаружены. Изменения в основном касались улучшения кода и оптимизации производительности.","recommendations":[],"score":9.1},"codeStyle":{"confidence":"High","detailed_analysis":"Анализ стиля кода показал, что в большинстве pull request код соответствует стандартам кодирования. Были отмечены улучшения в читаемости, форматировании и именовании переменных. В некоторых случаях были внесены незначительные корректировки, но в целом код хорошо структурирован и легко читается. В нескольких случаях были отмечены улучшения в обработке ошибок и упрощение структуры кода. В целом, код соответствует лучшим практикам, и нарушения стиля кодирования были минимальны.","summary":"В целом, код соответствует стандартам кодирования, с улучшениями в читаемости и форматировании.","recommendations":[],"score":8.22},"designPatterns":{"confidence":"High","detailed_analysis":"Анализ показал, что в большинстве pull request дизайн кода соответствует лучшим практикам. Были отмечены улучшения в структуре кода, упрощении логики и оптимизации производительности. В нескольких случаях были внесены изменения, направленные на улучшение гибкости и управляемости кода. В целом, код хорошо структурирован и соответствует принципам проектирования.","summary":"В целом, дизайн кода соответствует лучшим практикам, с улучшениями в структуре и производительности.","recommendations":[],"score":9.19}},"totalSummary":"Общая оценка производительности сотрудника положительная. В большинстве pull request были отмечены улучшения в коде, оптимизация производительности и соответствие стандартам кодирования. Анти-паттерны не обнаружены, а дизайн кода соответствует лучшим практикам. Рекомендации в основном касаются улучшения читаемости и тестирования. В целом, сотрудник демонстрирует хорошее понимание принципов разработки и умение писать качественный код."},"totalScore":8.836666666666666}